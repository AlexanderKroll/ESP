{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training gradient boosting model for enzyme-substrate pair prediction with ESM-1b-vectors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Loading and preprocessing data for model training and evaluation\n",
    "### 2. Hyperparameter optimization using a 5-fold cross-validation (CV)\n",
    "### 3. Training and validating the final model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\alexk\\projects\\SubFinder\\notebooks_and_code\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import pickle\n",
    "import sys\n",
    "import os\n",
    "import logging\n",
    "from os.path import join\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import roc_auc_score\n",
    "#from hyperopt import fmin, tpe, hp, Trials, rand\n",
    "import xgboost as xgb\n",
    "from sklearn.metrics import matthews_corrcoef\n",
    "\n",
    "\n",
    "\n",
    "sys.path.append('.\\\\additional_code')\n",
    "#from data_preprocessing import *\n",
    "\n",
    "CURRENT_DIR = os.getcwd()\n",
    "print(CURRENT_DIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Loading and preprocessing data for model training and evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def array_column_to_strings(df, column):\n",
    "    df[column] = [str(list(df[column][ind])) for ind in df.index]\n",
    "    return(df)\n",
    "\n",
    "def string_column_to_array(df, column):\n",
    "    df[column] = [np.array(eval(df[column][ind])) for ind in df.index]\n",
    "    return(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (a) Loading data: \n",
    "Only keeping data points from the GO Annotation database with experimental evidence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\alexk\\anaconda3\\envs\\Protein\\lib\\site-packages\\pandas\\core\\ops\\array_ops.py:56: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  result = libops.scalar_compare(x.ravel(), y, op)\n",
      "C:\\Users\\alexk\\anaconda3\\envs\\Protein\\lib\\site-packages\\pandas\\core\\ops\\array_ops.py:56: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  result = libops.scalar_compare(x.ravel(), y, op)\n"
     ]
    }
   ],
   "source": [
    "df_train = pd.read_pickle(join(CURRENT_DIR, \"..\" ,\"data\",\"splits\", \"df_train_with_ESM1b_ts_GNN.pkl\"))\n",
    "df_train = df_train.loc[df_train[\"ESM1b\"] != \"\"]\n",
    "df_train = df_train.loc[df_train[\"type\"] != \"engqvist\"]\n",
    "df_train = df_train.loc[df_train[\"GNN rep\"] != \"\"]\n",
    "df_train.reset_index(inplace = True, drop = True)\n",
    "\n",
    "df_test  = pd.read_pickle(join(CURRENT_DIR, \"..\" ,\"data\",\"splits\", \"df_test_with_ESM1b_ts_GNN.pkl\"))\n",
    "df_test = df_test.loc[df_test[\"ESM1b\"] != \"\"]\n",
    "df_test = df_test.loc[df_test[\"type\"] != \"engqvist\"]\n",
    "df_test = df_test.loc[df_test[\"GNN rep\"] != \"\"]\n",
    "df_test.reset_index(inplace = True, drop = True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (b) Splitting training set into 5-folds for hyperparameter optimization:\n",
    "The 5 folds are created in such a way that the same enzyme does not occure in two different folds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_dataframe(df, frac):\n",
    "    df1 = pd.DataFrame(columns = list(df.columns))\n",
    "    df2 = pd.DataFrame(columns = list(df.columns))\n",
    "    try:\n",
    "        df.drop(columns = [\"level_0\"], inplace = True)\n",
    "    except: \n",
    "        pass\n",
    "    df.reset_index(inplace = True)\n",
    "    \n",
    "    train_indices = []\n",
    "    test_indices = []\n",
    "    ind = 0\n",
    "    while len(train_indices) +len(test_indices) < len(df):\n",
    "        if ind not in train_indices and ind not in test_indices:\n",
    "            if ind % frac != 0:\n",
    "                n_old = len(train_indices)\n",
    "                train_indices.append(ind)\n",
    "                train_indices = list(set(train_indices))\n",
    "\n",
    "                while n_old != len(train_indices):\n",
    "                    n_old = len(train_indices)\n",
    "\n",
    "                    training_seqs= list(set(df[\"ESM1b\"].loc[train_indices]))\n",
    "\n",
    "                    train_indices = train_indices + (list(df.loc[df[\"ESM1b\"].isin(training_seqs)].index))\n",
    "                    train_indices = list(set(train_indices))\n",
    "                \n",
    "            else:\n",
    "                n_old = len(test_indices)\n",
    "                test_indices.append(ind)\n",
    "                test_indices = list(set(test_indices))\n",
    "\n",
    "                while n_old != len(test_indices):\n",
    "                    n_old = len(test_indices)\n",
    "\n",
    "                    testing_seqs= list(set(df[\"ESM1b\"].loc[test_indices]))\n",
    "\n",
    "                    test_indices = test_indices + (list(df.loc[df[\"ESM1b\"].isin(testing_seqs)].index))\n",
    "                    test_indices = list(set(test_indices))\n",
    "                \n",
    "        ind +=1\n",
    "    return(df.loc[train_indices], df.loc[test_indices])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''data_train2 = df_train.copy()\n",
    "data_train2 = array_column_to_strings(data_train2, column = \"ESM1b\")\n",
    "\n",
    "data_train2, df_fold = split_dataframe(df = data_train2, frac=5)\n",
    "indices_fold1 = list(df_fold[\"index\"])\n",
    "print(len(data_train2), len(indices_fold1))#\n",
    "\n",
    "data_train2, df_fold = split_dataframe(df = data_train2, frac=4)\n",
    "indices_fold2 = list(df_fold[\"index\"])\n",
    "print(len(data_train2), len(indices_fold2))\n",
    "\n",
    "data_train2, df_fold = split_dataframe(df = data_train2, frac=3)\n",
    "indices_fold3 = list(df_fold[\"index\"])\n",
    "print(len(data_train2), len(indices_fold3))\n",
    "\n",
    "data_train2, df_fold = split_dataframe(df = data_train2, frac=2)\n",
    "indices_fold4 = list(df_fold[\"index\"])\n",
    "indices_fold5 = list(data_train2[\"index\"])\n",
    "print(len(data_train2), len(indices_fold4))\n",
    "\n",
    "\n",
    "fold_indices = [indices_fold1, indices_fold2, indices_fold3, indices_fold4, indices_fold5]\n",
    "\n",
    "train_indices = [[], [], [], [], []]\n",
    "test_indices = [[], [], [], [], []]\n",
    "\n",
    "for i in range(5):\n",
    "    for j in range(5):\n",
    "        if i != j:\n",
    "            train_indices[i] = train_indices[i] + fold_indices[j]\n",
    "            \n",
    "    test_indices[i] = fold_indices[i]\n",
    "    \n",
    "np.save(join(CURRENT_DIR, \"..\" ,\"data\",\"splits\", \"CV_train_indices.npy\"), train_indices)\n",
    "np.save(join(CURRENT_DIR, \"..\" ,\"data\",\"splits\", \"CV_test_indices.npy\"), test_indices)''';"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_indices = list(np.load(join(CURRENT_DIR, \"..\" ,\"data\",\"splits\", \"CV_train_indices.npy\"),  allow_pickle=True))\n",
    "test_indices = list(np.load(join(CURRENT_DIR, \"..\" ,\"data\",\"splits\", \"CV_test_indices.npy\"),  allow_pickle=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Hyperparameter optimization using a 5-fold cross-validation (CV)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (a) ECFP and ESM1b:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (i) Creating numpy arrays with input vectors and output variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_input_and_output_data(df):\n",
    "    X = ();\n",
    "    y = ();\n",
    "    \n",
    "    for ind in df.index:\n",
    "        emb = df[\"ESM1b\"][ind]\n",
    "        ecfp = np.array(list(df[\"ECFP\"][ind])).astype(int)\n",
    "                \n",
    "        X = X +(np.concatenate([ecfp, emb]), );\n",
    "        y = y + (df[\"Binding\"][ind], );\n",
    "\n",
    "    return(X,y)\n",
    "\n",
    "train_X, train_y =  create_input_and_output_data(df = df_train)\n",
    "test_X, test_y =  create_input_and_output_data(df = df_test)\n",
    "\n",
    "\n",
    "feature_names =  [\"ECFP_\" + str(i) for i in range(1024)]\n",
    "feature_names = feature_names + [\"ESM1b_\" + str(i) for i in range(1280)]\n",
    "\n",
    "train_X = np.array(train_X)\n",
    "test_X  = np.array(test_X)\n",
    "\n",
    "train_y = np.array(train_y)\n",
    "test_y  = np.array(test_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (ii) Performing hyperparameter optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'hp' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_14128/3269672333.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     26\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     27\u001b[0m \u001b[1;31m#Defining search space for hyperparameter optimization\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 28\u001b[1;33m space_gradient_boosting = {\"learning_rate\": hp.uniform(\"learning_rate\", 0.01, 0.5),\n\u001b[0m\u001b[0;32m     29\u001b[0m     \u001b[1;34m\"max_depth\"\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mhp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mchoice\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"max_depth\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;36m9\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m11\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m12\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m13\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     30\u001b[0m     \u001b[1;34m\"reg_lambda\"\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mhp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0muniform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"reg_lambda\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'hp' is not defined"
     ]
    }
   ],
   "source": [
    "def cross_validation_neg_acc_gradient_boosting(param):\n",
    "    num_round = param[\"num_rounds\"]\n",
    "    param[\"tree_method\"] = \"gpu_hist\"\n",
    "    param[\"sampling_method\"] = \"gradient_based\"\n",
    "    param['objective'] = 'binary:logistic'\n",
    "    weights = np.array([param[\"weight\"] if binding == 0 else 1.0 for binding in df_train[\"Binding\"]])\n",
    "    \n",
    "    del param[\"num_rounds\"]\n",
    "    del param[\"weight\"]\n",
    "    \n",
    "    loss = []\n",
    "    for i in range(5):\n",
    "        train_index, test_index  = train_indices[i], test_indices[i]\n",
    "        dtrain = xgb.DMatrix(np.array(train_X[train_index]), weight = weights[train_index],\n",
    "                         label = np.array(train_y[train_index]))\n",
    "        dvalid = xgb.DMatrix(np.array(train_X[test_index]))\n",
    "        bst = xgb.train(param,  dtrain, int(num_round), verbose_eval=1)\n",
    "        y_valid_pred = np.round(bst.predict(dvalid))\n",
    "        validation_y = train_y[test_index]\n",
    "    \n",
    "        false_positive = 100*(1-np.mean(np.array(validation_y)[y_valid_pred == 1]))\n",
    "        false_negative = 100*(np.mean(np.array(validation_y)[y_valid_pred == 0]))\n",
    "        logging.info(\"False positive rate: \" + str(false_positive)+ \"; False negative rate: \" + str(false_negative))\n",
    "        loss.append(2*(false_negative**2) + false_positive**1.3)\n",
    "    return(np.mean(loss))\n",
    "\n",
    "#Defining search space for hyperparameter optimization\n",
    "space_gradient_boosting = {\"learning_rate\": hp.uniform(\"learning_rate\", 0.01, 0.5),\n",
    "    \"max_depth\": hp.choice(\"max_depth\", [9,10,11,12,13]),\n",
    "    \"reg_lambda\": hp.uniform(\"reg_lambda\", 0, 5),\n",
    "    \"reg_alpha\": hp.uniform(\"reg_alpha\", 0, 5),\n",
    "    \"max_delta_step\": hp.uniform(\"max_delta_step\", 0, 5),\n",
    "    \"min_child_weight\": hp.uniform(\"min_child_weight\", 0.1, 15),\n",
    "    \"num_rounds\":  hp.uniform(\"num_rounds\", 200, 400),\n",
    "    \"weight\" : hp.uniform(\"weight\", 0.1,0.33)}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Performing a random grid search:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''trials = Trials()\n",
    "\n",
    "for i in range(1,2000):\n",
    "    best = fmin(fn = cross_validation_neg_acc_gradient_boosting, space = space_gradient_boosting,\n",
    "                algo = rand.suggest, max_evals = i, trials = trials)\n",
    "    np.save(join(CURRENT_DIR, \"..\" ,\"data\", \"results\", \"cross_validation_binding_ESM1b.npy\"), trials.best_trial)\n",
    "    np.save(join(CURRENT_DIR, \"..\" ,\"data\", \"results\", \"cross_validation_binding_ESM1b_argmin.npy\"), trials.argmin)\n",
    "    logging.info(i)\n",
    "    logging.info(trials.best_trial[\"result\"][\"loss\"])\n",
    "    logging.info(trials.argmin)''';"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Best set of hyperparameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "param = {'learning_rate': 0.12771337495138718,\n",
    "         'max_delta_step': 3.080851382419611,\n",
    "         'max_depth': 13,\n",
    "         'min_child_weight': 2.68947814956559,\n",
    "         'num_rounds': 332.92969059815346,\n",
    "         'reg_alpha': 1.4293630231664674,\n",
    "         'reg_lambda': 0.12220981612600046,\n",
    "         'weight': 0.11412319177763543}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (iii) Repeating 5-fold CV for best set of hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[08:02:25] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[08:05:46] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[08:09:10] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[08:12:30] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[08:15:49] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Loss values: [145.78749933523534, 143.24696900455865, 152.99577743836903, 142.04005688827212, 140.47859087124428]\n",
      "Accuracies: [0.8696086443294289, 0.8701705855232826, 0.859611805370912, 0.8664304694419841, 0.8676669981017807]\n",
      "ROC-AUC scores: [0.9386338140991644, 0.9417085126064844, 0.9334066416003604, 0.9396788677977708, 0.9387971266200663]\n"
     ]
    }
   ],
   "source": [
    "num_round = param[\"num_rounds\"]\n",
    "param[\"tree_method\"] = \"gpu_hist\"\n",
    "param[\"sampling_method\"] = \"gradient_based\"\n",
    "param['objective'] = 'binary:logistic'\n",
    "weights = np.array([param[\"weight\"] if binding == 0 else 1.0 for binding in df_train[\"Binding\"]])\n",
    "\n",
    "del param[\"num_rounds\"]\n",
    "del param[\"weight\"]\n",
    "\n",
    "\n",
    "loss = []\n",
    "accuracy = []\n",
    "ROC_AUC = []\n",
    "\n",
    "for i in range(5):\n",
    "    train_index, test_index  = train_indices[i], test_indices[i]\n",
    "    dtrain = xgb.DMatrix(np.array(train_X[train_index]), weight = weights[train_index],\n",
    "                     label = np.array(train_y[train_index]))\n",
    "    dvalid = xgb.DMatrix(np.array(train_X[test_index]))\n",
    "    bst = xgb.train(param,  dtrain, int(num_round), verbose_eval=1)\n",
    "    y_valid_pred = np.round(bst.predict(dvalid))\n",
    "    validation_y = train_y[test_index]\n",
    "\n",
    "    #calculate loss:\n",
    "    false_positive = 100*(1-np.mean(np.array(validation_y)[y_valid_pred == 1]))\n",
    "    false_negative = 100*(np.mean(np.array(validation_y)[y_valid_pred == 0]))\n",
    "    logging.info(\"False positive rate: \" + str(false_positive)+ \"; False negative rate: \" + str(false_negative))\n",
    "    loss.append(2*(false_negative**2) + false_positive**1.3)\n",
    "    #calculate accuracy:\n",
    "    accuracy.append(np.mean(y_valid_pred == np.array(validation_y)))\n",
    "    #calculate ROC-AUC score:\n",
    "    ROC_AUC.append(roc_auc_score(np.array(validation_y), bst.predict(dvalid)))\n",
    "    \n",
    "print(\"Loss values: %s\" %loss) \n",
    "print(\"Accuracies: %s\" %accuracy)\n",
    "print(\"ROC-AUC scores: %s\" %ROC_AUC)\n",
    "\n",
    "np.save(join(CURRENT_DIR, \"..\" ,\"data\", \"training_results\", \"acc_CV_xgboost_ESM1b_ECFP.npy\"), np.array(accuracy))\n",
    "np.save(join(CURRENT_DIR, \"..\" ,\"data\", \"training_results\", \"loss_CV_xgboost_ESM1b_ECFP.npy\"), np.array(loss))\n",
    "np.save(join(CURRENT_DIR, \"..\" ,\"data\", \"training_results\", \"ROC_AUC_CV_xgboost_ESM1b_ECFP.npy\"), np.array(ROC_AUC))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "144.90977870753588"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "np.mean([145.78749933523534, 143.24696900455865, 152.99577743836903, 142.04005688827212, 140.47859087124428])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (iv) 3. Training and validating the final model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training the model and validating it on the test set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[08:19:09] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Accuracy on test set: 0.8732035928143712, ROC-AUC score for test set: 0.9372709213592973, MCC: 0.6944703270478896\n"
     ]
    }
   ],
   "source": [
    "dtrain = xgb.DMatrix(np.array(train_X), weight = weights, label = np.array(train_y),\n",
    "                feature_names= feature_names)\n",
    "dtest = xgb.DMatrix(np.array(test_X), label = np.array(test_y),\n",
    "                    feature_names= feature_names)\n",
    "\n",
    "bst = xgb.train(param,  dtrain, int(num_round), verbose_eval=1)\n",
    "y_test_pred = np.round(bst.predict(dtest))\n",
    "acc_test = np.mean(y_test_pred == np.array(test_y))\n",
    "roc_auc = roc_auc_score(np.array(test_y), bst.predict(dtest))\n",
    "mcc = matthews_corrcoef(np.array(test_y), y_test_pred)\n",
    "\n",
    "print(\"Accuracy on test set: %s, ROC-AUC score for test set: %s, MCC: %s\"  % (acc_test, roc_auc, mcc))\n",
    "\n",
    "np.save(join(CURRENT_DIR, \"..\" ,\"data\", \"training_results\", \"y_test_pred_xgboost_ESM1b_ECFP.npy\"), bst.predict(dtest))\n",
    "np.save(join(CURRENT_DIR, \"..\" ,\"data\", \"training_results\", \"y_test_true_xgboost_ESM1b_ECFP.npy\"), test_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (b) ESM1b and GNN:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (i) Creating numpy arrays with input vectors and output variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_input_and_output_data(df):\n",
    "    X = ();\n",
    "    y = ();\n",
    "        \n",
    "    for ind in df.index:\n",
    "        emb = df[\"ESM1b\"][ind]\n",
    "        ecfp = df[\"GNN rep\"][ind]\n",
    "                \n",
    "        X = X +(np.concatenate([ecfp, emb]), );\n",
    "        y = y + (df[\"Binding\"][ind], );\n",
    "\n",
    "    return(X,y)\n",
    "\n",
    "train_X, train_y =  create_input_and_output_data(df = df_train)\n",
    "test_X, test_y =  create_input_and_output_data(df = df_test)\n",
    "\n",
    "\n",
    "feature_names =  [\"GNN rep_\" + str(i) for i in range(50)]\n",
    "feature_names = feature_names + [\"ESM1b_\" + str(i) for i in range(1280)]\n",
    "\n",
    "train_X = np.array(train_X)\n",
    "test_X  = np.array(test_X)\n",
    "\n",
    "train_y = np.array(train_y)\n",
    "test_y  = np.array(test_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (ii) Performing hyperparameter optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'hp' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_3812/3269672333.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     26\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     27\u001b[0m \u001b[1;31m#Defining search space for hyperparameter optimization\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 28\u001b[1;33m space_gradient_boosting = {\"learning_rate\": hp.uniform(\"learning_rate\", 0.01, 0.5),\n\u001b[0m\u001b[0;32m     29\u001b[0m     \u001b[1;34m\"max_depth\"\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mhp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mchoice\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"max_depth\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;36m9\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m11\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m12\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m13\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     30\u001b[0m     \u001b[1;34m\"reg_lambda\"\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mhp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0muniform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"reg_lambda\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'hp' is not defined"
     ]
    }
   ],
   "source": [
    "def cross_validation_neg_acc_gradient_boosting(param):\n",
    "    num_round = param[\"num_rounds\"]\n",
    "    param[\"tree_method\"] = \"gpu_hist\"\n",
    "    param[\"sampling_method\"] = \"gradient_based\"\n",
    "    param['objective'] = 'binary:logistic'\n",
    "    weights = np.array([param[\"weight\"] if binding == 0 else 1.0 for binding in df_train[\"Binding\"]])\n",
    "    \n",
    "    del param[\"num_rounds\"]\n",
    "    del param[\"weight\"]\n",
    "    \n",
    "    loss = []\n",
    "    for i in range(5):\n",
    "        train_index, test_index  = train_indices[i], test_indices[i]\n",
    "        dtrain = xgb.DMatrix(np.array(train_X[train_index]), weight = weights[train_index],\n",
    "                         label = np.array(train_y[train_index]))\n",
    "        dvalid = xgb.DMatrix(np.array(train_X[test_index]))\n",
    "        bst = xgb.train(param,  dtrain, int(num_round), verbose_eval=1)\n",
    "        y_valid_pred = np.round(bst.predict(dvalid))\n",
    "        validation_y = train_y[test_index]\n",
    "    \n",
    "        false_positive = 100*(1-np.mean(np.array(validation_y)[y_valid_pred == 1]))\n",
    "        false_negative = 100*(np.mean(np.array(validation_y)[y_valid_pred == 0]))\n",
    "        logging.info(\"False positive rate: \" + str(false_positive)+ \"; False negative rate: \" + str(false_negative))\n",
    "        loss.append(2*(false_negative**2) + false_positive**1.3)\n",
    "    return(np.mean(loss))\n",
    "\n",
    "#Defining search space for hyperparameter optimization\n",
    "space_gradient_boosting = {\"learning_rate\": hp.uniform(\"learning_rate\", 0.01, 0.5),\n",
    "    \"max_depth\": hp.choice(\"max_depth\", [9,10,11,12,13]),\n",
    "    \"reg_lambda\": hp.uniform(\"reg_lambda\", 0, 5),\n",
    "    \"reg_alpha\": hp.uniform(\"reg_alpha\", 0, 5),\n",
    "    \"max_delta_step\": hp.uniform(\"max_delta_step\", 0, 5),\n",
    "    \"min_child_weight\": hp.uniform(\"min_child_weight\", 0.1, 15),\n",
    "    \"num_rounds\":  hp.uniform(\"num_rounds\", 200, 400),\n",
    "    \"weight\" : hp.uniform(\"weight\", 0.1,0.33)}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Performing a random grid search:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''trials = Trials()\n",
    "\n",
    "for i in range(1,2000):\n",
    "    best = fmin(fn = cross_validation_neg_acc_gradient_boosting, space = space_gradient_boosting,\n",
    "                algo = rand.suggest, max_evals = i, trials = trials)\n",
    "    np.save(join(CURRENT_DIR, \"..\" ,\"data\", \"results\", \"cross_validation_binding_ESM1b.npy\"), trials.best_trial)\n",
    "    np.save(join(CURRENT_DIR, \"..\" ,\"data\", \"results\", \"cross_validation_binding_ESM1b_argmin.npy\"), trials.argmin)\n",
    "    logging.info(i)\n",
    "    logging.info(trials.best_trial[\"result\"][\"loss\"])\n",
    "    logging.info(trials.argmin)''';"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Best set of hyperparameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "param = {'learning_rate': 0.18650490181254992,\n",
    "         'max_delta_step': 3.747845574621026,\n",
    "         'max_depth': 10,\n",
    "         'min_child_weight': 0.3985828341503377,\n",
    "         'num_rounds': 366.6289439088624,\n",
    "         'reg_alpha': 0.8924081775198611,\n",
    "         'reg_lambda': 4.888409483879253, \n",
    "         'weight': 0.14249550342115477}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (iii) Repeating 5-fold CV for best set of hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_round = param[\"num_rounds\"]\n",
    "param[\"tree_method\"] = \"gpu_hist\"\n",
    "param[\"sampling_method\"] = \"gradient_based\"\n",
    "param['objective'] = 'binary:logistic'\n",
    "weights = np.array([param[\"weight\"] if binding == 0 else 1.0 for binding in df_train[\"Binding\"]])\n",
    "\n",
    "del param[\"num_rounds\"]\n",
    "del param[\"weight\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13:13:08] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[13:15:32] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[13:17:57] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[13:20:21] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[14:52:12] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Loss values: [127.93542431344466, 122.79501284863223, 132.211203999234, 126.27687643490749, 131.02385081797956]\n",
      "Accuracies: [0.9080177971488241, 0.9076071922544952, 0.906319241336524, 0.9075287865367582, 0.9075296031817771]\n",
      "ROC-AUC scores: [0.9481174271320283, 0.9501233965053054, 0.9437746666563114, 0.9507466012024709, 0.9510292058347031]\n"
     ]
    }
   ],
   "source": [
    "loss = []\n",
    "accuracy = []\n",
    "ROC_AUC = []\n",
    "\n",
    "for i in range(5):\n",
    "    train_index, test_index  = train_indices[i], test_indices[i]\n",
    "    dtrain = xgb.DMatrix(np.array(train_X[train_index]), weight = weights[train_index],\n",
    "                     label = np.array(train_y[train_index]))\n",
    "    dvalid = xgb.DMatrix(np.array(train_X[test_index]))\n",
    "    bst = xgb.train(param,  dtrain, int(num_round), verbose_eval=1)\n",
    "    y_valid_pred = np.round(bst.predict(dvalid))\n",
    "    validation_y = train_y[test_index]\n",
    "\n",
    "    #calculate loss:\n",
    "    false_positive = 100*(1-np.mean(np.array(validation_y)[y_valid_pred == 1]))\n",
    "    false_negative = 100*(np.mean(np.array(validation_y)[y_valid_pred == 0]))\n",
    "    logging.info(\"False positive rate: \" + str(false_positive)+ \"; False negative rate: \" + str(false_negative))\n",
    "    loss.append(2*(false_negative**2) + false_positive**1.3)\n",
    "    #calculate accuracy:\n",
    "    accuracy.append(np.mean(y_valid_pred == np.array(validation_y)))\n",
    "    #calculate ROC-AUC score:\n",
    "    ROC_AUC.append(roc_auc_score(np.array(validation_y), bst.predict(dvalid)))\n",
    "    \n",
    "print(\"Loss values: %s\" %loss) \n",
    "print(\"Accuracies: %s\" %accuracy)\n",
    "print(\"ROC-AUC scores: %s\" %ROC_AUC)\n",
    "\n",
    "np.save(join(CURRENT_DIR, \"..\" ,\"data\", \"training_results\", \"acc_CV_xgboost_ESM1b_GNN.npy\"), np.array(accuracy))\n",
    "np.save(join(CURRENT_DIR, \"..\" ,\"data\", \"training_results\", \"loss_CV_xgboost_ESM1b_GNN.npy\"), np.array(loss))\n",
    "np.save(join(CURRENT_DIR, \"..\" ,\"data\", \"training_results\", \"ROC_AUC_CV_xgboost_ESM1b_GNN.npy\"), np.array(ROC_AUC))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "128.04847368283959"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean([127.93542431344466, 122.79501284863223, 132.211203999234, 126.27687643490749, 131.02385081797956])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (iv) 3. Training and validating the final model\n",
    "Training the model and validating it on the test set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:54:35] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Accuracy on test set: 0.9051646706586827, ROC-AUC score for test set: 0.9455840254566843, MCC: 0.7509981408842288\n"
     ]
    }
   ],
   "source": [
    "dtrain = xgb.DMatrix(np.array(train_X), weight = weights, label = np.array(train_y),\n",
    "                feature_names= feature_names)\n",
    "dtest = xgb.DMatrix(np.array(test_X), label = np.array(test_y),\n",
    "                    feature_names= feature_names)\n",
    "\n",
    "bst = xgb.train(param,  dtrain, int(num_round), verbose_eval=1)\n",
    "y_test_pred = np.round(bst.predict(dtest))\n",
    "acc_test = np.mean(y_test_pred == np.array(test_y))\n",
    "roc_auc = roc_auc_score(np.array(test_y), bst.predict(dtest))\n",
    "mcc = matthews_corrcoef(np.array(test_y), y_test_pred)\n",
    "\n",
    "print(\"Accuracy on test set: %s, ROC-AUC score for test set: %s, MCC: %s\"  % (acc_test, roc_auc, mcc))\n",
    "\n",
    "np.save(join(CURRENT_DIR, \"..\" ,\"data\", \"training_results\", \"y_test_pred_xgboost_ESM1b_GNN.npy\"), bst.predict(dtest))\n",
    "np.save(join(CURRENT_DIR, \"..\" ,\"data\", \"training_results\", \"y_test_true_xgboost_ESM1b_GNN.npy\"), test_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (c) ESM1b_ts and ECFP:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (i) Creating numpy arrays with input vectors and output variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_input_and_output_data(df):\n",
    "    X = ();\n",
    "    y = ();\n",
    "    \n",
    "    for ind in df.index:\n",
    "        emb = df[\"ESM1b_ts\"][ind]\n",
    "        ecfp = np.array(list(df[\"ECFP\"][ind])).astype(int)\n",
    "                \n",
    "        X = X +(np.concatenate([ecfp, emb]), );\n",
    "        y = y + (df[\"Binding\"][ind], );\n",
    "\n",
    "    return(X,y)\n",
    "\n",
    "train_X, train_y =  create_input_and_output_data(df = df_train)\n",
    "test_X, test_y =  create_input_and_output_data(df = df_test)\n",
    "\n",
    "\n",
    "feature_names =  [\"ECFP_\" + str(i) for i in range(1024)]\n",
    "feature_names = feature_names + [\"ESM1b_ts_\" + str(i) for i in range(1280)]\n",
    "\n",
    "train_X = np.array(train_X)\n",
    "test_X  = np.array(test_X)\n",
    "\n",
    "train_y = np.array(train_y)\n",
    "test_y  = np.array(test_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (ii) Performing hyperparameter optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_validation_neg_acc_gradient_boosting(param):\n",
    "    num_round = param[\"num_rounds\"]\n",
    "    param[\"tree_method\"] = \"gpu_hist\"\n",
    "    param[\"sampling_method\"] = \"gradient_based\"\n",
    "    param['objective'] = 'binary:logistic'\n",
    "    weights = np.array([param[\"weight\"] if binding == 0 else 1.0 for binding in df_train[\"Binding\"]])\n",
    "    \n",
    "    del param[\"num_rounds\"]\n",
    "    del param[\"weight\"]\n",
    "    \n",
    "    loss = []\n",
    "    for i in range(5):\n",
    "        train_index, test_index  = train_indices[i], test_indices[i]\n",
    "        dtrain = xgb.DMatrix(np.array(train_X[train_index]), weight = weights[train_index],\n",
    "                         label = np.array(train_y[train_index]))\n",
    "        dvalid = xgb.DMatrix(np.array(train_X[test_index]))\n",
    "        bst = xgb.train(param,  dtrain, int(num_round), verbose_eval=1)\n",
    "        y_valid_pred = np.round(bst.predict(dvalid))\n",
    "        validation_y = train_y[test_index]\n",
    "    \n",
    "        false_positive = 100*(1-np.mean(np.array(validation_y)[y_valid_pred == 1]))\n",
    "        false_negative = 100*(np.mean(np.array(validation_y)[y_valid_pred == 0]))\n",
    "        logging.info(\"False positive rate: \" + str(false_positive)+ \"; False negative rate: \" + str(false_negative))\n",
    "        loss.append(2*(false_negative**2) + false_positive**1.3)\n",
    "    return(np.mean(loss))\n",
    "\n",
    "#Defining search space for hyperparameter optimization\n",
    "space_gradient_boosting = {\"learning_rate\": hp.uniform(\"learning_rate\", 0.01, 0.5),\n",
    "                            \"max_depth\": hp.choice(\"max_depth\", [9,10,11,12,13]),\n",
    "                            \"reg_lambda\": hp.uniform(\"reg_lambda\", 0, 5),\n",
    "                            \"reg_alpha\": hp.uniform(\"reg_alpha\", 0, 5),\n",
    "                            \"max_delta_step\": hp.uniform(\"max_delta_step\", 0, 5),\n",
    "                            \"min_child_weight\": hp.uniform(\"min_child_weight\", 0.1, 15),\n",
    "                            \"num_rounds\":  hp.uniform(\"num_rounds\", 200, 400),\n",
    "                            \"weight\" : hp.uniform(\"weight\", 0.1,0.33)}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Performing a random grid search:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''trials = Trials()\n",
    "\n",
    "for i in range(1,2000):\n",
    "    best = fmin(fn = cross_validation_neg_acc_gradient_boosting, space = space_gradient_boosting,\n",
    "                algo = rand.suggest, max_evals = i, trials = trials)\n",
    "    np.save(join(CURRENT_DIR, \"..\" ,\"data\", \"results\", \"cross_validation_binding_ESM1b.npy\"), trials.best_trial)\n",
    "    np.save(join(CURRENT_DIR, \"..\" ,\"data\", \"results\", \"cross_validation_binding_ESM1b_argmin.npy\"), trials.argmin)\n",
    "    logging.info(i)\n",
    "    logging.info(trials.best_trial[\"result\"][\"loss\"])\n",
    "    logging.info(trials.argmin)''';"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Best set of hyperparameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "param = {'learning_rate': 0.31553117247348733,\n",
    "         'max_delta_step': 1.7726044219753656,\n",
    "         'max_depth': 10,\n",
    "         'min_child_weight': 1.3845040588450772,\n",
    "         'num_rounds': 342.68325188584106,\n",
    "         'reg_alpha': 0.531395259755843,\n",
    "         'reg_lambda': 3.744980563764689,\n",
    "         'weight': 0.26187490421514203}\n",
    "\n",
    "num_round = param[\"num_rounds\"]\n",
    "param[\"tree_method\"] = \"gpu_hist\"\n",
    "param[\"sampling_method\"] = \"gradient_based\"\n",
    "param['objective'] = 'binary:logistic'\n",
    "weights = np.array([param[\"weight\"] if binding == 0 else 1.0 for binding in df_train[\"Binding\"]])\n",
    "\n",
    "del param[\"num_rounds\"]\n",
    "del param[\"weight\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (iii) Repeating 5-fold CV for best set of hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:57:59] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[15:00:12] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[15:02:28] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[15:04:38] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[15:06:53] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Loss values: [118.64570140259957, 109.55544934268875, 136.58107225995332, 112.14992450710591, 116.58008809267714]\n",
      "Accuracies: [0.9095614274039772, 0.9113877362840018, 0.8988744128334663, 0.9105403011514615, 0.9075296031817771]\n",
      "ROC-AUC scores: [0.9531463757576579, 0.9543092505120799, 0.9443616020172131, 0.9560860893869755, 0.9515226897235054]\n"
     ]
    }
   ],
   "source": [
    "loss = []\n",
    "accuracy = []\n",
    "ROC_AUC = []\n",
    "\n",
    "for i in range(5):\n",
    "    train_index, test_index  = train_indices[i], test_indices[i]\n",
    "    dtrain = xgb.DMatrix(np.array(train_X[train_index]), weight = weights[train_index],\n",
    "                     label = np.array(train_y[train_index]))\n",
    "    dvalid = xgb.DMatrix(np.array(train_X[test_index]))\n",
    "    bst = xgb.train(param,  dtrain, int(num_round), verbose_eval=1)\n",
    "    y_valid_pred = np.round(bst.predict(dvalid))\n",
    "    validation_y = train_y[test_index]\n",
    "\n",
    "    #calculate loss:\n",
    "    false_positive = 100*(1-np.mean(np.array(validation_y)[y_valid_pred == 1]))\n",
    "    false_negative = 100*(np.mean(np.array(validation_y)[y_valid_pred == 0]))\n",
    "    logging.info(\"False positive rate: \" + str(false_positive)+ \"; False negative rate: \" + str(false_negative))\n",
    "    loss.append(2*(false_negative**2) + false_positive**1.3)\n",
    "    #calculate accuracy:\n",
    "    accuracy.append(np.mean(y_valid_pred == np.array(validation_y)))\n",
    "    #calculate ROC-AUC score:\n",
    "    ROC_AUC.append(roc_auc_score(np.array(validation_y), bst.predict(dvalid)))\n",
    "    \n",
    "print(\"Loss values: %s\" %loss) \n",
    "print(\"Accuracies: %s\" %accuracy)\n",
    "print(\"ROC-AUC scores: %s\" %ROC_AUC)\n",
    "\n",
    "np.save(join(CURRENT_DIR, \"..\" ,\"data\", \"training_results\", \"acc_CV_xgboost_ESM1b_ts_ECFP.npy\"), np.array(accuracy))\n",
    "np.save(join(CURRENT_DIR, \"..\" ,\"data\", \"training_results\", \"loss_CV_xgboost_ESM1b_ts_ECFP.npy\"), np.array(loss))\n",
    "np.save(join(CURRENT_DIR, \"..\" ,\"data\", \"training_results\", \"ROC_AUC_CV_xgboost_ESM1b_ts_ECFP.npy\"), np.array(ROC_AUC))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "118.70244712100494"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean([118.64570140259957, 109.55544934268875, 136.58107225995332, 112.14992450710591, 116.58008809267714])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (iv) 3. Training and validating the final model\n",
    "Training the model and validating it on the test set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15:09:04] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Accuracy on test set: 0.9063622754491018, ROC-AUC score for test set: 0.9499652082794869, MCC: 0.7594154904873446\n"
     ]
    }
   ],
   "source": [
    "dtrain = xgb.DMatrix(np.array(train_X), weight = weights, label = np.array(train_y),\n",
    "                feature_names= feature_names)\n",
    "dtest = xgb.DMatrix(np.array(test_X), label = np.array(test_y),\n",
    "                    feature_names= feature_names)\n",
    "\n",
    "bst = xgb.train(param,  dtrain, int(num_round), verbose_eval=1)\n",
    "y_test_pred = np.round(bst.predict(dtest))\n",
    "acc_test = np.mean(y_test_pred == np.array(test_y))\n",
    "roc_auc = roc_auc_score(np.array(test_y), bst.predict(dtest))\n",
    "mcc = matthews_corrcoef(np.array(test_y), y_test_pred)\n",
    "\n",
    "print(\"Accuracy on test set: %s, ROC-AUC score for test set: %s, MCC: %s\"  % (acc_test, roc_auc, mcc))\n",
    "\n",
    "np.save(join(CURRENT_DIR, \"..\" ,\"data\", \"training_results\", \"y_test_pred_xgboost_ESM1b_ts_ECFP.npy\"), bst.predict(dtest))\n",
    "np.save(join(CURRENT_DIR, \"..\" ,\"data\", \"training_results\", \"y_test_true_xgboost_ESM1b_ts_ECFP.npy\"), test_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (d) ESM1b_ts and GNN:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (i) Creating numpy arrays with input vectors and output variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_input_and_output_data(df):\n",
    "    X = ();\n",
    "    y = ();\n",
    "    \n",
    "    for ind in df.index:\n",
    "        emb = df[\"ESM1b_ts\"][ind]\n",
    "        ecfp = df[\"GNN rep\"][ind]\n",
    "                \n",
    "        X = X +(np.concatenate([ecfp, emb]), );\n",
    "        y = y + (df[\"Binding\"][ind], );\n",
    "\n",
    "    return(X,y)\n",
    "\n",
    "train_X, train_y =  create_input_and_output_data(df = df_train)\n",
    "test_X, test_y =  create_input_and_output_data(df = df_test)\n",
    "\n",
    "\n",
    "feature_names =  [\"GNN rep_\" + str(i) for i in range(50)]\n",
    "feature_names = feature_names + [\"ESM1b_\" + str(i) for i in range(1280)]\n",
    "\n",
    "train_X = np.array(train_X)\n",
    "test_X  = np.array(test_X)\n",
    "\n",
    "train_y = np.array(train_y)\n",
    "test_y  = np.array(test_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (ii) Performing hyperparameter optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'hp' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_7960/3269672333.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     26\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     27\u001b[0m \u001b[1;31m#Defining search space for hyperparameter optimization\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 28\u001b[1;33m space_gradient_boosting = {\"learning_rate\": hp.uniform(\"learning_rate\", 0.01, 0.5),\n\u001b[0m\u001b[0;32m     29\u001b[0m     \u001b[1;34m\"max_depth\"\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mhp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mchoice\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"max_depth\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;36m9\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m11\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m12\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m13\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     30\u001b[0m     \u001b[1;34m\"reg_lambda\"\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mhp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0muniform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"reg_lambda\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'hp' is not defined"
     ]
    }
   ],
   "source": [
    "def cross_validation_neg_acc_gradient_boosting(param):\n",
    "    num_round = param[\"num_rounds\"]\n",
    "    param[\"tree_method\"] = \"gpu_hist\"\n",
    "    param[\"sampling_method\"] = \"gradient_based\"\n",
    "    param['objective'] = 'binary:logistic'\n",
    "    weights = np.array([param[\"weight\"] if binding == 0 else 1.0 for binding in df_train[\"Binding\"]])\n",
    "    \n",
    "    del param[\"num_rounds\"]\n",
    "    del param[\"weight\"]\n",
    "    \n",
    "    loss = []\n",
    "    for i in range(5):\n",
    "        train_index, test_index  = train_indices[i], test_indices[i]\n",
    "        dtrain = xgb.DMatrix(np.array(train_X[train_index]), weight = weights[train_index],\n",
    "                         label = np.array(train_y[train_index]))\n",
    "        dvalid = xgb.DMatrix(np.array(train_X[test_index]))\n",
    "        bst = xgb.train(param,  dtrain, int(num_round), verbose_eval=1)\n",
    "        y_valid_pred = np.round(bst.predict(dvalid))\n",
    "        validation_y = train_y[test_index]\n",
    "    \n",
    "        false_positive = 100*(1-np.mean(np.array(validation_y)[y_valid_pred == 1]))\n",
    "        false_negative = 100*(np.mean(np.array(validation_y)[y_valid_pred == 0]))\n",
    "        logging.info(\"False positive rate: \" + str(false_positive)+ \"; False negative rate: \" + str(false_negative))\n",
    "        loss.append(2*(false_negative**2) + false_positive**1.3)\n",
    "    return(np.mean(loss))\n",
    "\n",
    "#Defining search space for hyperparameter optimization\n",
    "space_gradient_boosting = {\"learning_rate\": hp.uniform(\"learning_rate\", 0.01, 0.5),\n",
    "    \"max_depth\": hp.choice(\"max_depth\", [9,10,11,12,13]),\n",
    "    \"reg_lambda\": hp.uniform(\"reg_lambda\", 0, 5),\n",
    "    \"reg_alpha\": hp.uniform(\"reg_alpha\", 0, 5),\n",
    "    \"max_delta_step\": hp.uniform(\"max_delta_step\", 0, 5),\n",
    "    \"min_child_weight\": hp.uniform(\"min_child_weight\", 0.1, 15),\n",
    "    \"num_rounds\":  hp.uniform(\"num_rounds\", 200, 400),\n",
    "    \"weight\" : hp.uniform(\"weight\", 0.1,0.33)}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Performing a random grid search:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''trials = Trials()\n",
    "\n",
    "for i in range(1,2000):\n",
    "    best = fmin(fn = cross_validation_neg_acc_gradient_boosting, space = space_gradient_boosting,\n",
    "                algo = rand.suggest, max_evals = i, trials = trials)\n",
    "    np.save(join(CURRENT_DIR, \"..\" ,\"data\", \"results\", \"cross_validation_binding_ESM1b.npy\"), trials.best_trial)\n",
    "    np.save(join(CURRENT_DIR, \"..\" ,\"data\", \"results\", \"cross_validation_binding_ESM1b_argmin.npy\"), trials.argmin)\n",
    "    logging.info(i)\n",
    "    logging.info(trials.best_trial[\"result\"][\"loss\"])\n",
    "    logging.info(trials.argmin)''';"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Best set of hyperparameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "param = {'learning_rate': 0.18444025726334898,\n",
    "         'max_delta_step': 3.2748796106084117,\n",
    "         'max_depth': 13,\n",
    "         'min_child_weight': 3.1946753845027738,\n",
    "         'num_rounds': 314.1036429221291,\n",
    "         'reg_alpha': 0.48821021807600673,\n",
    "         'reg_lambda': 2.6236829011598073,\n",
    "         'weight': 0.1264521266931227}\n",
    "\n",
    "num_round = param[\"num_rounds\"]\n",
    "param[\"tree_method\"] = \"gpu_hist\"\n",
    "param[\"sampling_method\"] = \"gradient_based\"\n",
    "param['objective'] = 'binary:logistic'\n",
    "weights = np.array([param[\"weight\"] if binding == 0 else 1.0 for binding in df_train[\"Binding\"]])\n",
    "\n",
    "del param[\"num_rounds\"]\n",
    "del param[\"weight\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (iii) Repeating 5-fold CV for best set of hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15:11:47] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[15:13:04] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[15:14:22] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[15:15:41] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[15:16:57] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Loss values: [107.10779217320857, 97.97889476323061, 117.6449558838506, 92.98319474363471, 102.69988687285533]\n",
      "Accuracies: [0.9046581312993734, 0.9083448593822038, 0.90064699104848, 0.9066430469441984, 0.9074392117870379]\n",
      "ROC-AUC scores: [0.9584373172944172, 0.9558062039027504, 0.9500524479937247, 0.9617684224032785, 0.9569448004040885]\n"
     ]
    }
   ],
   "source": [
    "loss = []\n",
    "accuracy = []\n",
    "ROC_AUC = []\n",
    "\n",
    "for i in range(5):\n",
    "    train_index, test_index  = train_indices[i], test_indices[i]\n",
    "    dtrain = xgb.DMatrix(np.array(train_X[train_index]), weight = weights[train_index],\n",
    "                     label = np.array(train_y[train_index]))\n",
    "    dvalid = xgb.DMatrix(np.array(train_X[test_index]))\n",
    "    bst = xgb.train(param,  dtrain, int(num_round), verbose_eval=1)\n",
    "    y_valid_pred = np.round(bst.predict(dvalid))\n",
    "    validation_y = train_y[test_index]\n",
    "\n",
    "    #calculate loss:\n",
    "    false_positive = 100*(1-np.mean(np.array(validation_y)[y_valid_pred == 1]))\n",
    "    false_negative = 100*(np.mean(np.array(validation_y)[y_valid_pred == 0]))\n",
    "    logging.info(\"False positive rate: \" + str(false_positive)+ \"; False negative rate: \" + str(false_negative))\n",
    "    loss.append(2*(false_negative**2) + false_positive**1.3)\n",
    "    #calculate accuracy:\n",
    "    accuracy.append(np.mean(y_valid_pred == np.array(validation_y)))\n",
    "    #calculate ROC-AUC score:\n",
    "    ROC_AUC.append(roc_auc_score(np.array(validation_y), bst.predict(dvalid)))\n",
    "    \n",
    "print(\"Loss values: %s\" %loss) \n",
    "print(\"Accuracies: %s\" %accuracy)\n",
    "print(\"ROC-AUC scores: %s\" %ROC_AUC)\n",
    "\n",
    "np.save(join(CURRENT_DIR, \"..\" ,\"data\", \"training_results\", \"acc_CV_xgboost_ESM1b_ts_GNN.npy\"), np.array(accuracy))\n",
    "np.save(join(CURRENT_DIR, \"..\" ,\"data\", \"training_results\", \"loss_CV_xgboost_ESM1b_ts_GNN.npy\"), np.array(loss))\n",
    "np.save(join(CURRENT_DIR, \"..\" ,\"data\", \"training_results\", \"ROC_AUC_CV_xgboost_ESM1b_ts_GNN.npy\"), np.array(ROC_AUC))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "103.68294488735596"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean([107.10779217320857, 97.97889476323061, 117.6449558838506, 92.98319474363471, 102.69988687285533])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (iv) 3. Training and validating the final model\n",
    "Training the model and validating it on the test set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15:18:15] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Accuracy on test set: 0.9028443113772455, ROC-AUC score for test set: 0.9540429057244825, MCC: 0.7544314356676812\n"
     ]
    }
   ],
   "source": [
    "dtrain = xgb.DMatrix(np.array(train_X), weight = weights, label = np.array(train_y),\n",
    "                feature_names= feature_names)\n",
    "dtest = xgb.DMatrix(np.array(test_X), label = np.array(test_y),\n",
    "                    feature_names= feature_names)\n",
    "\n",
    "bst = xgb.train(param,  dtrain, int(num_round), verbose_eval=1)\n",
    "y_test_pred = np.round(bst.predict(dtest))\n",
    "acc_test = np.mean(y_test_pred == np.array(test_y))\n",
    "roc_auc = roc_auc_score(np.array(test_y), bst.predict(dtest))\n",
    "mcc = matthews_corrcoef(np.array(test_y), y_test_pred)\n",
    "\n",
    "print(\"Accuracy on test set: %s, ROC-AUC score for test set: %s, MCC: %s\"  % (acc_test, roc_auc, mcc))\n",
    "\n",
    "np.save(join(CURRENT_DIR, \"..\" ,\"data\", \"training_results\", \"y_test_pred_xgboost_ESM1b_ts_GNN.npy\"), bst.predict(dtest))\n",
    "np.save(join(CURRENT_DIR, \"..\" ,\"data\", \"training_results\", \"y_test_true_xgboost_ESM1b_ts_GNN.npy\"), test_y)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
