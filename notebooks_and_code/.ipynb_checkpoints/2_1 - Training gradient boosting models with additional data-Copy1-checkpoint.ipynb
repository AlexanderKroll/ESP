{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training gradient boosting model for enzyme-substrate pair prediction with ESM-1b-vectors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Loading and preprocessing data for model training and evaluation\n",
    "### 2. Hyperparameter optimization using a 5-fold cross-validation (CV)\n",
    "### 3. Training and validating the final model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\alexk\\projects\\SubFinder\\notebooks_and_code\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import pickle\n",
    "import sys\n",
    "import os\n",
    "import logging\n",
    "from os.path import join\n",
    "from sklearn.model_selection import KFold\n",
    "#from hyperopt import fmin, tpe, hp, Trials, rand\n",
    "import xgboost as xgb\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "sys.path.append('.\\\\additional_code')\n",
    "#from data_preprocessing import *\n",
    "\n",
    "CURRENT_DIR = os.getcwd()\n",
    "print(CURRENT_DIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Loading and preprocessing data for model training and evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (a) Loading data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\alexk\\anaconda3\\envs\\Protein\\lib\\site-packages\\pandas\\core\\ops\\array_ops.py:56: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  result = libops.scalar_compare(x.ravel(), y, op)\n",
      "C:\\Users\\alexk\\anaconda3\\envs\\Protein\\lib\\site-packages\\pandas\\core\\ops\\array_ops.py:56: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  result = libops.scalar_compare(x.ravel(), y, op)\n"
     ]
    }
   ],
   "source": [
    "df_train = pd.read_pickle(join(CURRENT_DIR, \"..\" ,\"data\",\"splits\", \"df_train_with_EC1_1_3_15_with_ESM1b_ts_GNN_V2.pkl\"))\n",
    "df_train = df_train.loc[df_train[\"ESM1b_ts\"] != \"\"]\n",
    "df_train = df_train.loc[df_train[\"GNN rep\"] != \"\"]\n",
    "\n",
    "df_train.reset_index(inplace = True, drop = True)\n",
    "\n",
    "df_test  = pd.read_pickle(join(CURRENT_DIR, \"..\" ,\"data\",\"splits\", \"df_test_with_EC1_1_3_15_with_ESM1b_ts_GNN_V2.pkl\"))\n",
    "df_test = df_test.loc[df_test[\"ESM1b_ts\"] != \"\"]\n",
    "df_test = df_test.loc[df_test[\"GNN rep\"] != \"\"]\n",
    "df_test.reset_index(inplace = True, drop = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading new dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test_new = pd.read_pickle(join(CURRENT_DIR, \"..\" ,\"data\", \"splits\", \"df_EC1_1_3_15_with_enzyme_reps_GNN_V2.pkl\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Randomly sample 10 enzymes that will be part of the training set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_input_and_output_data(df):\n",
    "    X = ();\n",
    "    y = ();\n",
    "    \n",
    "    for ind in df.index:\n",
    "        emb = df[\"ESM1b_ts\"][ind]\n",
    "        ecfp = np.array(list(df[\"ECFP\"][ind])).astype(int)\n",
    "                \n",
    "        X = X +(np.concatenate([ecfp, emb]), );\n",
    "        y = y + (df[\"Binding\"][ind], );\n",
    "\n",
    "    return(np.array(X),np.array(y))\n",
    "\n",
    "feature_names =  [\"ECFP_\" + str(i) for i in range(1024)]\n",
    "feature_names = feature_names + [\"ESM1b_ts_\" + str(i) for i in range(1280)]\n",
    "\n",
    "#import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\alexk\\anaconda3\\envs\\Protein\\lib\\site-packages\\pandas\\core\\ops\\array_ops.py:56: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  result = libops.scalar_compare(x.ravel(), y, op)\n"
     ]
    }
   ],
   "source": [
    "new_enzymes =  list(set(df_test_new[\"Uniprot ID\"]))\n",
    "random.seed(2)\n",
    "random.shuffle(new_enzymes)\n",
    "enzyme_folds = []\n",
    "\n",
    "#enzyme_folds = [new_enzymes[0:5], new_enzymes[5:10], new_enzymes[10:15], new_enzymes[15:]]\n",
    "enzyme_folds =[[\"A0A011QK89\", \"A0A087D1R1\", \"R0EVG9\",'B1HZY7', 'C2K1F0',\"A4YVE0\"],\n",
    "                [\"A0A0U6K8E5\", \"C9Y9E7\",\"A4YVE0\",\"E6SCX5\",\"B7N6P4\", 'B8MKR3'],\n",
    "                ['Q5WIP4', 'A0A087RXW1', \"A9QH69\", 'B7RR92' , \"E6SCX5\"],\n",
    "                [\"A0A077SBA9\", \"D4MUV9\", \"C4VMW0\", \"S2DJ52\", \"D4N087\"]]\n",
    "\n",
    "for i in range(4):\n",
    "    test_enzymes = enzyme_folds[i]\n",
    "\n",
    "    df_train = pd.read_pickle(join(CURRENT_DIR, \"..\" ,\"data\",\n",
    "                                   \"splits\", \"df_train_with_EC1_1_3_15_with_ESM1b_ts_GNN_V2.pkl\"))\n",
    "    df_train = df_train.loc[df_train[\"ESM1b_ts\"] != \"\"]\n",
    "    df_train.reset_index(inplace = True, drop = True)\n",
    "\n",
    "\n",
    "    df_train = df_train.loc[~df_train[\"Uniprot ID\"].isin(test_enzymes)]\n",
    "    \n",
    "    \n",
    "    train_X, train_y =  create_input_and_output_data(df = df_train)\n",
    "    test_X, test_y =  create_input_and_output_data(df = df_test)\n",
    "    test_new_X, test_new_y =  create_input_and_output_data(df = df_test_new)\n",
    "    \n",
    "    \n",
    "    param = {'learning_rate': 0.21593894516312712,\n",
    "             'max_delta_step': 2.3197168781549893,\n",
    "             'max_depth': 12,\n",
    "              'min_child_weight': 0.6315847279633628,\n",
    "               'num_rounds': 396.91340133372364, \n",
    "               'reg_alpha': 0.30340726745680807, \n",
    "               'reg_lambda': 1.1575318518353965, \n",
    "               'weight': 0.11364941242322603}\n",
    "    \n",
    "    param =  {'learning_rate': 0.2450500663744065,\n",
    "         'max_delta_step': 2.382647656857187,\n",
    "         'max_depth': 11,\n",
    "         'min_child_weight': 1.222014993565574, \n",
    "         'num_rounds': 379.3863424395678,\n",
    "         'reg_alpha': 1.7242896864948025,\n",
    "         'reg_lambda': 2.845463948389928,\n",
    "         'weight': 0.10896532373464474}\n",
    "\n",
    "    num_round = param[\"num_rounds\"]\n",
    "    param[\"tree_method\"] = \"gpu_hist\"\n",
    "    param[\"sampling_method\"] = \"gradient_based\"\n",
    "    param['objective'] = 'binary:logistic'\n",
    "    weights = np.array([param[\"weight\"] if binding == 0 else 1.0 for binding in df_train[\"Binding\"]])\n",
    "    #weights = [weights[i]*5 if dtype ==\"engqvist\" else weights[i] for i, dtype in enumerate(df_train[\"type\"])]\n",
    "\n",
    "    del param[\"num_rounds\"]\n",
    "    del param[\"weight\"]\n",
    "    \n",
    "    dtrain = xgb.DMatrix(np.array(train_X), weight = weights, label = np.array(train_y),\n",
    "                feature_names= feature_names)\n",
    "    dtest = xgb.DMatrix(np.array(test_X), label = np.array(test_y),\n",
    "                        feature_names= feature_names)\n",
    "\n",
    "    bst = xgb.train(param,  dtrain, int(num_round), verbose_eval=1)\n",
    "    y_test_pred = np.round(bst.predict(dtest))\n",
    "    acc_test = np.mean(y_test_pred == np.array(test_y))\n",
    "    roc_auc = roc_auc_score(np.array(test_y), bst.predict(dtest))\n",
    "\n",
    "    print(\"Accuracy on test set: %s, ROC-AUC score for test set: %s\"  % (acc_test, roc_auc))\n",
    "    \n",
    "    dtest_new = xgb.DMatrix(np.array(test_new_X), label = np.array(test_new_y),\n",
    "                    feature_names= feature_names)\n",
    "\n",
    "    y_test_new_pred = np.round(bst.predict(dtest_new))\n",
    "    acc_test_new = np.mean(y_test_new_pred == np.array(test_new_y))\n",
    "    roc_auc_new = roc_auc_score(np.array(test_new_y), bst.predict(dtest_new))\n",
    "\n",
    "    print(\"All enzymes:\")\n",
    "    print(\"Accuracy on test set: %s, ROC-AUC score for test set: %s\"  % (acc_test_new, roc_auc_new))\n",
    "    \n",
    "    df_test_new_test = df_test_new.loc[df_test_new[\"Uniprot ID\"].isin(test_enzymes)]\n",
    "    test_new_X2, test_new_y2 =  create_input_and_output_data(df = df_test_new_test)\n",
    "    test_new_X2  = np.array(test_new_X2)\n",
    "    test_new_y2  = np.array(test_new_y2)\n",
    "\n",
    "    dtest_new = xgb.DMatrix(np.array(test_new_X2), label = np.array(test_new_y2),\n",
    "                        feature_names= feature_names)\n",
    "    y_test_new_pred = np.round(bst.predict(dtest_new))\n",
    "    acc_test_new = np.mean(y_test_new_pred == np.array(test_new_y2))\n",
    "    roc_auc_new = roc_auc_score(np.array(test_new_y2), bst.predict(dtest_new))\n",
    "\n",
    "    print(\"Enzymes not in training set:\")\n",
    "    print(\"Accuracy on test set: %s, ROC-AUC score for test set: %s\"  % (acc_test_new, roc_auc_new))\n",
    "    for i, enz in enumerate(test_enzymes):\n",
    "        acc = np.mean(y_test_new_pred[i*6: (i+1)*6] == np.array(test_new_y2)[i*6: (i+1)*6])\n",
    "        print(enz, acc)\n",
    "    #plt.hist(bst.predict(dtest_new), bins = 20, rwidth=0.9)\n",
    "    #plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = df_train.loc[~df_train[\"Uniprot ID\"].isin(test_enzymes)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_input_and_output_data(df):\n",
    "    X = ();\n",
    "    y = ();\n",
    "    \n",
    "    for ind in df.index:\n",
    "        emb = df[\"ESM1b_ts\"][ind]\n",
    "        ecfp = np.array(list(df[\"GNN rep\"][ind])).astype(int)\n",
    "                \n",
    "        X = X +(np.concatenate([ecfp, emb]), );\n",
    "        y = y + (df[\"Binding\"][ind], );\n",
    "\n",
    "    return(X,y)\n",
    "\n",
    "train_X, train_y =  create_input_and_output_data(df = df_train)\n",
    "test_X, test_y =  create_input_and_output_data(df = df_test)\n",
    "test_new_X, test_new_y =  create_input_and_output_data(df = df_test_new)\n",
    "\n",
    "\n",
    "feature_names =  [\"GNN rep_\" + str(i) for i in range(50)]\n",
    "feature_names = feature_names + [\"ESM1b_ts_\" + str(i) for i in range(1280)]\n",
    "\n",
    "train_X = np.array(train_X)\n",
    "test_X  = np.array(test_X)\n",
    "test_new_X  = np.array(test_new_X)\n",
    "\n",
    "train_y = np.array(train_y)\n",
    "test_y  = np.array(test_y)\n",
    "test_new_y  = np.array(test_new_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (iv) 3. Training and validating the final model\n",
    "Training the model and validating it on the test set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on test set: 0.9187125748502994, ROC-AUC score for test set: 0.955980597458338\n"
     ]
    }
   ],
   "source": [
    "weight_new_data_points = 1\n",
    "\n",
    "param = {'learning_rate': 0.21593894516312712,\n",
    "         'max_delta_step': 2.3197168781549893,\n",
    "         'max_depth': 12,\n",
    "          'min_child_weight': 0.6315847279633628,\n",
    "           'num_rounds': 396.91340133372364, \n",
    "           'reg_alpha': 0.30340726745680807, \n",
    "           'reg_lambda': 1.1575318518353965, \n",
    "           'weight': 0.11364941242322603}\n",
    "\n",
    "num_round = param[\"num_rounds\"]\n",
    "param[\"tree_method\"] = \"gpu_hist\"\n",
    "param[\"sampling_method\"] = \"gradient_based\"\n",
    "param['objective'] = 'binary:logistic'\n",
    "weights = np.array([param[\"weight\"] if binding == 0 else 1.0 for binding in df_train[\"Binding\"]])\n",
    "weights = [weights[i]*weight_new_data_points if dtype ==\"engqvist\" else weights[i] for i, dtype in enumerate(df_train[\"type\"])]\n",
    "\n",
    "del param[\"num_rounds\"]\n",
    "del param[\"weight\"]\n",
    "\n",
    "dtrain = xgb.DMatrix(np.array(train_X), weight = weights, label = np.array(train_y),\n",
    "                feature_names= feature_names)\n",
    "dtest = xgb.DMatrix(np.array(test_X), label = np.array(test_y),\n",
    "                    feature_names= feature_names)\n",
    "\n",
    "bst = xgb.train(param,  dtrain, int(num_round), verbose_eval=1)\n",
    "y_test_pred = np.round(bst.predict(dtest))\n",
    "acc_test = np.mean(y_test_pred == np.array(test_y))\n",
    "roc_auc = roc_auc_score(np.array(test_y), bst.predict(dtest))\n",
    "\n",
    "print(\"Accuracy on test set: %s, ROC-AUC score for test set: %s\"  % (acc_test, roc_auc))\n",
    "\n",
    "#np.save(join(CURRENT_DIR, \"..\" ,\"data\", \"training_results\", \"y_test_pred_xgboost_ESM1b_ts_ECFP.npy\"), bst.predict(dtest))\n",
    "#np.save(join(CURRENT_DIR, \"..\" ,\"data\", \"training_results\", \"y_test_true_xgboost_ESM1b_ts_ECFP.npy\"), test_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Validation of new test set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All enzymes:\n",
      "Accuracy on test set: 0.5, ROC-AUC score for test set: 0.3832532253984316\n"
     ]
    }
   ],
   "source": [
    "dtest_new = xgb.DMatrix(np.array(test_new_X), label = np.array(test_new_y),\n",
    "                    feature_names= feature_names)\n",
    "\n",
    "y_test_new_pred = np.round(bst.predict(dtest_new))\n",
    "acc_test_new = np.mean(y_test_new_pred == np.array(test_new_y))\n",
    "roc_auc_new = roc_auc_score(np.array(test_new_y), bst.predict(dtest_new))\n",
    "\n",
    "print(\"All enzymes:\")\n",
    "print(\"Accuracy on test set: %s, ROC-AUC score for test set: %s\"  % (acc_test_new, roc_auc_new))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enzymes not in training set:\n",
      "Accuracy on test set: 0.5303030303030303, ROC-AUC score for test set: 0.40645773979107314\n"
     ]
    }
   ],
   "source": [
    "df_test_new_test = df_test_new.loc[df_test_new[\"Uniprot ID\"].isin(test_enzymes)]\n",
    "test_new_X2, test_new_y2 =  create_input_and_output_data(df = df_test_new_test)\n",
    "test_new_X2  = np.array(test_new_X2)\n",
    "test_new_y2  = np.array(test_new_y2)\n",
    "\n",
    "dtest_new = xgb.DMatrix(np.array(test_new_X2), label = np.array(test_new_y2),\n",
    "                    feature_names= feature_names)\n",
    "y_test_new_pred = np.round(bst.predict(dtest_new))\n",
    "acc_test_new = np.mean(y_test_new_pred == np.array(test_new_y2))\n",
    "roc_auc_new = roc_auc_score(np.array(test_new_y2), bst.predict(dtest_new))\n",
    "\n",
    "print(\"Enzymes not in training set:\")\n",
    "print(\"Accuracy on test set: %s, ROC-AUC score for test set: %s\"  % (acc_test_new, roc_auc_new))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weight for new data points: 1\n",
      "Accuracy on test set: 0.918562874251497, ROC-AUC score for test set: 0.955903955078284\n",
      "All enzymes:\n",
      "Accuracy on test set: 0.5454545454545454, ROC-AUC score for test set: 0.5351851851851852\n",
      "Enzymes not in training set:\n",
      "Accuracy on test set: 0.5454545454545454, ROC-AUC score for test set: 0.5351851851851852\n",
      "Weight for new data points: 2\n",
      "Accuracy on test set: 0.9187874251497006, ROC-AUC score for test set: 0.9565065878578927\n",
      "All enzymes:\n",
      "Accuracy on test set: 0.5606060606060606, ROC-AUC score for test set: 0.42500000000000004\n",
      "Enzymes not in training set:\n",
      "Accuracy on test set: 0.5606060606060606, ROC-AUC score for test set: 0.42500000000000004\n",
      "Weight for new data points: 3\n",
      "Accuracy on test set: 0.9193113772455089, ROC-AUC score for test set: 0.9567346270417203\n",
      "All enzymes:\n",
      "Accuracy on test set: 0.5606060606060606, ROC-AUC score for test set: 0.5037037037037038\n",
      "Enzymes not in training set:\n",
      "Accuracy on test set: 0.5606060606060606, ROC-AUC score for test set: 0.5037037037037038\n",
      "Weight for new data points: 4\n",
      "Accuracy on test set: 0.9180389221556886, ROC-AUC score for test set: 0.9575971924965179\n",
      "All enzymes:\n",
      "Accuracy on test set: 0.5, ROC-AUC score for test set: 0.5166666666666666\n",
      "Enzymes not in training set:\n",
      "Accuracy on test set: 0.5, ROC-AUC score for test set: 0.5166666666666666\n",
      "Weight for new data points: 5\n",
      "Accuracy on test set: 0.918188622754491, ROC-AUC score for test set: 0.9568997871912915\n",
      "All enzymes:\n",
      "Accuracy on test set: 0.5757575757575758, ROC-AUC score for test set: 0.48703703703703705\n",
      "Enzymes not in training set:\n",
      "Accuracy on test set: 0.5757575757575758, ROC-AUC score for test set: 0.48703703703703705\n",
      "Weight for new data points: 6\n",
      "Accuracy on test set: 0.9176646706586826, ROC-AUC score for test set: 0.9565959991639957\n",
      "All enzymes:\n",
      "Accuracy on test set: 0.5303030303030303, ROC-AUC score for test set: 0.5361111111111111\n",
      "Enzymes not in training set:\n",
      "Accuracy on test set: 0.5303030303030303, ROC-AUC score for test set: 0.5361111111111111\n",
      "Weight for new data points: 7\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-12-eb9358e0e2ef>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     26\u001b[0m                         feature_names= feature_names)\n\u001b[0;32m     27\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 28\u001b[1;33m     \u001b[0mbst\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mxgb\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[1;33m,\u001b[0m  \u001b[0mdtrain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnum_round\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose_eval\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     29\u001b[0m     \u001b[0my_test_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mround\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbst\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdtest\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     30\u001b[0m     \u001b[0macc_test\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_test_pred\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_y\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\Predicting_Km\\lib\\site-packages\\xgboost\\training.py\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(params, dtrain, num_boost_round, evals, obj, feval, maximize, early_stopping_rounds, evals_result, verbose_eval, xgb_model, callbacks)\u001b[0m\n\u001b[0;32m    210\u001b[0m                            \u001b[0mevals\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mevals\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    211\u001b[0m                            \u001b[0mobj\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeval\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfeval\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 212\u001b[1;33m                            xgb_model=xgb_model, callbacks=callbacks)\n\u001b[0m\u001b[0;32m    213\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    214\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\Predicting_Km\\lib\\site-packages\\xgboost\\training.py\u001b[0m in \u001b[0;36m_train_internal\u001b[1;34m(params, dtrain, num_boost_round, evals, obj, feval, xgb_model, callbacks)\u001b[0m\n\u001b[0;32m     73\u001b[0m         \u001b[1;31m# Skip the first update if it is a recovery step.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     74\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mversion\u001b[0m \u001b[1;33m%\u001b[0m \u001b[1;36m2\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 75\u001b[1;33m             \u001b[0mbst\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdtrain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     76\u001b[0m             \u001b[0mbst\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave_rabit_checkpoint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     77\u001b[0m             \u001b[0mversion\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\Predicting_Km\\lib\\site-packages\\xgboost\\core.py\u001b[0m in \u001b[0;36mupdate\u001b[1;34m(self, dtrain, iteration, fobj)\u001b[0m\n\u001b[0;32m   1159\u001b[0m             _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n\u001b[0;32m   1160\u001b[0m                                                     \u001b[0mctypes\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mc_int\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miteration\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1161\u001b[1;33m                                                     dtrain.handle))\n\u001b[0m\u001b[0;32m   1162\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1163\u001b[0m             \u001b[0mpred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdtrain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutput_margin\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "for weight_new in range(1,15):\n",
    "    weight_new_data_points = weight_new\n",
    "    print(\"Weight for new data points: %s\" % weight_new_data_points)\n",
    "    param = {'learning_rate': 0.21593894516312712,\n",
    "             'max_delta_step': 2.3197168781549893,\n",
    "             'max_depth': 12,\n",
    "              'min_child_weight': 0.6315847279633628,\n",
    "               'num_rounds': 396.91340133372364, \n",
    "               'reg_alpha': 0.30340726745680807, \n",
    "               'reg_lambda': 1.1575318518353965, \n",
    "               'weight': 0.11364941242322603}\n",
    "\n",
    "    num_round = param[\"num_rounds\"]\n",
    "    param[\"tree_method\"] = \"gpu_hist\"\n",
    "    param[\"sampling_method\"] = \"gradient_based\"\n",
    "    param['objective'] = 'binary:logistic'\n",
    "    weights = np.array([param[\"weight\"] if binding == 0 else 1.0 for binding in df_train[\"Binding\"]])\n",
    "    weights = [weights[i]*weight_new_data_points if dtype ==\"engqvist\" else weights[i] for i, dtype in enumerate(df_train[\"type\"])]\n",
    "\n",
    "    del param[\"num_rounds\"]\n",
    "    del param[\"weight\"]\n",
    "\n",
    "    dtrain = xgb.DMatrix(np.array(train_X), weight = weights, label = np.array(train_y),\n",
    "                    feature_names= feature_names)\n",
    "    dtest = xgb.DMatrix(np.array(test_X), label = np.array(test_y),\n",
    "                        feature_names= feature_names)\n",
    "\n",
    "    bst = xgb.train(param,  dtrain, int(num_round), verbose_eval=1)\n",
    "    y_test_pred = np.round(bst.predict(dtest))\n",
    "    acc_test = np.mean(y_test_pred == np.array(test_y))\n",
    "    roc_auc = roc_auc_score(np.array(test_y), bst.predict(dtest))\n",
    "\n",
    "    print(\"Accuracy on test set: %s, ROC-AUC score for test set: %s\"  % (acc_test, roc_auc))\n",
    "\n",
    "\n",
    "\n",
    "    dtest_new = xgb.DMatrix(np.array(test_new_X), label = np.array(test_new_y),\n",
    "                        feature_names= feature_names)\n",
    "\n",
    "    y_test_new_pred = np.round(bst.predict(dtest_new))\n",
    "    acc_test_new = np.mean(y_test_new_pred == np.array(test_new_y))\n",
    "    roc_auc_new = roc_auc_score(np.array(test_new_y), bst.predict(dtest_new))\n",
    "    print(\"All enzymes:\")\n",
    "    print(\"Accuracy on test set: %s, ROC-AUC score for test set: %s\"  % (acc_test_new, roc_auc_new))\n",
    "\n",
    "\n",
    "    df_test_new_test = df_test_new.loc[df_test_new[\"Uniprot ID\"].isin(test_enzymes)]\n",
    "    test_new_X, test_new_y =  create_input_and_output_data(df = df_test_new_test)\n",
    "    test_new_X  = np.array(test_new_X)\n",
    "    test_new_y  = np.array(test_new_y)\n",
    "    dtest_new = xgb.DMatrix(np.array(test_new_X), label = np.array(test_new_y),\n",
    "                        feature_names= feature_names)\n",
    "    y_test_new_pred = np.round(bst.predict(dtest_new))\n",
    "    acc_test_new = np.mean(y_test_new_pred == np.array(test_new_y))\n",
    "    roc_auc = roc_auc_score(np.array(test_new_y), bst.predict(dtest_new))\n",
    "\n",
    "    print(\"Enzymes not in training set:\")\n",
    "    print(\"Accuracy on test set: %s, ROC-AUC score for test set: %s\"  % (acc_test_new, roc_auc_new))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
