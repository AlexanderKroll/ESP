{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training gradient boosting model for enzyme-substrate pair prediction with ESM-1b-vectors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Loading and preprocessing data for model training and evaluation\n",
    "### 2. Hyperparameter optimization using a 5-fold cross-validation (CV)\n",
    "### 3. Training and validating the final model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\alexk\\projects\\SubFinder\\notebooks_and_code\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import pickle\n",
    "import sys\n",
    "import os\n",
    "import logging\n",
    "from os.path import join\n",
    "from sklearn.model_selection import KFold\n",
    "#from hyperopt import fmin, tpe, hp, Trials, rand\n",
    "import xgboost as xgb\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "sys.path.append('.\\\\additional_code')\n",
    "#from data_preprocessing import *\n",
    "\n",
    "CURRENT_DIR = os.getcwd()\n",
    "print(CURRENT_DIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Loading and preprocessing data for model training and evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (a) Loading data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\alexk\\anaconda3\\envs\\Protein\\lib\\site-packages\\pandas\\core\\ops\\array_ops.py:56: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  result = libops.scalar_compare(x.ravel(), y, op)\n",
      "C:\\Users\\alexk\\anaconda3\\envs\\Protein\\lib\\site-packages\\pandas\\core\\ops\\array_ops.py:56: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  result = libops.scalar_compare(x.ravel(), y, op)\n",
      "C:\\Users\\alexk\\anaconda3\\envs\\Protein\\lib\\site-packages\\pandas\\core\\ops\\array_ops.py:56: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  result = libops.scalar_compare(x.ravel(), y, op)\n",
      "C:\\Users\\alexk\\anaconda3\\envs\\Protein\\lib\\site-packages\\pandas\\core\\ops\\array_ops.py:56: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  result = libops.scalar_compare(x.ravel(), y, op)\n"
     ]
    }
   ],
   "source": [
    "df_test  = pd.read_pickle(join(CURRENT_DIR, \"..\" ,\"data\",\"splits\", \"df_test_with_ESM1b_ts.pkl\"))\n",
    "df_test = df_test.loc[df_test[\"ESM1b_ts\"] != \"\"]\n",
    "df_test.reset_index(inplace = True, drop = True)\n",
    "\n",
    "df_Mou  = pd.read_pickle(join(CURRENT_DIR, \"..\" ,\"data\", \"Min_data\", \"Min_df.pkl\"))\n",
    "df_Mou = df_Mou.loc[df_Mou[\"ESM1b_ts\"] != \"\"]\n",
    "df_Mou.reset_index(inplace = True, drop = True)\n",
    "\n",
    "df_Berry  = pd.read_pickle(join(CURRENT_DIR, \"..\" ,\"data\", \"Min_data\", \"Min_validation_Berry_df.pkl\"))\n",
    "df_Berry = df_Berry.loc[df_Berry[\"ESM1b_ts\"] != \"\"]\n",
    "df_Berry.reset_index(inplace = True, drop = True)\n",
    "\n",
    "df_Oat  = pd.read_pickle(join(CURRENT_DIR, \"..\" ,\"data\", \"Min_data\", \"Min_validation_Oat_df.pkl\"))\n",
    "df_Oat = df_Oat.loc[df_Oat[\"ESM1b_ts\"] != \"\"]\n",
    "df_Oat.reset_index(inplace = True, drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.17983842641376888, 0.3131578947368421, 0.30451127819548873)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(df_Mou[\"Binding\"]), np.mean(df_Berry[\"Binding\"]), np.mean(df_Oat[\"Binding\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading new dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_input_and_output_data(df):\n",
    "    X = ();\n",
    "    y = ();\n",
    "    \n",
    "    for ind in df.index:\n",
    "        emb = df[\"ESM1b_ts\"][ind]\n",
    "        ecfp = np.array(list(df[\"ECFP\"][ind])).astype(int)\n",
    "                \n",
    "        X = X +(np.concatenate([ecfp, emb]), );\n",
    "        y = y + (df[\"Binding\"][ind], );\n",
    "\n",
    "    return(np.array(X),np.array(y))\n",
    "\n",
    "feature_names =  [\"ECFP_\" + str(i) for i in range(1024)]\n",
    "feature_names = feature_names + [\"ESM1b_ts_\" + str(i) for i in range(1280)]\n",
    "\n",
    "#import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adding Yang et al. data to the training set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\alexk\\anaconda3\\envs\\Protein\\lib\\site-packages\\pandas\\core\\ops\\array_ops.py:56: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  result = libops.scalar_compare(x.ravel(), y, op)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[19:32:49] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[0]\teval-logloss:0.64568\ttrain-logloss:0.60286\n",
      "[1]\teval-logloss:0.61630\ttrain-logloss:0.54505\n",
      "[2]\teval-logloss:0.60495\ttrain-logloss:0.50130\n",
      "[3]\teval-logloss:0.60057\ttrain-logloss:0.47120\n",
      "[4]\teval-logloss:0.59920\ttrain-logloss:0.44867\n",
      "[5]\teval-logloss:0.59698\ttrain-logloss:0.43298\n",
      "[6]\teval-logloss:0.58226\ttrain-logloss:0.42292\n",
      "[7]\teval-logloss:0.58323\ttrain-logloss:0.41463\n",
      "[8]\teval-logloss:0.59773\ttrain-logloss:0.40060\n",
      "[9]\teval-logloss:0.60508\ttrain-logloss:0.39339\n",
      "[10]\teval-logloss:0.60520\ttrain-logloss:0.38366\n",
      "[11]\teval-logloss:0.60211\ttrain-logloss:0.37483\n",
      "[12]\teval-logloss:0.59695\ttrain-logloss:0.37063\n",
      "[13]\teval-logloss:0.60000\ttrain-logloss:0.36133\n",
      "[14]\teval-logloss:0.59444\ttrain-logloss:0.35452\n",
      "[15]\teval-logloss:0.58879\ttrain-logloss:0.35034\n",
      "[16]\teval-logloss:0.59021\ttrain-logloss:0.34154\n",
      "[17]\teval-logloss:0.59142\ttrain-logloss:0.33598\n",
      "[18]\teval-logloss:0.59351\ttrain-logloss:0.32917\n",
      "[19]\teval-logloss:0.59167\ttrain-logloss:0.32501\n",
      "[20]\teval-logloss:0.59093\ttrain-logloss:0.31764\n",
      "[21]\teval-logloss:0.58345\ttrain-logloss:0.31140\n",
      "[22]\teval-logloss:0.58449\ttrain-logloss:0.30521\n",
      "[23]\teval-logloss:0.58530\ttrain-logloss:0.29871\n",
      "[24]\teval-logloss:0.58147\ttrain-logloss:0.29662\n",
      "[25]\teval-logloss:0.58238\ttrain-logloss:0.29216\n",
      "[26]\teval-logloss:0.58698\ttrain-logloss:0.28986\n",
      "[27]\teval-logloss:0.59425\ttrain-logloss:0.28601\n",
      "[28]\teval-logloss:0.59608\ttrain-logloss:0.28320\n",
      "[29]\teval-logloss:0.59738\ttrain-logloss:0.27804\n",
      "[30]\teval-logloss:0.59825\ttrain-logloss:0.27268\n",
      "[31]\teval-logloss:0.59650\ttrain-logloss:0.26911\n",
      "[32]\teval-logloss:0.59833\ttrain-logloss:0.26645\n",
      "[33]\teval-logloss:0.60240\ttrain-logloss:0.26279\n",
      "[34]\teval-logloss:0.60101\ttrain-logloss:0.26064\n",
      "[35]\teval-logloss:0.60203\ttrain-logloss:0.25781\n",
      "[36]\teval-logloss:0.60076\ttrain-logloss:0.25534\n",
      "[37]\teval-logloss:0.60230\ttrain-logloss:0.25213\n",
      "[38]\teval-logloss:0.59452\ttrain-logloss:0.24759\n",
      "[39]\teval-logloss:0.59839\ttrain-logloss:0.24644\n",
      "[40]\teval-logloss:0.59754\ttrain-logloss:0.24328\n",
      "[41]\teval-logloss:0.59730\ttrain-logloss:0.24038\n",
      "[42]\teval-logloss:0.59837\ttrain-logloss:0.23660\n",
      "[43]\teval-logloss:0.59629\ttrain-logloss:0.23346\n",
      "[44]\teval-logloss:0.59766\ttrain-logloss:0.23044\n",
      "[45]\teval-logloss:0.59373\ttrain-logloss:0.22731\n",
      "[46]\teval-logloss:0.59708\ttrain-logloss:0.22445\n",
      "[47]\teval-logloss:0.59451\ttrain-logloss:0.22215\n",
      "[48]\teval-logloss:0.59150\ttrain-logloss:0.22095\n",
      "[49]\teval-logloss:0.58885\ttrain-logloss:0.21909\n",
      "[50]\teval-logloss:0.59365\ttrain-logloss:0.21541\n",
      "[51]\teval-logloss:0.59010\ttrain-logloss:0.21390\n",
      "[52]\teval-logloss:0.59070\ttrain-logloss:0.21200\n",
      "[53]\teval-logloss:0.59324\ttrain-logloss:0.20969\n",
      "[54]\teval-logloss:0.59133\ttrain-logloss:0.20727\n",
      "[55]\teval-logloss:0.59537\ttrain-logloss:0.20563\n",
      "[56]\teval-logloss:0.59517\ttrain-logloss:0.20318\n",
      "[57]\teval-logloss:0.59429\ttrain-logloss:0.20007\n",
      "[58]\teval-logloss:0.59294\ttrain-logloss:0.19659\n",
      "[59]\teval-logloss:0.59195\ttrain-logloss:0.19517\n",
      "[60]\teval-logloss:0.59094\ttrain-logloss:0.19383\n",
      "[61]\teval-logloss:0.59093\ttrain-logloss:0.19180\n",
      "[62]\teval-logloss:0.59369\ttrain-logloss:0.19033\n",
      "[63]\teval-logloss:0.59432\ttrain-logloss:0.18947\n",
      "[64]\teval-logloss:0.59570\ttrain-logloss:0.18778\n",
      "[65]\teval-logloss:0.59922\ttrain-logloss:0.18508\n",
      "[66]\teval-logloss:0.59934\ttrain-logloss:0.18393\n",
      "[67]\teval-logloss:0.60252\ttrain-logloss:0.18286\n",
      "[68]\teval-logloss:0.60642\ttrain-logloss:0.18068\n",
      "[69]\teval-logloss:0.60572\ttrain-logloss:0.17876\n",
      "[70]\teval-logloss:0.60637\ttrain-logloss:0.17716\n",
      "[71]\teval-logloss:0.61166\ttrain-logloss:0.17612\n",
      "[72]\teval-logloss:0.60955\ttrain-logloss:0.17447\n",
      "[73]\teval-logloss:0.61347\ttrain-logloss:0.17328\n",
      "[74]\teval-logloss:0.61271\ttrain-logloss:0.17194\n",
      "[75]\teval-logloss:0.61025\ttrain-logloss:0.17029\n",
      "[76]\teval-logloss:0.61030\ttrain-logloss:0.16902\n",
      "[77]\teval-logloss:0.60648\ttrain-logloss:0.16761\n",
      "[78]\teval-logloss:0.60720\ttrain-logloss:0.16594\n",
      "[79]\teval-logloss:0.60959\ttrain-logloss:0.16442\n",
      "[80]\teval-logloss:0.61160\ttrain-logloss:0.16383\n",
      "[81]\teval-logloss:0.61141\ttrain-logloss:0.16250\n",
      "[82]\teval-logloss:0.61490\ttrain-logloss:0.16169\n",
      "[83]\teval-logloss:0.61305\ttrain-logloss:0.16054\n",
      "[84]\teval-logloss:0.61450\ttrain-logloss:0.15936\n",
      "[85]\teval-logloss:0.61765\ttrain-logloss:0.15756\n",
      "[86]\teval-logloss:0.61844\ttrain-logloss:0.15657\n",
      "[87]\teval-logloss:0.62018\ttrain-logloss:0.15559\n",
      "[88]\teval-logloss:0.61990\ttrain-logloss:0.15419\n",
      "[89]\teval-logloss:0.61726\ttrain-logloss:0.15313\n",
      "[90]\teval-logloss:0.61574\ttrain-logloss:0.15215\n",
      "[91]\teval-logloss:0.61645\ttrain-logloss:0.15046\n",
      "[92]\teval-logloss:0.61928\ttrain-logloss:0.14985\n",
      "[93]\teval-logloss:0.62296\ttrain-logloss:0.14860\n",
      "[94]\teval-logloss:0.62366\ttrain-logloss:0.14754\n",
      "[95]\teval-logloss:0.62360\ttrain-logloss:0.14631\n",
      "[96]\teval-logloss:0.62557\ttrain-logloss:0.14531\n",
      "[97]\teval-logloss:0.62803\ttrain-logloss:0.14323\n",
      "[98]\teval-logloss:0.62830\ttrain-logloss:0.14237\n",
      "[99]\teval-logloss:0.62482\ttrain-logloss:0.14180\n",
      "[100]\teval-logloss:0.62550\ttrain-logloss:0.14036\n",
      "[101]\teval-logloss:0.62496\ttrain-logloss:0.13926\n",
      "[102]\teval-logloss:0.62591\ttrain-logloss:0.13839\n",
      "[103]\teval-logloss:0.62509\ttrain-logloss:0.13703\n",
      "[104]\teval-logloss:0.62532\ttrain-logloss:0.13603\n",
      "[105]\teval-logloss:0.62492\ttrain-logloss:0.13541\n",
      "[106]\teval-logloss:0.62547\ttrain-logloss:0.13464\n",
      "[107]\teval-logloss:0.62894\ttrain-logloss:0.13317\n",
      "[108]\teval-logloss:0.62933\ttrain-logloss:0.13226\n",
      "[109]\teval-logloss:0.62958\ttrain-logloss:0.13132\n",
      "[110]\teval-logloss:0.63447\ttrain-logloss:0.12993\n",
      "[111]\teval-logloss:0.63216\ttrain-logloss:0.12871\n",
      "[112]\teval-logloss:0.63198\ttrain-logloss:0.12715\n",
      "[113]\teval-logloss:0.63184\ttrain-logloss:0.12615\n",
      "[114]\teval-logloss:0.63416\ttrain-logloss:0.12514\n",
      "[115]\teval-logloss:0.63829\ttrain-logloss:0.12457\n",
      "[116]\teval-logloss:0.64117\ttrain-logloss:0.12401\n",
      "[117]\teval-logloss:0.64026\ttrain-logloss:0.12322\n",
      "[118]\teval-logloss:0.64424\ttrain-logloss:0.12230\n",
      "[119]\teval-logloss:0.64440\ttrain-logloss:0.12135\n",
      "[120]\teval-logloss:0.64414\ttrain-logloss:0.12067\n",
      "[121]\teval-logloss:0.64419\ttrain-logloss:0.11999\n",
      "[122]\teval-logloss:0.64331\ttrain-logloss:0.11870\n",
      "[123]\teval-logloss:0.64306\ttrain-logloss:0.11801\n",
      "[124]\teval-logloss:0.64219\ttrain-logloss:0.11712\n",
      "[125]\teval-logloss:0.64151\ttrain-logloss:0.11648\n",
      "[126]\teval-logloss:0.64184\ttrain-logloss:0.11575\n",
      "[127]\teval-logloss:0.64200\ttrain-logloss:0.11477\n",
      "[128]\teval-logloss:0.64304\ttrain-logloss:0.11386\n",
      "[129]\teval-logloss:0.64286\ttrain-logloss:0.11283\n",
      "[130]\teval-logloss:0.64308\ttrain-logloss:0.11237\n",
      "[131]\teval-logloss:0.64285\ttrain-logloss:0.11179\n",
      "[132]\teval-logloss:0.64314\ttrain-logloss:0.11126\n",
      "[133]\teval-logloss:0.64747\ttrain-logloss:0.11068\n",
      "[134]\teval-logloss:0.65075\ttrain-logloss:0.10951\n",
      "[135]\teval-logloss:0.65019\ttrain-logloss:0.10882\n",
      "[136]\teval-logloss:0.65065\ttrain-logloss:0.10830\n",
      "[137]\teval-logloss:0.65007\ttrain-logloss:0.10764\n",
      "[138]\teval-logloss:0.64988\ttrain-logloss:0.10725\n",
      "[139]\teval-logloss:0.64863\ttrain-logloss:0.10672\n",
      "[140]\teval-logloss:0.64716\ttrain-logloss:0.10619\n",
      "[141]\teval-logloss:0.64805\ttrain-logloss:0.10551\n",
      "[142]\teval-logloss:0.64853\ttrain-logloss:0.10497\n",
      "[143]\teval-logloss:0.64912\ttrain-logloss:0.10451\n",
      "[144]\teval-logloss:0.65319\ttrain-logloss:0.10402\n",
      "[145]\teval-logloss:0.65365\ttrain-logloss:0.10360\n",
      "[146]\teval-logloss:0.65414\ttrain-logloss:0.10292\n",
      "[147]\teval-logloss:0.65325\ttrain-logloss:0.10220\n",
      "[148]\teval-logloss:0.65243\ttrain-logloss:0.10189\n",
      "[149]\teval-logloss:0.65223\ttrain-logloss:0.10157\n",
      "[150]\teval-logloss:0.65162\ttrain-logloss:0.10107\n",
      "[151]\teval-logloss:0.65328\ttrain-logloss:0.10081\n",
      "[152]\teval-logloss:0.65312\ttrain-logloss:0.10022\n",
      "[153]\teval-logloss:0.65424\ttrain-logloss:0.09975\n",
      "[154]\teval-logloss:0.65196\ttrain-logloss:0.09928\n",
      "[155]\teval-logloss:0.65240\ttrain-logloss:0.09882\n",
      "[156]\teval-logloss:0.65306\ttrain-logloss:0.09818\n",
      "[157]\teval-logloss:0.65478\ttrain-logloss:0.09771\n",
      "[158]\teval-logloss:0.65565\ttrain-logloss:0.09726\n",
      "[159]\teval-logloss:0.65485\ttrain-logloss:0.09668\n",
      "[160]\teval-logloss:0.65519\ttrain-logloss:0.09644\n",
      "[161]\teval-logloss:0.65670\ttrain-logloss:0.09604\n",
      "[162]\teval-logloss:0.65677\ttrain-logloss:0.09560\n",
      "[163]\teval-logloss:0.65794\ttrain-logloss:0.09502\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[164]\teval-logloss:0.65879\ttrain-logloss:0.09434\n",
      "[165]\teval-logloss:0.66387\ttrain-logloss:0.09380\n",
      "[166]\teval-logloss:0.66316\ttrain-logloss:0.09317\n",
      "[167]\teval-logloss:0.66649\ttrain-logloss:0.09269\n",
      "[168]\teval-logloss:0.66834\ttrain-logloss:0.09199\n",
      "[169]\teval-logloss:0.66765\ttrain-logloss:0.09142\n",
      "[170]\teval-logloss:0.66833\ttrain-logloss:0.09095\n",
      "[171]\teval-logloss:0.66954\ttrain-logloss:0.09043\n",
      "[172]\teval-logloss:0.66822\ttrain-logloss:0.08982\n",
      "[173]\teval-logloss:0.67053\ttrain-logloss:0.08948\n",
      "[174]\teval-logloss:0.67389\ttrain-logloss:0.08920\n",
      "[175]\teval-logloss:0.67388\ttrain-logloss:0.08878\n",
      "[176]\teval-logloss:0.67424\ttrain-logloss:0.08840\n",
      "[177]\teval-logloss:0.67439\ttrain-logloss:0.08794\n",
      "[178]\teval-logloss:0.67385\ttrain-logloss:0.08745\n",
      "[179]\teval-logloss:0.67389\ttrain-logloss:0.08703\n",
      "[180]\teval-logloss:0.67362\ttrain-logloss:0.08661\n",
      "[181]\teval-logloss:0.67334\ttrain-logloss:0.08626\n",
      "[182]\teval-logloss:0.67316\ttrain-logloss:0.08578\n",
      "[183]\teval-logloss:0.67305\ttrain-logloss:0.08544\n",
      "[184]\teval-logloss:0.67351\ttrain-logloss:0.08476\n",
      "[185]\teval-logloss:0.67312\ttrain-logloss:0.08430\n",
      "[186]\teval-logloss:0.67220\ttrain-logloss:0.08396\n",
      "[187]\teval-logloss:0.67172\ttrain-logloss:0.08371\n",
      "[188]\teval-logloss:0.67704\ttrain-logloss:0.08341\n",
      "[189]\teval-logloss:0.67434\ttrain-logloss:0.08264\n",
      "[190]\teval-logloss:0.67471\ttrain-logloss:0.08221\n",
      "[191]\teval-logloss:0.67456\ttrain-logloss:0.08166\n",
      "[192]\teval-logloss:0.67612\ttrain-logloss:0.08123\n",
      "[193]\teval-logloss:0.67701\ttrain-logloss:0.08057\n",
      "[194]\teval-logloss:0.67997\ttrain-logloss:0.08014\n",
      "[195]\teval-logloss:0.67853\ttrain-logloss:0.07978\n",
      "[196]\teval-logloss:0.67906\ttrain-logloss:0.07933\n",
      "[197]\teval-logloss:0.68105\ttrain-logloss:0.07912\n",
      "[198]\teval-logloss:0.68316\ttrain-logloss:0.07876\n",
      "[199]\teval-logloss:0.68474\ttrain-logloss:0.07830\n",
      "[200]\teval-logloss:0.68340\ttrain-logloss:0.07816\n",
      "[201]\teval-logloss:0.68604\ttrain-logloss:0.07788\n",
      "[202]\teval-logloss:0.68628\ttrain-logloss:0.07752\n",
      "[203]\teval-logloss:0.68757\ttrain-logloss:0.07718\n",
      "[204]\teval-logloss:0.68685\ttrain-logloss:0.07668\n",
      "[205]\teval-logloss:0.68914\ttrain-logloss:0.07634\n",
      "[206]\teval-logloss:0.68956\ttrain-logloss:0.07594\n",
      "[207]\teval-logloss:0.68897\ttrain-logloss:0.07558\n",
      "[208]\teval-logloss:0.68989\ttrain-logloss:0.07515\n",
      "[209]\teval-logloss:0.68957\ttrain-logloss:0.07477\n",
      "[210]\teval-logloss:0.69158\ttrain-logloss:0.07450\n",
      "[211]\teval-logloss:0.69152\ttrain-logloss:0.07417\n",
      "[212]\teval-logloss:0.69137\ttrain-logloss:0.07387\n",
      "[213]\teval-logloss:0.69099\ttrain-logloss:0.07354\n",
      "[214]\teval-logloss:0.69239\ttrain-logloss:0.07331\n",
      "[215]\teval-logloss:0.69281\ttrain-logloss:0.07292\n",
      "[216]\teval-logloss:0.69271\ttrain-logloss:0.07266\n",
      "[217]\teval-logloss:0.69298\ttrain-logloss:0.07240\n",
      "[218]\teval-logloss:0.69322\ttrain-logloss:0.07212\n",
      "[219]\teval-logloss:0.69471\ttrain-logloss:0.07153\n",
      "[220]\teval-logloss:0.69438\ttrain-logloss:0.07117\n",
      "[221]\teval-logloss:0.69298\ttrain-logloss:0.07098\n",
      "[222]\teval-logloss:0.69639\ttrain-logloss:0.07072\n",
      "[223]\teval-logloss:0.69396\ttrain-logloss:0.07032\n",
      "[224]\teval-logloss:0.69314\ttrain-logloss:0.07000\n",
      "[225]\teval-logloss:0.69658\ttrain-logloss:0.06972\n",
      "[226]\teval-logloss:0.69871\ttrain-logloss:0.06925\n",
      "[227]\teval-logloss:0.69928\ttrain-logloss:0.06888\n",
      "[228]\teval-logloss:0.69980\ttrain-logloss:0.06861\n",
      "[229]\teval-logloss:0.69911\ttrain-logloss:0.06837\n",
      "[230]\teval-logloss:0.69811\ttrain-logloss:0.06816\n",
      "[231]\teval-logloss:0.69934\ttrain-logloss:0.06783\n",
      "[232]\teval-logloss:0.69948\ttrain-logloss:0.06760\n",
      "[233]\teval-logloss:0.69934\ttrain-logloss:0.06731\n",
      "[234]\teval-logloss:0.69801\ttrain-logloss:0.06703\n",
      "[235]\teval-logloss:0.69799\ttrain-logloss:0.06689\n",
      "[236]\teval-logloss:0.69907\ttrain-logloss:0.06658\n",
      "[237]\teval-logloss:0.69895\ttrain-logloss:0.06621\n",
      "[238]\teval-logloss:0.69827\ttrain-logloss:0.06578\n",
      "[239]\teval-logloss:0.69829\ttrain-logloss:0.06551\n",
      "[240]\teval-logloss:0.70080\ttrain-logloss:0.06518\n",
      "[241]\teval-logloss:0.70147\ttrain-logloss:0.06498\n",
      "[242]\teval-logloss:0.70071\ttrain-logloss:0.06470\n",
      "[243]\teval-logloss:0.70195\ttrain-logloss:0.06439\n",
      "[244]\teval-logloss:0.70220\ttrain-logloss:0.06421\n",
      "[245]\teval-logloss:0.70118\ttrain-logloss:0.06402\n",
      "[246]\teval-logloss:0.70389\ttrain-logloss:0.06380\n",
      "[247]\teval-logloss:0.70418\ttrain-logloss:0.06359\n",
      "[248]\teval-logloss:0.70542\ttrain-logloss:0.06330\n",
      "[249]\teval-logloss:0.70447\ttrain-logloss:0.06306\n",
      "[250]\teval-logloss:0.70601\ttrain-logloss:0.06280\n",
      "[251]\teval-logloss:0.70718\ttrain-logloss:0.06248\n",
      "[252]\teval-logloss:0.70625\ttrain-logloss:0.06221\n",
      "[253]\teval-logloss:0.70895\ttrain-logloss:0.06188\n",
      "[254]\teval-logloss:0.70909\ttrain-logloss:0.06162\n",
      "[255]\teval-logloss:0.70857\ttrain-logloss:0.06130\n",
      "[256]\teval-logloss:0.70798\ttrain-logloss:0.06090\n",
      "[257]\teval-logloss:0.70808\ttrain-logloss:0.06072\n",
      "[258]\teval-logloss:0.71077\ttrain-logloss:0.06050\n",
      "[259]\teval-logloss:0.71168\ttrain-logloss:0.06019\n",
      "[260]\teval-logloss:0.71021\ttrain-logloss:0.06000\n",
      "[261]\teval-logloss:0.71273\ttrain-logloss:0.05985\n",
      "[262]\teval-logloss:0.71168\ttrain-logloss:0.05957\n",
      "[263]\teval-logloss:0.71257\ttrain-logloss:0.05934\n",
      "[264]\teval-logloss:0.71269\ttrain-logloss:0.05909\n",
      "[265]\teval-logloss:0.71157\ttrain-logloss:0.05892\n",
      "[266]\teval-logloss:0.71206\ttrain-logloss:0.05877\n",
      "[267]\teval-logloss:0.71294\ttrain-logloss:0.05854\n",
      "[268]\teval-logloss:0.71496\ttrain-logloss:0.05840\n",
      "[269]\teval-logloss:0.71489\ttrain-logloss:0.05816\n",
      "[270]\teval-logloss:0.71606\ttrain-logloss:0.05776\n",
      "[271]\teval-logloss:0.71733\ttrain-logloss:0.05747\n",
      "[272]\teval-logloss:0.71724\ttrain-logloss:0.05728\n",
      "[273]\teval-logloss:0.71833\ttrain-logloss:0.05715\n",
      "[274]\teval-logloss:0.71764\ttrain-logloss:0.05693\n",
      "[275]\teval-logloss:0.71793\ttrain-logloss:0.05663\n",
      "[276]\teval-logloss:0.71728\ttrain-logloss:0.05632\n",
      "[277]\teval-logloss:0.71754\ttrain-logloss:0.05619\n",
      "[278]\teval-logloss:0.71886\ttrain-logloss:0.05595\n",
      "[279]\teval-logloss:0.71890\ttrain-logloss:0.05551\n",
      "[280]\teval-logloss:0.71971\ttrain-logloss:0.05526\n",
      "[281]\teval-logloss:0.71992\ttrain-logloss:0.05507\n",
      "[282]\teval-logloss:0.72225\ttrain-logloss:0.05496\n",
      "[283]\teval-logloss:0.72169\ttrain-logloss:0.05480\n",
      "[284]\teval-logloss:0.72404\ttrain-logloss:0.05456\n",
      "[285]\teval-logloss:0.72376\ttrain-logloss:0.05441\n",
      "[286]\teval-logloss:0.72397\ttrain-logloss:0.05410\n",
      "[287]\teval-logloss:0.72421\ttrain-logloss:0.05386\n",
      "[288]\teval-logloss:0.72529\ttrain-logloss:0.05374\n",
      "[289]\teval-logloss:0.72469\ttrain-logloss:0.05339\n",
      "[290]\teval-logloss:0.72594\ttrain-logloss:0.05314\n",
      "[291]\teval-logloss:0.72649\ttrain-logloss:0.05286\n",
      "[292]\teval-logloss:0.72749\ttrain-logloss:0.05272\n",
      "[293]\teval-logloss:0.72766\ttrain-logloss:0.05244\n",
      "[294]\teval-logloss:0.72762\ttrain-logloss:0.05226\n",
      "[295]\teval-logloss:0.73008\ttrain-logloss:0.05208\n",
      "[296]\teval-logloss:0.73109\ttrain-logloss:0.05196\n",
      "[297]\teval-logloss:0.73171\ttrain-logloss:0.05186\n",
      "[298]\teval-logloss:0.73169\ttrain-logloss:0.05173\n",
      "[299]\teval-logloss:0.73431\ttrain-logloss:0.05126\n",
      "[300]\teval-logloss:0.73472\ttrain-logloss:0.05112\n",
      "[301]\teval-logloss:0.73544\ttrain-logloss:0.05096\n",
      "[302]\teval-logloss:0.73549\ttrain-logloss:0.05084\n",
      "[303]\teval-logloss:0.73529\ttrain-logloss:0.05067\n",
      "[304]\teval-logloss:0.73358\ttrain-logloss:0.05055\n",
      "[305]\teval-logloss:0.73410\ttrain-logloss:0.05039\n",
      "[306]\teval-logloss:0.73359\ttrain-logloss:0.05029\n",
      "[307]\teval-logloss:0.73393\ttrain-logloss:0.05000\n",
      "[308]\teval-logloss:0.73373\ttrain-logloss:0.04979\n",
      "[309]\teval-logloss:0.73491\ttrain-logloss:0.04950\n",
      "[310]\teval-logloss:0.73490\ttrain-logloss:0.04936\n",
      "[311]\teval-logloss:0.73461\ttrain-logloss:0.04904\n",
      "[312]\teval-logloss:0.73483\ttrain-logloss:0.04889\n",
      "[313]\teval-logloss:0.73654\ttrain-logloss:0.04868\n",
      "[314]\teval-logloss:0.73610\ttrain-logloss:0.04853\n",
      "[315]\teval-logloss:0.73611\ttrain-logloss:0.04829\n",
      "[316]\teval-logloss:0.73630\ttrain-logloss:0.04813\n",
      "[317]\teval-logloss:0.73753\ttrain-logloss:0.04802\n",
      "[318]\teval-logloss:0.73634\ttrain-logloss:0.04785\n",
      "[319]\teval-logloss:0.73735\ttrain-logloss:0.04759\n",
      "[320]\teval-logloss:0.73764\ttrain-logloss:0.04742\n",
      "[321]\teval-logloss:0.73783\ttrain-logloss:0.04733\n",
      "[322]\teval-logloss:0.73790\ttrain-logloss:0.04718\n",
      "[323]\teval-logloss:0.73803\ttrain-logloss:0.04700\n",
      "[324]\teval-logloss:0.73771\ttrain-logloss:0.04688\n",
      "[325]\teval-logloss:0.73796\ttrain-logloss:0.04670\n",
      "[326]\teval-logloss:0.73969\ttrain-logloss:0.04658\n",
      "[327]\teval-logloss:0.74113\ttrain-logloss:0.04635\n",
      "[328]\teval-logloss:0.74229\ttrain-logloss:0.04616\n",
      "[329]\teval-logloss:0.74424\ttrain-logloss:0.04594\n",
      "[330]\teval-logloss:0.74587\ttrain-logloss:0.04579\n",
      "[331]\teval-logloss:0.74455\ttrain-logloss:0.04559\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[332]\teval-logloss:0.74462\ttrain-logloss:0.04549\n",
      "[333]\teval-logloss:0.74543\ttrain-logloss:0.04535\n",
      "[334]\teval-logloss:0.74745\ttrain-logloss:0.04519\n",
      "[335]\teval-logloss:0.74772\ttrain-logloss:0.04503\n",
      "[336]\teval-logloss:0.74894\ttrain-logloss:0.04495\n",
      "[337]\teval-logloss:0.74886\ttrain-logloss:0.04475\n",
      "[338]\teval-logloss:0.74919\ttrain-logloss:0.04467\n",
      "[339]\teval-logloss:0.74972\ttrain-logloss:0.04454\n",
      "[340]\teval-logloss:0.75028\ttrain-logloss:0.04433\n",
      "[341]\teval-logloss:0.75118\ttrain-logloss:0.04423\n",
      "Accuracy on test set: 0.9030475052285629, ROC-AUC score for test set: 0.9472670686419001\n",
      "All enzymes:\n",
      "Accuracy on test set: 0.9957850368809273, ROC-AUC score for test set: 1.0\n",
      "Accuracy on Berry validation set: 0.781578947368421, ROC-AUC score for test set: 0.8380501625937732\n",
      "Accuracy on Oat validation set: 0.7819548872180451, ROC-AUC score for test set: 0.8029362696029363\n"
     ]
    }
   ],
   "source": [
    "\n",
    "df_train = pd.read_pickle(join(CURRENT_DIR, \"..\" ,\"data\",\n",
    "                               \"splits\", \"df_train_with_ESM1b_ts.pkl\"))\n",
    "df_train = df_train.loc[df_train[\"ESM1b_ts\"] != \"\"]\n",
    "df_train.reset_index(inplace = True, drop = True)\n",
    "\n",
    "\n",
    "train_X, train_y =  create_input_and_output_data(df = df_train)\n",
    "test_X, test_y =  create_input_and_output_data(df = df_test)\n",
    "\n",
    "df_test_new = df_Mou.copy()\n",
    "test_new_X, test_new_y =  create_input_and_output_data(df = df_test_new)\n",
    "\n",
    "\n",
    "\n",
    "X_train_Mou = test_new_X\n",
    "y_train_Mou = test_new_y\n",
    "\n",
    "train_X = np.concatenate([train_X, X_train_Mou])\n",
    "train_y = np.concatenate([train_y, y_train_Mou])\n",
    "\n",
    "\n",
    "Berry_X, Berry_y =  create_input_and_output_data(df = df_Berry)\n",
    "Oat_X, Oat_y =  create_input_and_output_data(df = df_Oat)\n",
    "\n",
    "\n",
    "param = {'learning_rate': 0.31553117247348733,\n",
    "         'max_delta_step': 1.7726044219753656,\n",
    "         'max_depth': 10,\n",
    "         'min_child_weight': 1.3845040588450772,\n",
    "         'num_rounds': 342.68325188584106,\n",
    "         'reg_alpha': 0.531395259755843,\n",
    "         'reg_lambda': 3.744980563764689,\n",
    "         'weight': 0.26187490421514203}\n",
    "\n",
    "num_round = param[\"num_rounds\"]\n",
    "param[\"tree_method\"] = \"gpu_hist\"\n",
    "param[\"sampling_method\"] = \"gradient_based\"\n",
    "param['objective'] = 'binary:logistic'\n",
    "\n",
    "\n",
    "weights =  np.array([param[\"weight\"] if binding == 0 else 1.0 for binding in np.array(train_y)])\n",
    "\n",
    "\n",
    "del param[\"num_rounds\"]\n",
    "del param[\"weight\"]\n",
    "\n",
    "dtrain = xgb.DMatrix(np.array(train_X), weight = weights, label = np.array(train_y),\n",
    "            feature_names= feature_names)\n",
    "dtest = xgb.DMatrix(np.array(test_X), label = np.array(test_y),\n",
    "                    feature_names= feature_names)\n",
    "\n",
    "dtest_new = xgb.DMatrix(np.array(test_new_X), label = np.array(test_new_y), feature_names= feature_names)\n",
    "dOat = xgb.DMatrix(np.array(Oat_X), label = np.array(Oat_y), feature_names= feature_names)\n",
    "\n",
    "evallist = [(dOat, 'eval'), (dtrain, 'train')]\n",
    "\n",
    "bst = xgb.train(param,  dtrain, int(num_round),evallist, verbose_eval=1)\n",
    "y_test_pred = np.round(bst.predict(dtest))\n",
    "acc_test = np.mean(y_test_pred == np.array(test_y))\n",
    "roc_auc = roc_auc_score(np.array(test_y), bst.predict(dtest))\n",
    "\n",
    "print(\"Accuracy on test set: %s, ROC-AUC score for test set: %s\"  % (acc_test, roc_auc))\n",
    "\n",
    "\n",
    "y_test_new_pred = np.round(bst.predict(dtest_new))\n",
    "acc_test_new = np.mean(y_test_new_pred == np.array(test_new_y))\n",
    "roc_auc_new = roc_auc_score(np.array(test_new_y), bst.predict(dtest_new))\n",
    "\n",
    "print(\"All enzymes:\")\n",
    "print(\"Accuracy on test set: %s, ROC-AUC score for test set: %s\"  % (acc_test_new, roc_auc_new))\n",
    "\n",
    "dBerry = xgb.DMatrix(np.array(Berry_X), label = np.array(Berry_y), feature_names= feature_names)\n",
    "\n",
    "y_test_Berry_pred = np.round(bst.predict(dBerry))\n",
    "acc_test_Berry = np.mean(y_test_Berry_pred == np.array(Berry_y))\n",
    "roc_auc_Berry = roc_auc_score(np.array(Berry_y), bst.predict(dBerry))\n",
    "print(\"Accuracy on Berry validation set: %s, ROC-AUC score for test set: %s\"  % (acc_test_Berry, roc_auc_Berry))\n",
    "\n",
    "dOat = xgb.DMatrix(np.array(Oat_X), label = np.array(Oat_y), feature_names= feature_names)\n",
    "\n",
    "y_test_Oat_pred = np.round(bst.predict(dOat))\n",
    "acc_test_Oat = np.mean(y_test_Oat_pred == np.array(Oat_y))\n",
    "roc_auc_Oat = roc_auc_score(np.array(Oat_y), bst.predict(dOat))\n",
    "print(\"Accuracy on Oat validation set: %s, ROC-AUC score for test set: %s\"  % (acc_test_Oat, roc_auc_Oat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.5169972652560235, 0.4844586955185631)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import matthews_corrcoef\n",
    "matthews_corrcoef(Oat_y, np.round(bst.predict(dOat))), matthews_corrcoef(Berry_y, np.round(bst.predict(dBerry)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adding no Yang et al. data to the training set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\alexk\\anaconda3\\envs\\Protein\\lib\\site-packages\\pandas\\core\\ops\\array_ops.py:56: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  result = libops.scalar_compare(x.ravel(), y, op)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[19:36:12] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[0]\teval-logloss:0.71850\ttrain-logloss:0.60039\n",
      "[1]\teval-logloss:0.72579\ttrain-logloss:0.53749\n",
      "[2]\teval-logloss:0.74438\ttrain-logloss:0.50110\n",
      "[3]\teval-logloss:0.73915\ttrain-logloss:0.46993\n",
      "[4]\teval-logloss:0.74773\ttrain-logloss:0.44709\n",
      "[5]\teval-logloss:0.73408\ttrain-logloss:0.42411\n",
      "[6]\teval-logloss:0.72672\ttrain-logloss:0.41035\n",
      "[7]\teval-logloss:0.72813\ttrain-logloss:0.39732\n",
      "[8]\teval-logloss:0.72528\ttrain-logloss:0.38801\n",
      "[9]\teval-logloss:0.72715\ttrain-logloss:0.37413\n",
      "[10]\teval-logloss:0.74048\ttrain-logloss:0.36245\n",
      "[11]\teval-logloss:0.73173\ttrain-logloss:0.35791\n",
      "[12]\teval-logloss:0.72918\ttrain-logloss:0.34602\n",
      "[13]\teval-logloss:0.73268\ttrain-logloss:0.33752\n",
      "[14]\teval-logloss:0.71653\ttrain-logloss:0.33311\n",
      "[15]\teval-logloss:0.70905\ttrain-logloss:0.32405\n",
      "[16]\teval-logloss:0.70941\ttrain-logloss:0.32001\n",
      "[17]\teval-logloss:0.71234\ttrain-logloss:0.31638\n",
      "[18]\teval-logloss:0.71050\ttrain-logloss:0.31020\n",
      "[19]\teval-logloss:0.69440\ttrain-logloss:0.30532\n",
      "[20]\teval-logloss:0.69363\ttrain-logloss:0.30052\n",
      "[21]\teval-logloss:0.69370\ttrain-logloss:0.29570\n",
      "[22]\teval-logloss:0.69180\ttrain-logloss:0.29057\n",
      "[23]\teval-logloss:0.68960\ttrain-logloss:0.28749\n",
      "[24]\teval-logloss:0.69021\ttrain-logloss:0.28273\n",
      "[25]\teval-logloss:0.69339\ttrain-logloss:0.27892\n",
      "[26]\teval-logloss:0.69617\ttrain-logloss:0.27509\n",
      "[27]\teval-logloss:0.69044\ttrain-logloss:0.27131\n",
      "[28]\teval-logloss:0.68670\ttrain-logloss:0.26673\n",
      "[29]\teval-logloss:0.69262\ttrain-logloss:0.26288\n",
      "[30]\teval-logloss:0.69267\ttrain-logloss:0.25855\n",
      "[31]\teval-logloss:0.68657\ttrain-logloss:0.25614\n",
      "[32]\teval-logloss:0.68460\ttrain-logloss:0.25283\n",
      "[33]\teval-logloss:0.66665\ttrain-logloss:0.24956\n",
      "[34]\teval-logloss:0.66614\ttrain-logloss:0.24793\n",
      "[35]\teval-logloss:0.65896\ttrain-logloss:0.24549\n",
      "[36]\teval-logloss:0.65907\ttrain-logloss:0.24039\n",
      "[37]\teval-logloss:0.65817\ttrain-logloss:0.23929\n",
      "[38]\teval-logloss:0.65323\ttrain-logloss:0.23446\n",
      "[39]\teval-logloss:0.64904\ttrain-logloss:0.23241\n",
      "[40]\teval-logloss:0.65386\ttrain-logloss:0.23044\n",
      "[41]\teval-logloss:0.65091\ttrain-logloss:0.22831\n",
      "[42]\teval-logloss:0.65092\ttrain-logloss:0.22689\n",
      "[43]\teval-logloss:0.65166\ttrain-logloss:0.22496\n",
      "[44]\teval-logloss:0.65107\ttrain-logloss:0.22309\n",
      "[45]\teval-logloss:0.65312\ttrain-logloss:0.22112\n",
      "[46]\teval-logloss:0.65058\ttrain-logloss:0.21862\n",
      "[47]\teval-logloss:0.64664\ttrain-logloss:0.21528\n",
      "[48]\teval-logloss:0.65503\ttrain-logloss:0.21274\n",
      "[49]\teval-logloss:0.65802\ttrain-logloss:0.21027\n",
      "[50]\teval-logloss:0.65874\ttrain-logloss:0.20875\n",
      "[51]\teval-logloss:0.65556\ttrain-logloss:0.20646\n",
      "[52]\teval-logloss:0.63798\ttrain-logloss:0.20291\n",
      "[53]\teval-logloss:0.63553\ttrain-logloss:0.20101\n",
      "[54]\teval-logloss:0.64218\ttrain-logloss:0.19918\n",
      "[55]\teval-logloss:0.64208\ttrain-logloss:0.19720\n",
      "[56]\teval-logloss:0.63528\ttrain-logloss:0.19398\n",
      "[57]\teval-logloss:0.63645\ttrain-logloss:0.19179\n",
      "[58]\teval-logloss:0.63531\ttrain-logloss:0.18979\n",
      "[59]\teval-logloss:0.63628\ttrain-logloss:0.18762\n",
      "[60]\teval-logloss:0.63717\ttrain-logloss:0.18645\n",
      "[61]\teval-logloss:0.63465\ttrain-logloss:0.18451\n",
      "[62]\teval-logloss:0.63086\ttrain-logloss:0.18316\n",
      "[63]\teval-logloss:0.62538\ttrain-logloss:0.18179\n",
      "[64]\teval-logloss:0.62339\ttrain-logloss:0.18048\n",
      "[65]\teval-logloss:0.62425\ttrain-logloss:0.17922\n",
      "[66]\teval-logloss:0.62562\ttrain-logloss:0.17708\n",
      "[67]\teval-logloss:0.61701\ttrain-logloss:0.17585\n",
      "[68]\teval-logloss:0.61712\ttrain-logloss:0.17485\n",
      "[69]\teval-logloss:0.61869\ttrain-logloss:0.17362\n",
      "[70]\teval-logloss:0.62065\ttrain-logloss:0.17272\n",
      "[71]\teval-logloss:0.61767\ttrain-logloss:0.17132\n",
      "[72]\teval-logloss:0.61969\ttrain-logloss:0.17027\n",
      "[73]\teval-logloss:0.62418\ttrain-logloss:0.16835\n",
      "[74]\teval-logloss:0.62335\ttrain-logloss:0.16704\n",
      "[75]\teval-logloss:0.62213\ttrain-logloss:0.16523\n",
      "[76]\teval-logloss:0.62535\ttrain-logloss:0.16444\n",
      "[77]\teval-logloss:0.62457\ttrain-logloss:0.16325\n",
      "[78]\teval-logloss:0.62973\ttrain-logloss:0.16109\n",
      "[79]\teval-logloss:0.62674\ttrain-logloss:0.15995\n",
      "[80]\teval-logloss:0.62508\ttrain-logloss:0.15895\n",
      "[81]\teval-logloss:0.62334\ttrain-logloss:0.15795\n",
      "[82]\teval-logloss:0.62388\ttrain-logloss:0.15723\n",
      "[83]\teval-logloss:0.62256\ttrain-logloss:0.15634\n",
      "[84]\teval-logloss:0.62251\ttrain-logloss:0.15462\n",
      "[85]\teval-logloss:0.62314\ttrain-logloss:0.15367\n",
      "[86]\teval-logloss:0.62006\ttrain-logloss:0.15259\n",
      "[87]\teval-logloss:0.62115\ttrain-logloss:0.15166\n",
      "[88]\teval-logloss:0.61918\ttrain-logloss:0.15026\n",
      "[89]\teval-logloss:0.61681\ttrain-logloss:0.14888\n",
      "[90]\teval-logloss:0.61574\ttrain-logloss:0.14775\n",
      "[91]\teval-logloss:0.61818\ttrain-logloss:0.14641\n",
      "[92]\teval-logloss:0.61713\ttrain-logloss:0.14538\n",
      "[93]\teval-logloss:0.61498\ttrain-logloss:0.14351\n",
      "[94]\teval-logloss:0.61513\ttrain-logloss:0.14287\n",
      "[95]\teval-logloss:0.61408\ttrain-logloss:0.14162\n",
      "[96]\teval-logloss:0.61716\ttrain-logloss:0.13957\n",
      "[97]\teval-logloss:0.61898\ttrain-logloss:0.13871\n",
      "[98]\teval-logloss:0.61610\ttrain-logloss:0.13756\n",
      "[99]\teval-logloss:0.61789\ttrain-logloss:0.13679\n",
      "[100]\teval-logloss:0.61759\ttrain-logloss:0.13608\n",
      "[101]\teval-logloss:0.61745\ttrain-logloss:0.13493\n",
      "[102]\teval-logloss:0.61853\ttrain-logloss:0.13395\n",
      "[103]\teval-logloss:0.62005\ttrain-logloss:0.13297\n",
      "[104]\teval-logloss:0.61916\ttrain-logloss:0.13218\n",
      "[105]\teval-logloss:0.62229\ttrain-logloss:0.13158\n",
      "[106]\teval-logloss:0.62235\ttrain-logloss:0.13008\n",
      "[107]\teval-logloss:0.63149\ttrain-logloss:0.12905\n",
      "[108]\teval-logloss:0.63985\ttrain-logloss:0.12824\n",
      "[109]\teval-logloss:0.63921\ttrain-logloss:0.12760\n",
      "[110]\teval-logloss:0.63801\ttrain-logloss:0.12665\n",
      "[111]\teval-logloss:0.63584\ttrain-logloss:0.12607\n",
      "[112]\teval-logloss:0.63454\ttrain-logloss:0.12507\n",
      "[113]\teval-logloss:0.63353\ttrain-logloss:0.12390\n",
      "[114]\teval-logloss:0.63459\ttrain-logloss:0.12329\n",
      "[115]\teval-logloss:0.63377\ttrain-logloss:0.12255\n",
      "[116]\teval-logloss:0.63123\ttrain-logloss:0.12178\n",
      "[117]\teval-logloss:0.62987\ttrain-logloss:0.12034\n",
      "[118]\teval-logloss:0.64085\ttrain-logloss:0.11973\n",
      "[119]\teval-logloss:0.64079\ttrain-logloss:0.11927\n",
      "[120]\teval-logloss:0.65466\ttrain-logloss:0.11863\n",
      "[121]\teval-logloss:0.65489\ttrain-logloss:0.11788\n",
      "[122]\teval-logloss:0.65473\ttrain-logloss:0.11685\n",
      "[123]\teval-logloss:0.65439\ttrain-logloss:0.11628\n",
      "[124]\teval-logloss:0.65580\ttrain-logloss:0.11538\n",
      "[125]\teval-logloss:0.65913\ttrain-logloss:0.11476\n",
      "[126]\teval-logloss:0.65490\ttrain-logloss:0.11422\n",
      "[127]\teval-logloss:0.65914\ttrain-logloss:0.11317\n",
      "[128]\teval-logloss:0.65765\ttrain-logloss:0.11229\n",
      "[129]\teval-logloss:0.65643\ttrain-logloss:0.11143\n",
      "[130]\teval-logloss:0.65153\ttrain-logloss:0.11002\n",
      "[131]\teval-logloss:0.66180\ttrain-logloss:0.10917\n",
      "[132]\teval-logloss:0.65804\ttrain-logloss:0.10843\n",
      "[133]\teval-logloss:0.65671\ttrain-logloss:0.10792\n",
      "[134]\teval-logloss:0.65447\ttrain-logloss:0.10753\n",
      "[135]\teval-logloss:0.65230\ttrain-logloss:0.10688\n",
      "[136]\teval-logloss:0.65990\ttrain-logloss:0.10575\n",
      "[137]\teval-logloss:0.66178\ttrain-logloss:0.10500\n",
      "[138]\teval-logloss:0.66307\ttrain-logloss:0.10438\n",
      "[139]\teval-logloss:0.67209\ttrain-logloss:0.10367\n",
      "[140]\teval-logloss:0.67160\ttrain-logloss:0.10315\n",
      "[141]\teval-logloss:0.67866\ttrain-logloss:0.10260\n",
      "[142]\teval-logloss:0.67895\ttrain-logloss:0.10207\n",
      "[143]\teval-logloss:0.67892\ttrain-logloss:0.10152\n",
      "[144]\teval-logloss:0.67594\ttrain-logloss:0.10031\n",
      "[145]\teval-logloss:0.67599\ttrain-logloss:0.09975\n",
      "[146]\teval-logloss:0.67454\ttrain-logloss:0.09891\n",
      "[147]\teval-logloss:0.67426\ttrain-logloss:0.09850\n",
      "[148]\teval-logloss:0.67161\ttrain-logloss:0.09709\n",
      "[149]\teval-logloss:0.67078\ttrain-logloss:0.09631\n",
      "[150]\teval-logloss:0.67089\ttrain-logloss:0.09580\n",
      "[151]\teval-logloss:0.67122\ttrain-logloss:0.09539\n",
      "[152]\teval-logloss:0.66980\ttrain-logloss:0.09412\n",
      "[153]\teval-logloss:0.68792\ttrain-logloss:0.09340\n",
      "[154]\teval-logloss:0.68766\ttrain-logloss:0.09287\n",
      "[155]\teval-logloss:0.68997\ttrain-logloss:0.09221\n",
      "[156]\teval-logloss:0.68711\ttrain-logloss:0.09119\n",
      "[157]\teval-logloss:0.68393\ttrain-logloss:0.09074\n",
      "[158]\teval-logloss:0.68516\ttrain-logloss:0.09032\n",
      "[159]\teval-logloss:0.68589\ttrain-logloss:0.09003\n",
      "[160]\teval-logloss:0.69282\ttrain-logloss:0.08947\n",
      "[161]\teval-logloss:0.69242\ttrain-logloss:0.08919\n",
      "[162]\teval-logloss:0.69094\ttrain-logloss:0.08873\n",
      "[163]\teval-logloss:0.69355\ttrain-logloss:0.08833\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[164]\teval-logloss:0.69821\ttrain-logloss:0.08786\n",
      "[165]\teval-logloss:0.69782\ttrain-logloss:0.08750\n",
      "[166]\teval-logloss:0.69797\ttrain-logloss:0.08707\n",
      "[167]\teval-logloss:0.70249\ttrain-logloss:0.08658\n",
      "[168]\teval-logloss:0.70677\ttrain-logloss:0.08617\n",
      "[169]\teval-logloss:0.70782\ttrain-logloss:0.08555\n",
      "[170]\teval-logloss:0.71241\ttrain-logloss:0.08453\n",
      "[171]\teval-logloss:0.71293\ttrain-logloss:0.08410\n",
      "[172]\teval-logloss:0.71016\ttrain-logloss:0.08380\n",
      "[173]\teval-logloss:0.70948\ttrain-logloss:0.08350\n",
      "[174]\teval-logloss:0.71331\ttrain-logloss:0.08326\n",
      "[175]\teval-logloss:0.71472\ttrain-logloss:0.08274\n",
      "[176]\teval-logloss:0.71597\ttrain-logloss:0.08218\n",
      "[177]\teval-logloss:0.71648\ttrain-logloss:0.08165\n",
      "[178]\teval-logloss:0.71549\ttrain-logloss:0.08118\n",
      "[179]\teval-logloss:0.71477\ttrain-logloss:0.08075\n",
      "[180]\teval-logloss:0.71448\ttrain-logloss:0.08044\n",
      "[181]\teval-logloss:0.70504\ttrain-logloss:0.07954\n",
      "[182]\teval-logloss:0.70544\ttrain-logloss:0.07922\n",
      "[183]\teval-logloss:0.70581\ttrain-logloss:0.07888\n",
      "[184]\teval-logloss:0.71021\ttrain-logloss:0.07857\n",
      "[185]\teval-logloss:0.71162\ttrain-logloss:0.07831\n",
      "[186]\teval-logloss:0.70807\ttrain-logloss:0.07780\n",
      "[187]\teval-logloss:0.71084\ttrain-logloss:0.07726\n",
      "[188]\teval-logloss:0.71222\ttrain-logloss:0.07704\n",
      "[189]\teval-logloss:0.71151\ttrain-logloss:0.07666\n",
      "[190]\teval-logloss:0.71163\ttrain-logloss:0.07615\n",
      "[191]\teval-logloss:0.71314\ttrain-logloss:0.07574\n",
      "[192]\teval-logloss:0.71356\ttrain-logloss:0.07539\n",
      "[193]\teval-logloss:0.71250\ttrain-logloss:0.07510\n",
      "[194]\teval-logloss:0.71670\ttrain-logloss:0.07484\n",
      "[195]\teval-logloss:0.71992\ttrain-logloss:0.07446\n",
      "[196]\teval-logloss:0.72024\ttrain-logloss:0.07424\n",
      "[197]\teval-logloss:0.71892\ttrain-logloss:0.07391\n",
      "[198]\teval-logloss:0.71845\ttrain-logloss:0.07372\n",
      "[199]\teval-logloss:0.71525\ttrain-logloss:0.07346\n",
      "[200]\teval-logloss:0.71195\ttrain-logloss:0.07306\n",
      "[201]\teval-logloss:0.71074\ttrain-logloss:0.07286\n",
      "[202]\teval-logloss:0.71087\ttrain-logloss:0.07240\n",
      "[203]\teval-logloss:0.71239\ttrain-logloss:0.07209\n",
      "[204]\teval-logloss:0.71396\ttrain-logloss:0.07174\n",
      "[205]\teval-logloss:0.71219\ttrain-logloss:0.07154\n",
      "[206]\teval-logloss:0.71187\ttrain-logloss:0.07115\n",
      "[207]\teval-logloss:0.71649\ttrain-logloss:0.07078\n",
      "[208]\teval-logloss:0.71619\ttrain-logloss:0.07056\n",
      "[209]\teval-logloss:0.71564\ttrain-logloss:0.07036\n",
      "[210]\teval-logloss:0.71900\ttrain-logloss:0.07014\n",
      "[211]\teval-logloss:0.72172\ttrain-logloss:0.06985\n",
      "[212]\teval-logloss:0.72215\ttrain-logloss:0.06960\n",
      "[213]\teval-logloss:0.72127\ttrain-logloss:0.06928\n",
      "[214]\teval-logloss:0.72149\ttrain-logloss:0.06900\n",
      "[215]\teval-logloss:0.72316\ttrain-logloss:0.06875\n",
      "[216]\teval-logloss:0.72375\ttrain-logloss:0.06840\n",
      "[217]\teval-logloss:0.72250\ttrain-logloss:0.06826\n",
      "[218]\teval-logloss:0.72123\ttrain-logloss:0.06799\n",
      "[219]\teval-logloss:0.72017\ttrain-logloss:0.06762\n",
      "[220]\teval-logloss:0.72093\ttrain-logloss:0.06735\n",
      "[221]\teval-logloss:0.72360\ttrain-logloss:0.06709\n",
      "[222]\teval-logloss:0.72281\ttrain-logloss:0.06680\n",
      "[223]\teval-logloss:0.72861\ttrain-logloss:0.06656\n",
      "[224]\teval-logloss:0.72879\ttrain-logloss:0.06617\n",
      "[225]\teval-logloss:0.72878\ttrain-logloss:0.06599\n",
      "[226]\teval-logloss:0.73087\ttrain-logloss:0.06574\n",
      "[227]\teval-logloss:0.73090\ttrain-logloss:0.06538\n",
      "[228]\teval-logloss:0.73040\ttrain-logloss:0.06511\n",
      "[229]\teval-logloss:0.72944\ttrain-logloss:0.06481\n",
      "[230]\teval-logloss:0.72946\ttrain-logloss:0.06454\n",
      "[231]\teval-logloss:0.72965\ttrain-logloss:0.06427\n",
      "[232]\teval-logloss:0.73358\ttrain-logloss:0.06398\n",
      "[233]\teval-logloss:0.73411\ttrain-logloss:0.06377\n",
      "[234]\teval-logloss:0.73350\ttrain-logloss:0.06342\n",
      "[235]\teval-logloss:0.73375\ttrain-logloss:0.06318\n",
      "[236]\teval-logloss:0.73472\ttrain-logloss:0.06301\n",
      "[237]\teval-logloss:0.73223\ttrain-logloss:0.06245\n",
      "[238]\teval-logloss:0.73277\ttrain-logloss:0.06223\n",
      "[239]\teval-logloss:0.73274\ttrain-logloss:0.06195\n",
      "[240]\teval-logloss:0.73313\ttrain-logloss:0.06169\n",
      "[241]\teval-logloss:0.73316\ttrain-logloss:0.06145\n",
      "[242]\teval-logloss:0.73218\ttrain-logloss:0.06110\n",
      "[243]\teval-logloss:0.73011\ttrain-logloss:0.06092\n",
      "[244]\teval-logloss:0.73586\ttrain-logloss:0.06064\n",
      "[245]\teval-logloss:0.73194\ttrain-logloss:0.06001\n",
      "[246]\teval-logloss:0.73216\ttrain-logloss:0.05976\n",
      "[247]\teval-logloss:0.73499\ttrain-logloss:0.05924\n",
      "[248]\teval-logloss:0.73451\ttrain-logloss:0.05891\n",
      "[249]\teval-logloss:0.73669\ttrain-logloss:0.05862\n",
      "[250]\teval-logloss:0.73309\ttrain-logloss:0.05840\n",
      "[251]\teval-logloss:0.73035\ttrain-logloss:0.05813\n",
      "[252]\teval-logloss:0.72966\ttrain-logloss:0.05789\n",
      "[253]\teval-logloss:0.72982\ttrain-logloss:0.05751\n",
      "[254]\teval-logloss:0.72988\ttrain-logloss:0.05730\n",
      "[255]\teval-logloss:0.72388\ttrain-logloss:0.05704\n",
      "[256]\teval-logloss:0.72297\ttrain-logloss:0.05669\n",
      "[257]\teval-logloss:0.72326\ttrain-logloss:0.05649\n",
      "[258]\teval-logloss:0.72245\ttrain-logloss:0.05628\n",
      "[259]\teval-logloss:0.72302\ttrain-logloss:0.05606\n",
      "[260]\teval-logloss:0.72538\ttrain-logloss:0.05574\n",
      "[261]\teval-logloss:0.73191\ttrain-logloss:0.05544\n",
      "[262]\teval-logloss:0.73272\ttrain-logloss:0.05506\n",
      "[263]\teval-logloss:0.73410\ttrain-logloss:0.05492\n",
      "[264]\teval-logloss:0.73274\ttrain-logloss:0.05483\n",
      "[265]\teval-logloss:0.73434\ttrain-logloss:0.05446\n",
      "[266]\teval-logloss:0.73837\ttrain-logloss:0.05422\n",
      "[267]\teval-logloss:0.74716\ttrain-logloss:0.05402\n",
      "[268]\teval-logloss:0.74692\ttrain-logloss:0.05388\n",
      "[269]\teval-logloss:0.74770\ttrain-logloss:0.05369\n",
      "[270]\teval-logloss:0.74776\ttrain-logloss:0.05349\n",
      "[271]\teval-logloss:0.75336\ttrain-logloss:0.05331\n",
      "[272]\teval-logloss:0.75239\ttrain-logloss:0.05313\n",
      "[273]\teval-logloss:0.75562\ttrain-logloss:0.05297\n",
      "[274]\teval-logloss:0.76053\ttrain-logloss:0.05273\n",
      "[275]\teval-logloss:0.76384\ttrain-logloss:0.05256\n",
      "[276]\teval-logloss:0.76328\ttrain-logloss:0.05225\n",
      "[277]\teval-logloss:0.76347\ttrain-logloss:0.05213\n",
      "[278]\teval-logloss:0.76391\ttrain-logloss:0.05194\n",
      "[279]\teval-logloss:0.76304\ttrain-logloss:0.05171\n",
      "[280]\teval-logloss:0.76207\ttrain-logloss:0.05154\n",
      "[281]\teval-logloss:0.76050\ttrain-logloss:0.05123\n",
      "[282]\teval-logloss:0.76063\ttrain-logloss:0.05106\n",
      "[283]\teval-logloss:0.76063\ttrain-logloss:0.05095\n",
      "[284]\teval-logloss:0.76060\ttrain-logloss:0.05070\n",
      "[285]\teval-logloss:0.76051\ttrain-logloss:0.05050\n",
      "[286]\teval-logloss:0.75981\ttrain-logloss:0.05029\n",
      "[287]\teval-logloss:0.75987\ttrain-logloss:0.05017\n",
      "[288]\teval-logloss:0.75918\ttrain-logloss:0.04990\n",
      "[289]\teval-logloss:0.75880\ttrain-logloss:0.04967\n",
      "[290]\teval-logloss:0.75909\ttrain-logloss:0.04960\n",
      "[291]\teval-logloss:0.75802\ttrain-logloss:0.04947\n",
      "[292]\teval-logloss:0.75750\ttrain-logloss:0.04930\n",
      "[293]\teval-logloss:0.75616\ttrain-logloss:0.04912\n",
      "[294]\teval-logloss:0.75564\ttrain-logloss:0.04898\n",
      "[295]\teval-logloss:0.75579\ttrain-logloss:0.04883\n",
      "[296]\teval-logloss:0.75290\ttrain-logloss:0.04866\n",
      "[297]\teval-logloss:0.75330\ttrain-logloss:0.04854\n",
      "[298]\teval-logloss:0.75359\ttrain-logloss:0.04834\n",
      "[299]\teval-logloss:0.75350\ttrain-logloss:0.04815\n",
      "[300]\teval-logloss:0.75573\ttrain-logloss:0.04792\n",
      "[301]\teval-logloss:0.75593\ttrain-logloss:0.04774\n",
      "[302]\teval-logloss:0.75500\ttrain-logloss:0.04759\n",
      "[303]\teval-logloss:0.75474\ttrain-logloss:0.04745\n",
      "[304]\teval-logloss:0.75342\ttrain-logloss:0.04734\n",
      "[305]\teval-logloss:0.75397\ttrain-logloss:0.04716\n",
      "[306]\teval-logloss:0.75838\ttrain-logloss:0.04701\n",
      "[307]\teval-logloss:0.75803\ttrain-logloss:0.04682\n",
      "[308]\teval-logloss:0.76034\ttrain-logloss:0.04667\n",
      "[309]\teval-logloss:0.76074\ttrain-logloss:0.04652\n",
      "[310]\teval-logloss:0.76149\ttrain-logloss:0.04621\n",
      "[311]\teval-logloss:0.76206\ttrain-logloss:0.04605\n",
      "[312]\teval-logloss:0.76265\ttrain-logloss:0.04587\n",
      "[313]\teval-logloss:0.76230\ttrain-logloss:0.04566\n",
      "[314]\teval-logloss:0.76167\ttrain-logloss:0.04553\n",
      "[315]\teval-logloss:0.76231\ttrain-logloss:0.04536\n",
      "[316]\teval-logloss:0.76481\ttrain-logloss:0.04520\n",
      "[317]\teval-logloss:0.76101\ttrain-logloss:0.04497\n",
      "[318]\teval-logloss:0.76588\ttrain-logloss:0.04483\n",
      "[319]\teval-logloss:0.76658\ttrain-logloss:0.04465\n",
      "[320]\teval-logloss:0.77194\ttrain-logloss:0.04448\n",
      "[321]\teval-logloss:0.77179\ttrain-logloss:0.04433\n",
      "[322]\teval-logloss:0.77186\ttrain-logloss:0.04420\n",
      "[323]\teval-logloss:0.77552\ttrain-logloss:0.04406\n",
      "[324]\teval-logloss:0.77915\ttrain-logloss:0.04389\n",
      "[325]\teval-logloss:0.77770\ttrain-logloss:0.04377\n",
      "[326]\teval-logloss:0.77759\ttrain-logloss:0.04364\n",
      "[327]\teval-logloss:0.77936\ttrain-logloss:0.04350\n",
      "[328]\teval-logloss:0.77885\ttrain-logloss:0.04328\n",
      "[329]\teval-logloss:0.77831\ttrain-logloss:0.04315\n",
      "[330]\teval-logloss:0.77910\ttrain-logloss:0.04305\n",
      "[331]\teval-logloss:0.78018\ttrain-logloss:0.04290\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[332]\teval-logloss:0.77896\ttrain-logloss:0.04277\n",
      "[333]\teval-logloss:0.78326\ttrain-logloss:0.04266\n",
      "[334]\teval-logloss:0.78384\ttrain-logloss:0.04255\n",
      "[335]\teval-logloss:0.78561\ttrain-logloss:0.04234\n",
      "[336]\teval-logloss:0.78621\ttrain-logloss:0.04221\n",
      "[337]\teval-logloss:0.78672\ttrain-logloss:0.04208\n",
      "[338]\teval-logloss:0.79092\ttrain-logloss:0.04196\n",
      "[339]\teval-logloss:0.79200\ttrain-logloss:0.04179\n",
      "[340]\teval-logloss:0.79240\ttrain-logloss:0.04167\n",
      "[341]\teval-logloss:0.79287\ttrain-logloss:0.04150\n",
      "Accuracy on test set: 0.9060352554526442, ROC-AUC score for test set: 0.9502409054481795\n",
      "All enzymes:\n",
      "Accuracy on test set: 0.7024938531787847, ROC-AUC score for test set: 0.4906107802462527\n",
      "Accuracy on Berry validation set: 0.6578947368421053, ROC-AUC score for test set: 0.5614475675327602\n",
      "Accuracy on Oat validation set: 0.6804511278195489, ROC-AUC score for test set: 0.587721054387721\n"
     ]
    }
   ],
   "source": [
    "\n",
    "df_train = pd.read_pickle(join(CURRENT_DIR, \"..\" ,\"data\",\n",
    "                               \"splits\", \"df_train_with_ESM1b_ts.pkl\"))\n",
    "df_train = df_train.loc[df_train[\"ESM1b_ts\"] != \"\"]\n",
    "df_train.reset_index(inplace = True, drop = True)\n",
    "\n",
    "\n",
    "train_X, train_y =  create_input_and_output_data(df = df_train)\n",
    "test_X, test_y =  create_input_and_output_data(df = df_test)\n",
    "\n",
    "df_test_new = df_Mou.copy()\n",
    "test_new_X, test_new_y =  create_input_and_output_data(df = df_test_new)\n",
    "\n",
    "\n",
    "\n",
    "X_train_Mou = test_new_X\n",
    "y_train_Mou = test_new_y\n",
    "\n",
    "\n",
    "Berry_X, Berry_y =  create_input_and_output_data(df = df_Berry)\n",
    "Oat_X, Oat_y =  create_input_and_output_data(df = df_Oat)\n",
    "\n",
    "\n",
    "param = {'learning_rate': 0.31553117247348733,\n",
    "         'max_delta_step': 1.7726044219753656,\n",
    "         'max_depth': 10,\n",
    "         'min_child_weight': 1.3845040588450772,\n",
    "         'num_rounds': 342.68325188584106,\n",
    "         'reg_alpha': 0.531395259755843,\n",
    "         'reg_lambda': 3.744980563764689,\n",
    "         'weight': 0.26187490421514203}\n",
    "\n",
    "num_round = param[\"num_rounds\"]\n",
    "param[\"tree_method\"] = \"gpu_hist\"\n",
    "param[\"sampling_method\"] = \"gradient_based\"\n",
    "param['objective'] = 'binary:logistic'\n",
    "\n",
    "\n",
    "weights =  np.array([param[\"weight\"] if binding == 0 else 1.0 for binding in np.array(train_y)])\n",
    "\n",
    "\n",
    "del param[\"num_rounds\"]\n",
    "del param[\"weight\"]\n",
    "\n",
    "dtrain = xgb.DMatrix(np.array(train_X), weight = weights, label = np.array(train_y),\n",
    "            feature_names= feature_names)\n",
    "dtest = xgb.DMatrix(np.array(test_X), label = np.array(test_y),\n",
    "                    feature_names= feature_names)\n",
    "\n",
    "dtest_new = xgb.DMatrix(np.array(test_new_X), label = np.array(test_new_y), feature_names= feature_names)\n",
    "dOat = xgb.DMatrix(np.array(Oat_X), label = np.array(Oat_y), feature_names= feature_names)\n",
    "\n",
    "evallist = [(dOat, 'eval'), (dtrain, 'train')]\n",
    "\n",
    "bst = xgb.train(param,  dtrain, int(num_round),evallist, verbose_eval=1)\n",
    "y_test_pred = np.round(bst.predict(dtest))\n",
    "acc_test = np.mean(y_test_pred == np.array(test_y))\n",
    "roc_auc = roc_auc_score(np.array(test_y), bst.predict(dtest))\n",
    "\n",
    "print(\"Accuracy on test set: %s, ROC-AUC score for test set: %s\"  % (acc_test, roc_auc))\n",
    "\n",
    "\n",
    "y_test_new_pred = np.round(bst.predict(dtest_new))\n",
    "acc_test_new = np.mean(y_test_new_pred == np.array(test_new_y))\n",
    "roc_auc_new = roc_auc_score(np.array(test_new_y), bst.predict(dtest_new))\n",
    "\n",
    "print(\"All enzymes:\")\n",
    "print(\"Accuracy on test set: %s, ROC-AUC score for test set: %s\"  % (acc_test_new, roc_auc_new))\n",
    "\n",
    "dBerry = xgb.DMatrix(np.array(Berry_X), label = np.array(Berry_y), feature_names= feature_names)\n",
    "\n",
    "y_test_Berry_pred = np.round(bst.predict(dBerry))\n",
    "acc_test_Berry = np.mean(y_test_Berry_pred == np.array(Berry_y))\n",
    "roc_auc_Berry = roc_auc_score(np.array(Berry_y), bst.predict(dBerry))\n",
    "print(\"Accuracy on Berry validation set: %s, ROC-AUC score for test set: %s\"  % (acc_test_Berry, roc_auc_Berry))\n",
    "\n",
    "dOat = xgb.DMatrix(np.array(Oat_X), label = np.array(Oat_y), feature_names= feature_names)\n",
    "\n",
    "y_test_Oat_pred = np.round(bst.predict(dOat))\n",
    "acc_test_Oat = np.mean(y_test_Oat_pred == np.array(Oat_y))\n",
    "roc_auc_Oat = roc_auc_score(np.array(Oat_y), bst.predict(dOat))\n",
    "print(\"Accuracy on Oat validation set: %s, ROC-AUC score for test set: %s\"  % (acc_test_Oat, roc_auc_Oat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.12029878923247857, 0.0060553002732513465)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import matthews_corrcoef\n",
    "matthews_corrcoef(Oat_y, np.round(bst.predict(dOat))), matthews_corrcoef(Berry_y, np.round(bst.predict(dBerry)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
