{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training gradient boosting model for enzyme-substrate pair prediction with ESM-1b-vectors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Loading and preprocessing data for model training and evaluation\n",
    "### 2. Hyperparameter optimization using a 5-fold cross-validation (CV)\n",
    "### 3. Training and validating the final model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\alexk\\anaconda3\\envs\\ESP\\lib\\site-packages\\scipy\\__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.1\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\alexk\\projects\\ESP\\notebooks_and_code\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import pickle\n",
    "import sys\n",
    "import os\n",
    "import logging\n",
    "from os.path import join\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from hyperopt import fmin, tpe, hp, Trials, rand\n",
    "import xgboost as xgb\n",
    "from sklearn.metrics import matthews_corrcoef\n",
    "\n",
    "\n",
    "sys.path.append('.\\\\additional_code')\n",
    "#from data_preprocessing import *\n",
    "\n",
    "CURRENT_DIR = os.getcwd()\n",
    "print(CURRENT_DIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Loading and preprocessing data for model training and evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def array_column_to_strings(df, column):\n",
    "    df[column] = [str(list(df[column][ind])) for ind in df.index]\n",
    "    return(df)\n",
    "\n",
    "def string_column_to_array(df, column):\n",
    "    df[column] = [np.array(eval(df[column][ind])) for ind in df.index]\n",
    "    return(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (a) Loading data: \n",
    "Only keeping data points from the GO Annotation database with experimental evidence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\alexk\\anaconda3\\envs\\ESP\\lib\\site-packages\\pandas\\core\\ops\\array_ops.py:73: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  result = libops.scalar_compare(x.ravel(), y, op)\n",
      "C:\\Users\\alexk\\anaconda3\\envs\\ESP\\lib\\site-packages\\pandas\\core\\ops\\array_ops.py:73: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  result = libops.scalar_compare(x.ravel(), y, op)\n"
     ]
    }
   ],
   "source": [
    "df_train = pd.read_pickle(join(CURRENT_DIR, \"..\" ,\"data\",\"splits\", \"df_train_with_ESM1b_ts_GNN.pkl\"))\n",
    "df_train = df_train.loc[df_train[\"ESM1b\"] != \"\"]\n",
    "df_train = df_train.loc[df_train[\"type\"] != \"engqvist\"]\n",
    "df_train = df_train.loc[df_train[\"GNN rep\"] != \"\"]\n",
    "df_train.reset_index(inplace = True, drop = True)\n",
    "\n",
    "df_test  = pd.read_pickle(join(CURRENT_DIR, \"..\" ,\"data\",\"splits\", \"df_test_with_ESM1b_ts_GNN.pkl\"))\n",
    "df_test = df_test.loc[df_test[\"ESM1b\"] != \"\"]\n",
    "df_test = df_test.loc[df_test[\"type\"] != \"engqvist\"]\n",
    "df_test = df_test.loc[df_test[\"GNN rep\"] != \"\"]\n",
    "df_test.reset_index(inplace = True, drop = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (b) Splitting training set into 5-folds for hyperparameter optimization:\n",
    "The 5 folds are created in such a way that the same enzyme does not occure in two different folds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_dataframe(df, frac):\n",
    "    df1 = pd.DataFrame(columns = list(df.columns))\n",
    "    df2 = pd.DataFrame(columns = list(df.columns))\n",
    "    try:\n",
    "        df.drop(columns = [\"level_0\"], inplace = True)\n",
    "    except: \n",
    "        pass\n",
    "    df.reset_index(inplace = True)\n",
    "    \n",
    "    train_indices = []\n",
    "    test_indices = []\n",
    "    ind = 0\n",
    "    while len(train_indices) +len(test_indices) < len(df):\n",
    "        if ind not in train_indices and ind not in test_indices:\n",
    "            if ind % frac != 0:\n",
    "                n_old = len(train_indices)\n",
    "                train_indices.append(ind)\n",
    "                train_indices = list(set(train_indices))\n",
    "\n",
    "                while n_old != len(train_indices):\n",
    "                    n_old = len(train_indices)\n",
    "\n",
    "                    training_seqs= list(set(df[\"ESM1b\"].loc[train_indices]))\n",
    "\n",
    "                    train_indices = train_indices + (list(df.loc[df[\"ESM1b\"].isin(training_seqs)].index))\n",
    "                    train_indices = list(set(train_indices))\n",
    "                \n",
    "            else:\n",
    "                n_old = len(test_indices)\n",
    "                test_indices.append(ind)\n",
    "                test_indices = list(set(test_indices))\n",
    "\n",
    "                while n_old != len(test_indices):\n",
    "                    n_old = len(test_indices)\n",
    "\n",
    "                    testing_seqs= list(set(df[\"ESM1b\"].loc[test_indices]))\n",
    "\n",
    "                    test_indices = test_indices + (list(df.loc[df[\"ESM1b\"].isin(testing_seqs)].index))\n",
    "                    test_indices = list(set(test_indices))\n",
    "                \n",
    "        ind +=1\n",
    "    return(df.loc[train_indices], df.loc[test_indices])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "44733 11145\n",
      "33555 11178\n",
      "22014 11541\n",
      "10952 11062\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\alexk\\anaconda3\\envs\\ESP\\lib\\site-packages\\numpy\\lib\\npyio.py:501: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  arr = np.asanyarray(arr)\n"
     ]
    }
   ],
   "source": [
    "data_train2 = df_train.copy()\n",
    "data_train2 = array_column_to_strings(data_train2, column = \"ESM1b\")\n",
    "\n",
    "data_train2, df_fold = split_dataframe(df = data_train2, frac=5)\n",
    "indices_fold1 = list(df_fold[\"index\"])\n",
    "print(len(data_train2), len(indices_fold1))#\n",
    "\n",
    "data_train2, df_fold = split_dataframe(df = data_train2, frac=4)\n",
    "indices_fold2 = list(df_fold[\"index\"])\n",
    "print(len(data_train2), len(indices_fold2))\n",
    "\n",
    "data_train2, df_fold = split_dataframe(df = data_train2, frac=3)\n",
    "indices_fold3 = list(df_fold[\"index\"])\n",
    "print(len(data_train2), len(indices_fold3))\n",
    "\n",
    "data_train2, df_fold = split_dataframe(df = data_train2, frac=2)\n",
    "indices_fold4 = list(df_fold[\"index\"])\n",
    "indices_fold5 = list(data_train2[\"index\"])\n",
    "print(len(data_train2), len(indices_fold4))\n",
    "\n",
    "\n",
    "fold_indices = [indices_fold1, indices_fold2, indices_fold3, indices_fold4, indices_fold5]\n",
    "\n",
    "train_indices = [[], [], [], [], []]\n",
    "test_indices = [[], [], [], [], []]\n",
    "\n",
    "for i in range(5):\n",
    "    for j in range(5):\n",
    "        if i != j:\n",
    "            train_indices[i] = train_indices[i] + fold_indices[j]\n",
    "            \n",
    "    test_indices[i] = fold_indices[i]\n",
    "    \n",
    "np.save(join(CURRENT_DIR, \"..\" ,\"data\",\"splits\", \"CV_train_indices.npy\"), train_indices)\n",
    "np.save(join(CURRENT_DIR, \"..\" ,\"data\",\"splits\", \"CV_test_indices.npy\"), test_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_indices = list(np.load(join(CURRENT_DIR, \"..\" ,\"data\",\"splits\", \"CV_train_indices.npy\"),  allow_pickle=True))\n",
    "test_indices = list(np.load(join(CURRENT_DIR, \"..\" ,\"data\",\"splits\", \"CV_test_indices.npy\"),  allow_pickle=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Hyperparameter optimization using a 5-fold cross-validation (CV)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (a) ECFP and ESM1b:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (i) Creating numpy arrays with input vectors and output variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_input_and_output_data(df):\n",
    "    X = ();\n",
    "    y = ();\n",
    "    \n",
    "    for ind in df.index:\n",
    "        emb = df[\"ESM1b\"][ind]\n",
    "        ecfp = np.array(list(df[\"ECFP\"][ind])).astype(int)\n",
    "                \n",
    "        X = X +(np.concatenate([ecfp, emb]), );\n",
    "        y = y + (df[\"Binding\"][ind], );\n",
    "\n",
    "    return(X,y)\n",
    "\n",
    "train_X, train_y =  create_input_and_output_data(df = df_train)\n",
    "test_X, test_y =  create_input_and_output_data(df = df_test)\n",
    "\n",
    "\n",
    "feature_names =  [\"ECFP_\" + str(i) for i in range(1024)]\n",
    "feature_names = feature_names + [\"ESM1b_\" + str(i) for i in range(1280)]\n",
    "\n",
    "train_X = np.array(train_X)\n",
    "test_X  = np.array(test_X)\n",
    "\n",
    "train_y = np.array(train_y)\n",
    "test_y  = np.array(test_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (ii) Performing hyperparameter optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_validation_neg_acc_gradient_boosting(param):\n",
    "    num_round = param[\"num_rounds\"]\n",
    "    param[\"tree_method\"] = \"gpu_hist\"\n",
    "    param[\"sampling_method\"] = \"gradient_based\"\n",
    "    param['objective'] = 'binary:logistic'\n",
    "    weights = np.array([param[\"weight\"] if binding == 0 else 1.0 for binding in df_train[\"Binding\"]])\n",
    "    \n",
    "    del param[\"num_rounds\"]\n",
    "    del param[\"weight\"]\n",
    "    \n",
    "    loss = []\n",
    "    for i in range(5):\n",
    "        train_index, test_index  = train_indices[i], test_indices[i]\n",
    "        dtrain = xgb.DMatrix(np.array(train_X[train_index]), weight = weights[train_index],\n",
    "                         label = np.array(train_y[train_index]))\n",
    "        dvalid = xgb.DMatrix(np.array(train_X[test_index]))\n",
    "        bst = xgb.train(param,  dtrain, int(num_round), verbose_eval=1)\n",
    "        y_valid_pred = np.round(bst.predict(dvalid))\n",
    "        validation_y = train_y[test_index]\n",
    "    \n",
    "        false_positive = 100*(1-np.mean(np.array(validation_y)[y_valid_pred == 1]))\n",
    "        false_negative = 100*(np.mean(np.array(validation_y)[y_valid_pred == 0]))\n",
    "        logging.info(\"False positive rate: \" + str(false_positive)+ \"; False negative rate: \" + str(false_negative))\n",
    "        loss.append(2*(false_negative**2) + false_positive**1.3)\n",
    "    return(np.mean(loss))\n",
    "\n",
    "#Defining search space for hyperparameter optimization\n",
    "space_gradient_boosting = {\"learning_rate\": hp.uniform(\"learning_rate\", 0.01, 0.5),\n",
    "    \"max_depth\": hp.choice(\"max_depth\", [9,10,11,12,13]),\n",
    "    \"reg_lambda\": hp.uniform(\"reg_lambda\", 0, 5),\n",
    "    \"reg_alpha\": hp.uniform(\"reg_alpha\", 0, 5),\n",
    "    \"max_delta_step\": hp.uniform(\"max_delta_step\", 0, 5),\n",
    "    \"min_child_weight\": hp.uniform(\"min_child_weight\", 0.1, 15),\n",
    "    \"num_rounds\":  hp.uniform(\"num_rounds\", 200, 400),\n",
    "    \"weight\" : hp.uniform(\"weight\", 0.1,0.33)}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Performing a random grid search:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''trials = Trials()\n",
    "\n",
    "for i in range(1,2000):\n",
    "    best = fmin(fn = cross_validation_neg_acc_gradient_boosting, space = space_gradient_boosting,\n",
    "                algo = rand.suggest, max_evals = i, trials = trials)\n",
    "    logging.info(i)\n",
    "    logging.info(trials.best_trial[\"result\"][\"loss\"])\n",
    "    logging.info(trials.argmin)''';"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Best set of hyperparameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "param = {'learning_rate': 0.12771337495138718,\n",
    "         'max_delta_step': 3.080851382419611,\n",
    "         'max_depth': 13,\n",
    "         'min_child_weight': 2.68947814956559,\n",
    "         'num_rounds': 332.92969059815346,\n",
    "         'reg_alpha': 1.4293630231664674,\n",
    "         'reg_lambda': 0.12220981612600046,\n",
    "         'weight': 0.11412319177763543}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (iii) Repeating 5-fold CV for best set of hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16:49:49] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[16:53:07] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[16:56:27] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[16:59:49] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[17:03:06] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Loss values: [135.64613843194581, 146.31281276919225, 149.789174479733, 159.6153340309748, 137.4009624484746]\n",
      "Accuracies: [0.8691790040376851, 0.8684022186437645, 0.8662160991248592, 0.8606942686675104, 0.8758217677136596]\n",
      "ROC-AUC scores: [0.9426084967554512, 0.9383771038523977, 0.9347969874349884, 0.9294492918142963, 0.9389172581369728]\n"
     ]
    }
   ],
   "source": [
    "num_round = param[\"num_rounds\"]\n",
    "param[\"tree_method\"] = \"gpu_hist\"\n",
    "param[\"sampling_method\"] = \"gradient_based\"\n",
    "param['objective'] = 'binary:logistic'\n",
    "weights = np.array([param[\"weight\"] if binding == 0 else 1.0 for binding in df_train[\"Binding\"]])\n",
    "\n",
    "del param[\"num_rounds\"]\n",
    "del param[\"weight\"]\n",
    "\n",
    "\n",
    "loss = []\n",
    "accuracy = []\n",
    "ROC_AUC = []\n",
    "\n",
    "for i in range(5):\n",
    "    train_index, test_index  = train_indices[i], test_indices[i]\n",
    "    dtrain = xgb.DMatrix(np.array(train_X[train_index]), weight = weights[train_index],\n",
    "                     label = np.array(train_y[train_index]))\n",
    "    dvalid = xgb.DMatrix(np.array(train_X[test_index]))\n",
    "    bst = xgb.train(param,  dtrain, int(num_round), verbose_eval=1)\n",
    "    y_valid_pred = np.round(bst.predict(dvalid))\n",
    "    validation_y = train_y[test_index]\n",
    "\n",
    "    #calculate loss:\n",
    "    false_positive = 100*(1-np.mean(np.array(validation_y)[y_valid_pred == 1]))\n",
    "    false_negative = 100*(np.mean(np.array(validation_y)[y_valid_pred == 0]))\n",
    "    logging.info(\"False positive rate: \" + str(false_positive)+ \"; False negative rate: \" + str(false_negative))\n",
    "    loss.append(2*(false_negative**2) + false_positive**1.3)\n",
    "    #calculate accuracy:\n",
    "    accuracy.append(np.mean(y_valid_pred == np.array(validation_y)))\n",
    "    #calculate ROC-AUC score:\n",
    "    ROC_AUC.append(roc_auc_score(np.array(validation_y), bst.predict(dvalid)))\n",
    "    \n",
    "print(\"Loss values: %s\" %loss) \n",
    "print(\"Accuracies: %s\" %accuracy)\n",
    "print(\"ROC-AUC scores: %s\" %ROC_AUC)\n",
    "\n",
    "np.save(join(CURRENT_DIR, \"..\" ,\"data\", \"training_results\", \"acc_CV_xgboost_ESM1b_ECFP.npy\"), np.array(accuracy))\n",
    "np.save(join(CURRENT_DIR, \"..\" ,\"data\", \"training_results\", \"loss_CV_xgboost_ESM1b_ECFP.npy\"), np.array(loss))\n",
    "np.save(join(CURRENT_DIR, \"..\" ,\"data\", \"training_results\", \"ROC_AUC_CV_xgboost_ESM1b_ECFP.npy\"), np.array(ROC_AUC))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (iv) 3. Training and validating the final model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training the model and validating it on the test set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17:06:29] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Accuracy on test set: 0.8722044728434505, ROC-AUC score for test set: 0.9368380603439415, MCC: 0.6915652351366568\n"
     ]
    }
   ],
   "source": [
    "dtrain = xgb.DMatrix(np.array(train_X), weight = weights, label = np.array(train_y),\n",
    "                feature_names= feature_names)\n",
    "dtest = xgb.DMatrix(np.array(test_X), label = np.array(test_y),\n",
    "                    feature_names= feature_names)\n",
    "\n",
    "bst = xgb.train(param,  dtrain, int(num_round), verbose_eval=1)\n",
    "y_test_pred = np.round(bst.predict(dtest))\n",
    "acc_test = np.mean(y_test_pred == np.array(test_y))\n",
    "roc_auc = roc_auc_score(np.array(test_y), bst.predict(dtest))\n",
    "mcc = matthews_corrcoef(np.array(test_y), y_test_pred)\n",
    "\n",
    "print(\"Accuracy on test set: %s, ROC-AUC score for test set: %s, MCC: %s\"  % (acc_test, roc_auc, mcc))\n",
    "\n",
    "#np.save(join(CURRENT_DIR, \"..\" ,\"data\", \"training_results\", \"y_test_pred_xgboost_ESM1b_ECFP.npy\"), bst.predict(dtest))\n",
    "#np.save(join(CURRENT_DIR, \"..\" ,\"data\", \"training_results\", \"y_test_true_xgboost_ESM1b_ECFP.npy\"), test_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (b) ESM1b and GNN (pre-trained):"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (i) Creating numpy arrays with input vectors and output variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_input_and_output_data(df):\n",
    "    X = ();\n",
    "    y = ();\n",
    "        \n",
    "    for ind in df.index:\n",
    "        emb = df[\"ESM1b\"][ind]\n",
    "        ecfp = df[\"GNN rep (pretrained)\"][ind]\n",
    "                \n",
    "        X = X +(np.concatenate([ecfp, emb]), );\n",
    "        y = y + (df[\"Binding\"][ind], );\n",
    "\n",
    "    return(X,y)\n",
    "\n",
    "train_X, train_y =  create_input_and_output_data(df = df_train)\n",
    "test_X, test_y =  create_input_and_output_data(df = df_test)\n",
    "\n",
    "\n",
    "feature_names =  [\"GNN rep_\" + str(i) for i in range(50)]\n",
    "feature_names = feature_names + [\"ESM1b_\" + str(i) for i in range(1280)]\n",
    "\n",
    "train_X = np.array(train_X)\n",
    "test_X  = np.array(test_X)\n",
    "\n",
    "train_y = np.array(train_y)\n",
    "test_y  = np.array(test_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (ii) Performing hyperparameter optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_validation_neg_acc_gradient_boosting(param):\n",
    "    num_round = param[\"num_rounds\"]\n",
    "    param[\"tree_method\"] = \"gpu_hist\"\n",
    "    param[\"sampling_method\"] = \"gradient_based\"\n",
    "    param['objective'] = 'binary:logistic'\n",
    "    weights = np.array([param[\"weight\"] if binding == 0 else 1.0 for binding in df_train[\"Binding\"]])\n",
    "    \n",
    "    del param[\"num_rounds\"]\n",
    "    del param[\"weight\"]\n",
    "    \n",
    "    loss = []\n",
    "    for i in range(5):\n",
    "        train_index, test_index  = train_indices[i], test_indices[i]\n",
    "        dtrain = xgb.DMatrix(np.array(train_X[train_index]), weight = weights[train_index],\n",
    "                         label = np.array(train_y[train_index]))\n",
    "        dvalid = xgb.DMatrix(np.array(train_X[test_index]))\n",
    "        bst = xgb.train(param,  dtrain, int(num_round), verbose_eval=1)\n",
    "        y_valid_pred = np.round(bst.predict(dvalid))\n",
    "        validation_y = train_y[test_index]\n",
    "    \n",
    "        false_positive = 100*(1-np.mean(np.array(validation_y)[y_valid_pred == 1]))\n",
    "        false_negative = 100*(np.mean(np.array(validation_y)[y_valid_pred == 0]))\n",
    "        logging.info(\"False positive rate: \" + str(false_positive)+ \"; False negative rate: \" + str(false_negative))\n",
    "        loss.append(2*(false_negative**2) + false_positive**1.3)\n",
    "    return(np.mean(loss))\n",
    "\n",
    "#Defining search space for hyperparameter optimization\n",
    "space_gradient_boosting = {\"learning_rate\": hp.uniform(\"learning_rate\", 0.01, 0.5),\n",
    "    \"max_depth\": hp.choice(\"max_depth\", [9,10,11,12,13]),\n",
    "    \"reg_lambda\": hp.uniform(\"reg_lambda\", 0, 5),\n",
    "    \"reg_alpha\": hp.uniform(\"reg_alpha\", 0, 5),\n",
    "    \"max_delta_step\": hp.uniform(\"max_delta_step\", 0, 5),\n",
    "    \"min_child_weight\": hp.uniform(\"min_child_weight\", 0.1, 15),\n",
    "    \"num_rounds\":  hp.uniform(\"num_rounds\", 200, 400),\n",
    "    \"weight\" : hp.uniform(\"weight\", 0.1,0.33)}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Performing a random grid search:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''trials = Trials()\n",
    "\n",
    "for i in range(1,2000):\n",
    "    best = fmin(fn = cross_validation_neg_acc_gradient_boosting, space = space_gradient_boosting,\n",
    "                algo = rand.suggest, max_evals = i, trials = trials)\n",
    "    logging.info(i)\n",
    "    logging.info(trials.best_trial[\"result\"][\"loss\"])\n",
    "    logging.info(trials.argmin)''';"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Best set of hyperparameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "param = {'learning_rate': 0.09207371208675638,\n",
    "         'max_delta_step': 1.6501026095681381,\n",
    "         'max_depth': 12, \n",
    "         'min_child_weight': 4.385828776339477,\n",
    "         'num_rounds': 361.4040208821599,\n",
    "         'reg_alpha': 2.8139614176935313,\n",
    "         'reg_lambda': 1.1521733347508363,\n",
    "         'weight': 0.14162338902155536}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (iii) Repeating 5-fold CV for best set of hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_round = param[\"num_rounds\"]\n",
    "param[\"tree_method\"] = \"gpu_hist\"\n",
    "param[\"sampling_method\"] = \"gradient_based\"\n",
    "param['objective'] = 'binary:logistic'\n",
    "weights = np.array([param[\"weight\"] if binding == 0 else 1.0 for binding in df_train[\"Binding\"]])\n",
    "\n",
    "del param[\"num_rounds\"]\n",
    "del param[\"weight\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17:10:59] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[17:12:56] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[17:14:53] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[17:16:49] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[17:18:46] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Loss values: [121.97575964696276, 132.66941366275, 143.92507718249186, 155.63028256825766, 139.25640504585414]\n",
      "Accuracies: [0.8886496186630776, 0.8872785829307569, 0.8777402304826272, 0.8782317844874344, 0.8850438276113952]\n",
      "ROC-AUC scores: [0.9474577315968011, 0.9433819919446351, 0.9373767455135212, 0.9336666463444948, 0.9437762941205631]\n"
     ]
    }
   ],
   "source": [
    "loss = []\n",
    "accuracy = []\n",
    "ROC_AUC = []\n",
    "\n",
    "for i in range(5):\n",
    "    train_index, test_index  = train_indices[i], test_indices[i]\n",
    "    dtrain = xgb.DMatrix(np.array(train_X[train_index]), weight = weights[train_index],\n",
    "                     label = np.array(train_y[train_index]))\n",
    "    dvalid = xgb.DMatrix(np.array(train_X[test_index]))\n",
    "    bst = xgb.train(param,  dtrain, int(num_round), verbose_eval=1)\n",
    "    y_valid_pred = np.round(bst.predict(dvalid))\n",
    "    validation_y = train_y[test_index]\n",
    "\n",
    "    #calculate loss:\n",
    "    false_positive = 100*(1-np.mean(np.array(validation_y)[y_valid_pred == 1]))\n",
    "    false_negative = 100*(np.mean(np.array(validation_y)[y_valid_pred == 0]))\n",
    "    logging.info(\"False positive rate: \" + str(false_positive)+ \"; False negative rate: \" + str(false_negative))\n",
    "    loss.append(2*(false_negative**2) + false_positive**1.3)\n",
    "    #calculate accuracy:\n",
    "    accuracy.append(np.mean(y_valid_pred == np.array(validation_y)))\n",
    "    #calculate ROC-AUC score:\n",
    "    ROC_AUC.append(roc_auc_score(np.array(validation_y), bst.predict(dvalid)))\n",
    "    \n",
    "print(\"Loss values: %s\" %loss) \n",
    "print(\"Accuracies: %s\" %accuracy)\n",
    "print(\"ROC-AUC scores: %s\" %ROC_AUC)\n",
    "\n",
    "np.save(join(CURRENT_DIR, \"..\" ,\"data\", \"training_results\", \"acc_CV_xgboost_ESM1b_GNN_pretrained.npy\"), np.array(accuracy))\n",
    "np.save(join(CURRENT_DIR, \"..\" ,\"data\", \"training_results\", \"loss_CV_xgboost_ESM1b_GNN_pretrained.npy\"), np.array(loss))\n",
    "np.save(join(CURRENT_DIR, \"..\" ,\"data\", \"training_results\", \"ROC_AUC_CV_xgboost_ESM1b_GNN_pretrained.npy\"), np.array(ROC_AUC))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (iv) 3. Training and validating the final model\n",
    "Training the model and validating it on the test set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17:20:43] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Accuracy on test set: 0.8944943903707556, ROC-AUC score for test set: 0.9415865958288083, MCC: 0.7327206623426592\n"
     ]
    }
   ],
   "source": [
    "dtrain = xgb.DMatrix(np.array(train_X), weight = weights, label = np.array(train_y),\n",
    "                feature_names= feature_names)\n",
    "dtest = xgb.DMatrix(np.array(test_X), label = np.array(test_y),\n",
    "                    feature_names= feature_names)\n",
    "\n",
    "bst = xgb.train(param,  dtrain, int(num_round), verbose_eval=1)\n",
    "y_test_pred = np.round(bst.predict(dtest))\n",
    "acc_test = np.mean(y_test_pred == np.array(test_y))\n",
    "roc_auc = roc_auc_score(np.array(test_y), bst.predict(dtest))\n",
    "mcc = matthews_corrcoef(np.array(test_y), y_test_pred)\n",
    "\n",
    "print(\"Accuracy on test set: %s, ROC-AUC score for test set: %s, MCC: %s\"  % (acc_test, roc_auc, mcc))\n",
    "\n",
    "np.save(join(CURRENT_DIR, \"..\" ,\"data\", \"training_results\", \"y_test_pred_xgboost_ESM1b_GNN_pretrained.npy\"), bst.predict(dtest))\n",
    "np.save(join(CURRENT_DIR, \"..\" ,\"data\", \"training_results\", \"y_test_true_xgboost_ESM1b_GNN_pretrained.npy\"), test_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (c) ESM1b_ts and ECFP:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (i) Creating numpy arrays with input vectors and output variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_input_and_output_data(df):\n",
    "    X = ();\n",
    "    y = ();\n",
    "    \n",
    "    for ind in df.index:\n",
    "        emb = df[\"ESM1b_ts\"][ind]\n",
    "        ecfp = np.array(list(df[\"ECFP\"][ind])).astype(int)\n",
    "                \n",
    "        X = X +(np.concatenate([ecfp, emb]), );\n",
    "        y = y + (df[\"Binding\"][ind], );\n",
    "\n",
    "    return(X,y)\n",
    "\n",
    "train_X, train_y =  create_input_and_output_data(df = df_train)\n",
    "test_X, test_y =  create_input_and_output_data(df = df_test)\n",
    "\n",
    "\n",
    "feature_names =  [\"ECFP_\" + str(i) for i in range(1024)]\n",
    "feature_names = feature_names + [\"ESM1b_ts_\" + str(i) for i in range(1280)]\n",
    "\n",
    "train_X = np.array(train_X)\n",
    "test_X  = np.array(test_X)\n",
    "\n",
    "train_y = np.array(train_y)\n",
    "test_y  = np.array(test_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (ii) Performing hyperparameter optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_validation_neg_acc_gradient_boosting(param):\n",
    "    num_round = param[\"num_rounds\"]\n",
    "    param[\"tree_method\"] = \"gpu_hist\"\n",
    "    param[\"sampling_method\"] = \"gradient_based\"\n",
    "    param['objective'] = 'binary:logistic'\n",
    "    weights = np.array([param[\"weight\"] if binding == 0 else 1.0 for binding in df_train[\"Binding\"]])\n",
    "    \n",
    "    del param[\"num_rounds\"]\n",
    "    del param[\"weight\"]\n",
    "    \n",
    "    loss = []\n",
    "    for i in range(5):\n",
    "        train_index, test_index  = train_indices[i], test_indices[i]\n",
    "        dtrain = xgb.DMatrix(np.array(train_X[train_index]), weight = weights[train_index],\n",
    "                         label = np.array(train_y[train_index]))\n",
    "        dvalid = xgb.DMatrix(np.array(train_X[test_index]))\n",
    "        bst = xgb.train(param,  dtrain, int(num_round), verbose_eval=1)\n",
    "        y_valid_pred = np.round(bst.predict(dvalid))\n",
    "        validation_y = train_y[test_index]\n",
    "    \n",
    "        false_positive = 100*(1-np.mean(np.array(validation_y)[y_valid_pred == 1]))\n",
    "        false_negative = 100*(np.mean(np.array(validation_y)[y_valid_pred == 0]))\n",
    "        logging.info(\"False positive rate: \" + str(false_positive)+ \"; False negative rate: \" + str(false_negative))\n",
    "        loss.append(2*(false_negative**2) + false_positive**1.3)\n",
    "    return(np.mean(loss))\n",
    "\n",
    "#Defining search space for hyperparameter optimization\n",
    "space_gradient_boosting = {\"learning_rate\": hp.uniform(\"learning_rate\", 0.01, 0.5),\n",
    "                            \"max_depth\": hp.choice(\"max_depth\", [9,10,11,12,13]),\n",
    "                            \"reg_lambda\": hp.uniform(\"reg_lambda\", 0, 5),\n",
    "                            \"reg_alpha\": hp.uniform(\"reg_alpha\", 0, 5),\n",
    "                            \"max_delta_step\": hp.uniform(\"max_delta_step\", 0, 5),\n",
    "                            \"min_child_weight\": hp.uniform(\"min_child_weight\", 0.1, 15),\n",
    "                            \"num_rounds\":  hp.uniform(\"num_rounds\", 200, 400),\n",
    "                            \"weight\" : hp.uniform(\"weight\", 0.1,0.33)}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Performing a random grid search:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''trials = Trials()\n",
    "\n",
    "for i in range(1,2000):\n",
    "    best = fmin(fn = cross_validation_neg_acc_gradient_boosting, space = space_gradient_boosting,\n",
    "                algo = rand.suggest, max_evals = i, trials = trials)\n",
    "    logging.info(i)\n",
    "    logging.info(trials.best_trial[\"result\"][\"loss\"])\n",
    "    logging.info(trials.argmin)''';"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Best set of hyperparameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "param = {'learning_rate': 0.31553117247348733,\n",
    "         'max_delta_step': 1.7726044219753656,\n",
    "         'max_depth': 10,\n",
    "         'min_child_weight': 1.3845040588450772,\n",
    "         'num_rounds': 342.68325188584106,\n",
    "         'reg_alpha': 0.531395259755843,\n",
    "         'reg_lambda': 3.744980563764689,\n",
    "         'weight': 0.26187490421514203}\n",
    "\n",
    "num_round = param[\"num_rounds\"]\n",
    "param[\"tree_method\"] = \"gpu_hist\"\n",
    "param[\"sampling_method\"] = \"gradient_based\"\n",
    "param['objective'] = 'binary:logistic'\n",
    "weights = np.array([param[\"weight\"] if binding == 0 else 1.0 for binding in df_train[\"Binding\"]])\n",
    "\n",
    "del param[\"num_rounds\"]\n",
    "del param[\"weight\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (iii) Repeating 5-fold CV for best set of hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[20:05:57] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[20:08:10] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[20:10:28] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[20:12:44] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[20:15:02] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Loss values: [108.68044529838687, 113.38285635774665, 116.75072442009302, 125.35861908227079, 119.36638679297242]\n",
      "Accuracies: [0.9103633916554509, 0.9104490964394346, 0.9081535395546313, 0.9067980473693726, 0.908235938641344]\n",
      "ROC-AUC scores: [0.956404258764795, 0.9524134068104446, 0.9484047612505799, 0.9470567532760683, 0.951539293645603]\n"
     ]
    }
   ],
   "source": [
    "loss = []\n",
    "accuracy = []\n",
    "ROC_AUC = []\n",
    "\n",
    "for i in range(5):\n",
    "    train_index, test_index  = train_indices[i], test_indices[i]\n",
    "    dtrain = xgb.DMatrix(np.array(train_X[train_index]), weight = weights[train_index],\n",
    "                     label = np.array(train_y[train_index]))\n",
    "    dvalid = xgb.DMatrix(np.array(train_X[test_index]))\n",
    "    bst = xgb.train(param,  dtrain, int(num_round), verbose_eval=1)\n",
    "    y_valid_pred = np.round(bst.predict(dvalid))\n",
    "    validation_y = train_y[test_index]\n",
    "\n",
    "    #calculate loss:\n",
    "    false_positive = 100*(1-np.mean(np.array(validation_y)[y_valid_pred == 1]))\n",
    "    false_negative = 100*(np.mean(np.array(validation_y)[y_valid_pred == 0]))\n",
    "    logging.info(\"False positive rate: \" + str(false_positive)+ \"; False negative rate: \" + str(false_negative))\n",
    "    loss.append(2*(false_negative**2) + false_positive**1.3)\n",
    "    #calculate accuracy:\n",
    "    accuracy.append(np.mean(y_valid_pred == np.array(validation_y)))\n",
    "    #calculate ROC-AUC score:\n",
    "    ROC_AUC.append(roc_auc_score(np.array(validation_y), bst.predict(dvalid)))\n",
    "    \n",
    "print(\"Loss values: %s\" %loss) \n",
    "print(\"Accuracies: %s\" %accuracy)\n",
    "print(\"ROC-AUC scores: %s\" %ROC_AUC)\n",
    "\n",
    "np.save(join(CURRENT_DIR, \"..\" ,\"data\", \"training_results\", \"acc_CV_xgboost_ESM1b_ts_ECFP.npy\"), np.array(accuracy))\n",
    "np.save(join(CURRENT_DIR, \"..\" ,\"data\", \"training_results\", \"loss_CV_xgboost_ESM1b_ts_ECFP.npy\"), np.array(loss))\n",
    "np.save(join(CURRENT_DIR, \"..\" ,\"data\", \"training_results\", \"ROC_AUC_CV_xgboost_ESM1b_ts_ECFP.npy\"), np.array(ROC_AUC))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (iv) 3. Training and validating the final model\n",
    "Training the model and validating it on the test set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[20:17:20] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Accuracy on test set: 0.904599152983134, ROC-AUC score for test set: 0.9494417844088786, MCC: 0.7541937162526161\n"
     ]
    }
   ],
   "source": [
    "dtrain = xgb.DMatrix(np.array(train_X), weight = weights, label = np.array(train_y),\n",
    "                feature_names= feature_names)\n",
    "dtest = xgb.DMatrix(np.array(test_X), label = np.array(test_y),\n",
    "                    feature_names= feature_names)\n",
    "\n",
    "bst = xgb.train(param,  dtrain, int(num_round), verbose_eval=1)\n",
    "y_test_pred = np.round(bst.predict(dtest))\n",
    "acc_test = np.mean(y_test_pred == np.array(test_y))\n",
    "roc_auc = roc_auc_score(np.array(test_y), bst.predict(dtest))\n",
    "mcc = matthews_corrcoef(np.array(test_y), y_test_pred)\n",
    "\n",
    "print(\"Accuracy on test set: %s, ROC-AUC score for test set: %s, MCC: %s\"  % (acc_test, roc_auc, mcc))\n",
    "\n",
    "np.save(join(CURRENT_DIR, \"..\" ,\"data\", \"training_results\", \"y_test_pred_xgboost_ESM1b_ts_ECFP.npy\"), bst.predict(dtest))\n",
    "np.save(join(CURRENT_DIR, \"..\" ,\"data\", \"training_results\", \"y_test_true_xgboost_ESM1b_ts_ECFP.npy\"), test_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (d) ESM1b_ts and ECFP (512-dimensional):"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (i) Creating numpy arrays with input vectors and output variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_input_and_output_data(df):\n",
    "    X = ();\n",
    "    y = ();\n",
    "    \n",
    "    for ind in df.index:\n",
    "        emb = df[\"ESM1b_ts\"][ind]\n",
    "        ecfp = np.array(list(df[\"ECFP_512\"][ind])).astype(int)\n",
    "                \n",
    "        X = X +(np.concatenate([ecfp, emb]), );\n",
    "        y = y + (df[\"Binding\"][ind], );\n",
    "\n",
    "    return(X,y)\n",
    "\n",
    "train_X, train_y =  create_input_and_output_data(df = df_train)\n",
    "test_X, test_y =  create_input_and_output_data(df = df_test)\n",
    "\n",
    "feature_names =  [\"ECFP_\" + str(i) for i in range(512)]\n",
    "feature_names = feature_names + [\"ESM1b_ts_\" + str(i) for i in range(1280)]\n",
    "\n",
    "train_X = np.array(train_X)\n",
    "test_X  = np.array(test_X)\n",
    "\n",
    "train_y = np.array(train_y)\n",
    "test_y  = np.array(test_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (ii) Performing hyperparameter optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_validation_neg_acc_gradient_boosting(param):\n",
    "    num_round = param[\"num_rounds\"]\n",
    "    param[\"tree_method\"] = \"gpu_hist\"\n",
    "    param[\"sampling_method\"] = \"gradient_based\"\n",
    "    param['objective'] = 'binary:logistic'\n",
    "    weights = np.array([param[\"weight\"] if binding == 0 else 1.0 for binding in df_train[\"Binding\"]])\n",
    "    \n",
    "    del param[\"num_rounds\"]\n",
    "    del param[\"weight\"]\n",
    "    \n",
    "    loss = []\n",
    "    for i in range(5):\n",
    "        train_index, test_index  = train_indices[i], test_indices[i]\n",
    "        dtrain = xgb.DMatrix(np.array(train_X[train_index]), weight = weights[train_index],\n",
    "                         label = np.array(train_y[train_index]))\n",
    "        dvalid = xgb.DMatrix(np.array(train_X[test_index]))\n",
    "        bst = xgb.train(param,  dtrain, int(num_round), verbose_eval=1)\n",
    "        y_valid_pred = np.round(bst.predict(dvalid))\n",
    "        validation_y = train_y[test_index]\n",
    "    \n",
    "        false_positive = 100*(1-np.mean(np.array(validation_y)[y_valid_pred == 1]))\n",
    "        false_negative = 100*(np.mean(np.array(validation_y)[y_valid_pred == 0]))\n",
    "        logging.info(\"False positive rate: \" + str(false_positive)+ \"; False negative rate: \" + str(false_negative))\n",
    "        loss.append(2*(false_negative**2) + false_positive**1.3)\n",
    "    return(np.mean(loss))\n",
    "\n",
    "#Defining search space for hyperparameter optimization\n",
    "space_gradient_boosting = {\"learning_rate\": hp.uniform(\"learning_rate\", 0.01, 0.5),\n",
    "                            \"max_depth\": hp.choice(\"max_depth\", [9,10,11,12,13]),\n",
    "                            \"reg_lambda\": hp.uniform(\"reg_lambda\", 0, 5),\n",
    "                            \"reg_alpha\": hp.uniform(\"reg_alpha\", 0, 5),\n",
    "                            \"max_delta_step\": hp.uniform(\"max_delta_step\", 0, 5),\n",
    "                            \"min_child_weight\": hp.uniform(\"min_child_weight\", 0.1, 15),\n",
    "                            \"num_rounds\":  hp.uniform(\"num_rounds\", 200, 400),\n",
    "                            \"weight\" : hp.uniform(\"weight\", 0.1,0.33)}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Performing a random grid search:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''trials = Trials()\n",
    "\n",
    "for i in range(1,2000):\n",
    "    best = fmin(fn = cross_validation_neg_acc_gradient_boosting, space = space_gradient_boosting,\n",
    "                algo = rand.suggest, max_evals = i, trials = trials)\n",
    "    logging.info(i)\n",
    "    logging.info(trials.best_trial[\"result\"][\"loss\"])\n",
    "    logging.info(trials.argmin)''';"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Best set of hyperparameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "param = {'learning_rate': 0.20031456821679422,\n",
    "         'max_delta_step': 3.723458003552047,\n",
    "         'max_depth': 10,\n",
    "         'min_child_weight': 2.0109208762032678,\n",
    "         'num_rounds': 347.78525681188614,\n",
    "         'reg_alpha': 2.213525607682663,\n",
    "         'reg_lambda': 4.5822546393906025,\n",
    "         'weight': 0.16604653557737126}\n",
    "\n",
    "num_round = param[\"num_rounds\"]\n",
    "param[\"tree_method\"] = \"gpu_hist\"\n",
    "param[\"sampling_method\"] = \"gradient_based\"\n",
    "param['objective'] = 'binary:logistic'\n",
    "weights = np.array([param[\"weight\"] if binding == 0 else 1.0 for binding in df_train[\"Binding\"]])\n",
    "\n",
    "del param[\"num_rounds\"]\n",
    "del param[\"weight\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (iii) Repeating 5-fold CV for best set of hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[20:21:07] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[20:23:08] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[20:25:08] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[20:27:11] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[20:29:15] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Loss values: [104.16043379763315, 118.19757372302232, 124.29384769765849, 132.1245948240752, 119.5747769265525]\n",
      "Accuracies: [0.8947510094212652, 0.8884415816782967, 0.8868382289229703, 0.8823901645272103, 0.8911614317019723]\n",
      "ROC-AUC scores: [0.9559755847455434, 0.9496475323966114, 0.9486398091770489, 0.9454227918700563, 0.9495638094101112]\n"
     ]
    }
   ],
   "source": [
    "loss = []\n",
    "accuracy = []\n",
    "ROC_AUC = []\n",
    "\n",
    "for i in range(5):\n",
    "    train_index, test_index  = train_indices[i], test_indices[i]\n",
    "    dtrain = xgb.DMatrix(np.array(train_X[train_index]), weight = weights[train_index],\n",
    "                     label = np.array(train_y[train_index]))\n",
    "    dvalid = xgb.DMatrix(np.array(train_X[test_index]))\n",
    "    bst = xgb.train(param,  dtrain, int(num_round), verbose_eval=1)\n",
    "    y_valid_pred = np.round(bst.predict(dvalid))\n",
    "    validation_y = train_y[test_index]\n",
    "\n",
    "    #calculate loss:\n",
    "    false_positive = 100*(1-np.mean(np.array(validation_y)[y_valid_pred == 1]))\n",
    "    false_negative = 100*(np.mean(np.array(validation_y)[y_valid_pred == 0]))\n",
    "    logging.info(\"False positive rate: \" + str(false_positive)+ \"; False negative rate: \" + str(false_negative))\n",
    "    loss.append(2*(false_negative**2) + false_positive**1.3)\n",
    "    #calculate accuracy:\n",
    "    accuracy.append(np.mean(y_valid_pred == np.array(validation_y)))\n",
    "    #calculate ROC-AUC score:\n",
    "    ROC_AUC.append(roc_auc_score(np.array(validation_y), bst.predict(dvalid)))\n",
    "    \n",
    "print(\"Loss values: %s\" %loss) \n",
    "print(\"Accuracies: %s\" %accuracy)\n",
    "print(\"ROC-AUC scores: %s\" %ROC_AUC)\n",
    "\n",
    "np.save(join(CURRENT_DIR, \"..\" ,\"data\", \"training_results\", \"acc_CV_xgboost_ESM1b_ts_ECFP_512.npy\"), np.array(accuracy))\n",
    "np.save(join(CURRENT_DIR, \"..\" ,\"data\", \"training_results\", \"loss_CV_xgboost_ESM1b_ts_ECFP_512.npy\"), np.array(loss))\n",
    "np.save(join(CURRENT_DIR, \"..\" ,\"data\", \"training_results\", \"ROC_AUC_CV_xgboost_ESM1b_ts_ECFP_512.npy\"), np.array(ROC_AUC))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (iv) 3. Training and validating the final model\n",
    "Training the model and validating it on the test set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[20:31:17] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Accuracy on test set: 0.8875102162122, ROC-AUC score for test set: 0.9467608865614003, MCC: 0.7238779924304148\n"
     ]
    }
   ],
   "source": [
    "dtrain = xgb.DMatrix(np.array(train_X), weight = weights, label = np.array(train_y),\n",
    "                feature_names= feature_names)\n",
    "dtest = xgb.DMatrix(np.array(test_X), label = np.array(test_y),\n",
    "                    feature_names= feature_names)\n",
    "\n",
    "bst = xgb.train(param,  dtrain, int(num_round), verbose_eval=1)\n",
    "y_test_pred = np.round(bst.predict(dtest))\n",
    "acc_test = np.mean(y_test_pred == np.array(test_y))\n",
    "roc_auc = roc_auc_score(np.array(test_y), bst.predict(dtest))\n",
    "mcc = matthews_corrcoef(np.array(test_y), y_test_pred)\n",
    "\n",
    "print(\"Accuracy on test set: %s, ROC-AUC score for test set: %s, MCC: %s\"  % (acc_test, roc_auc, mcc))\n",
    "\n",
    "np.save(join(CURRENT_DIR, \"..\" ,\"data\", \"training_results\", \"y_test_pred_xgboost_ESM1b_ts_ECFP_512.npy\"), bst.predict(dtest))\n",
    "np.save(join(CURRENT_DIR, \"..\" ,\"data\", \"training_results\", \"y_test_true_xgboost_ESM1b_ts_ECFP_512.npy\"), test_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (e) ESM1b_ts and ECFP (2048-dimensional):"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (i) Creating numpy arrays with input vectors and output variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_input_and_output_data(df):\n",
    "    X = ();\n",
    "    y = ();\n",
    "    \n",
    "    for ind in df.index:\n",
    "        emb = df[\"ESM1b_ts\"][ind]\n",
    "        ecfp = np.array(list(df[\"ECFP_2048\"][ind])).astype(int)\n",
    "                \n",
    "        X = X +(np.concatenate([ecfp, emb]), );\n",
    "        y = y + (df[\"Binding\"][ind], );\n",
    "\n",
    "    return(X,y)\n",
    "\n",
    "train_X, train_y =  create_input_and_output_data(df = df_train)\n",
    "test_X, test_y =  create_input_and_output_data(df = df_test)\n",
    "\n",
    "feature_names =  [\"ECFP_\" + str(i) for i in range(2048)]\n",
    "feature_names = feature_names + [\"ESM1b_ts_\" + str(i) for i in range(1280)]\n",
    "\n",
    "train_X = np.array(train_X)\n",
    "test_X  = np.array(test_X)\n",
    "\n",
    "train_y = np.array(train_y)\n",
    "test_y  = np.array(test_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (ii) Performing hyperparameter optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_validation_neg_acc_gradient_boosting(param):\n",
    "    num_round = param[\"num_rounds\"]\n",
    "    param[\"tree_method\"] = \"gpu_hist\"\n",
    "    param[\"sampling_method\"] = \"gradient_based\"\n",
    "    param['objective'] = 'binary:logistic'\n",
    "    weights = np.array([param[\"weight\"] if binding == 0 else 1.0 for binding in df_train[\"Binding\"]])\n",
    "    \n",
    "    del param[\"num_rounds\"]\n",
    "    del param[\"weight\"]\n",
    "    \n",
    "    loss = []\n",
    "    for i in range(5):\n",
    "        train_index, test_index  = train_indices[i], test_indices[i]\n",
    "        dtrain = xgb.DMatrix(np.array(train_X[train_index]), weight = weights[train_index],\n",
    "                         label = np.array(train_y[train_index]))\n",
    "        dvalid = xgb.DMatrix(np.array(train_X[test_index]))\n",
    "        bst = xgb.train(param,  dtrain, int(num_round), verbose_eval=1)\n",
    "        y_valid_pred = np.round(bst.predict(dvalid))\n",
    "        validation_y = train_y[test_index]\n",
    "    \n",
    "        false_positive = 100*(1-np.mean(np.array(validation_y)[y_valid_pred == 1]))\n",
    "        false_negative = 100*(np.mean(np.array(validation_y)[y_valid_pred == 0]))\n",
    "        logging.info(\"False positive rate: \" + str(false_positive)+ \"; False negative rate: \" + str(false_negative))\n",
    "        loss.append(2*(false_negative**2) + false_positive**1.3)\n",
    "    return(np.mean(loss))\n",
    "\n",
    "#Defining search space for hyperparameter optimization\n",
    "space_gradient_boosting = {\"learning_rate\": hp.uniform(\"learning_rate\", 0.01, 0.5),\n",
    "                            \"max_depth\": hp.choice(\"max_depth\", [9,10,11,12,13]),\n",
    "                            \"reg_lambda\": hp.uniform(\"reg_lambda\", 0, 5),\n",
    "                            \"reg_alpha\": hp.uniform(\"reg_alpha\", 0, 5),\n",
    "                            \"max_delta_step\": hp.uniform(\"max_delta_step\", 0, 5),\n",
    "                            \"min_child_weight\": hp.uniform(\"min_child_weight\", 0.1, 15),\n",
    "                            \"num_rounds\":  hp.uniform(\"num_rounds\", 200, 400),\n",
    "                            \"weight\" : hp.uniform(\"weight\", 0.1,0.33)}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Performing a random grid search:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''trials = Trials()\n",
    "\n",
    "for i in range(1,2000):\n",
    "    best = fmin(fn = cross_validation_neg_acc_gradient_boosting, space = space_gradient_boosting,\n",
    "                algo = rand.suggest, max_evals = i, trials = trials)\n",
    "    logging.info(i)\n",
    "    logging.info(trials.best_trial[\"result\"][\"loss\"])\n",
    "    logging.info(trials.argmin)''';"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Best set of hyperparameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "param = {'learning_rate': 0.38572930012069273,\n",
    "         'max_delta_step': 2.3691090709866254,\n",
    "         'max_depth': 13,\n",
    "         'min_child_weight': 0.11946441222742316,\n",
    "         'num_rounds': 185.5041665008057,\n",
    "         'reg_alpha': 0.4492202436042625,\n",
    "         'reg_lambda': 0.8927451484733545,\n",
    "         'weight': 0.10881477775175043}\n",
    "\n",
    "num_round = param[\"num_rounds\"]\n",
    "param[\"tree_method\"] = \"gpu_hist\"\n",
    "param[\"sampling_method\"] = \"gradient_based\"\n",
    "param['objective'] = 'binary:logistic'\n",
    "weights = np.array([param[\"weight\"] if binding == 0 else 1.0 for binding in df_train[\"Binding\"]])\n",
    "\n",
    "del param[\"num_rounds\"]\n",
    "del param[\"weight\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (iii) Repeating 5-fold CV for best set of hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[05:46:37] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[05:49:52] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[05:53:02] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[05:56:13] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[05:59:33] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Loss values: [105.30552432607526, 115.14142937211616, 113.2335149181909, 133.1620701477483, 122.36331116450947]\n",
      "Accuracies: [0.9023777478689996, 0.8997137233852209, 0.9020015596568755, 0.8933285120231423, 0.8975529583637691]\n",
      "ROC-AUC scores: [0.9565390334782213, 0.9511082440869931, 0.9489242322179354, 0.9441804521532098, 0.9494393660817402]\n"
     ]
    }
   ],
   "source": [
    "loss = []\n",
    "accuracy = []\n",
    "ROC_AUC = []\n",
    "\n",
    "for i in range(5):\n",
    "    train_index, test_index  = train_indices[i], test_indices[i]\n",
    "    dtrain = xgb.DMatrix(np.array(train_X[train_index]), weight = weights[train_index],\n",
    "                     label = np.array(train_y[train_index]))\n",
    "    dvalid = xgb.DMatrix(np.array(train_X[test_index]))\n",
    "    bst = xgb.train(param,  dtrain, int(num_round), verbose_eval=1)\n",
    "    y_valid_pred = np.round(bst.predict(dvalid))\n",
    "    validation_y = train_y[test_index]\n",
    "\n",
    "    #calculate loss:\n",
    "    false_positive = 100*(1-np.mean(np.array(validation_y)[y_valid_pred == 1]))\n",
    "    false_negative = 100*(np.mean(np.array(validation_y)[y_valid_pred == 0]))\n",
    "    logging.info(\"False positive rate: \" + str(false_positive)+ \"; False negative rate: \" + str(false_negative))\n",
    "    loss.append(2*(false_negative**2) + false_positive**1.3)\n",
    "    #calculate accuracy:\n",
    "    accuracy.append(np.mean(y_valid_pred == np.array(validation_y)))\n",
    "    #calculate ROC-AUC score:\n",
    "    ROC_AUC.append(roc_auc_score(np.array(validation_y), bst.predict(dvalid)))\n",
    "    \n",
    "print(\"Loss values: %s\" %loss) \n",
    "print(\"Accuracies: %s\" %accuracy)\n",
    "print(\"ROC-AUC scores: %s\" %ROC_AUC)\n",
    "\n",
    "np.save(join(CURRENT_DIR, \"..\" ,\"data\", \"training_results\", \"acc_CV_xgboost_ESM1b_ts_ECFP_2048.npy\"), np.array(accuracy))\n",
    "np.save(join(CURRENT_DIR, \"..\" ,\"data\", \"training_results\", \"loss_CV_xgboost_ESM1b_ts_ECFP_2048.npy\"), np.array(loss))\n",
    "np.save(join(CURRENT_DIR, \"..\" ,\"data\", \"training_results\", \"ROC_AUC_CV_xgboost_ESM1b_ts_ECFP_2048.npy\"), np.array(ROC_AUC))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (iv) 3. Training and validating the final model\n",
    "Training the model and validating it on the test set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[06:02:45] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Accuracy on test set: 0.8977635782747604, ROC-AUC score for test set: 0.9484819112091449, MCC: 0.7428505008103589\n"
     ]
    }
   ],
   "source": [
    "dtrain = xgb.DMatrix(np.array(train_X), weight = weights, label = np.array(train_y),\n",
    "                feature_names= feature_names)\n",
    "dtest = xgb.DMatrix(np.array(test_X), label = np.array(test_y),\n",
    "                    feature_names= feature_names)\n",
    "\n",
    "bst = xgb.train(param,  dtrain, int(num_round), verbose_eval=1)\n",
    "y_test_pred = np.round(bst.predict(dtest))\n",
    "acc_test = np.mean(y_test_pred == np.array(test_y))\n",
    "roc_auc = roc_auc_score(np.array(test_y), bst.predict(dtest))\n",
    "mcc = matthews_corrcoef(np.array(test_y), y_test_pred)\n",
    "\n",
    "print(\"Accuracy on test set: %s, ROC-AUC score for test set: %s, MCC: %s\"  % (acc_test, roc_auc, mcc))\n",
    "\n",
    "np.save(join(CURRENT_DIR, \"..\" ,\"data\", \"training_results\", \"y_test_pred_xgboost_ESM1b_ts_ECFP_2048.npy\"), bst.predict(dtest))\n",
    "np.save(join(CURRENT_DIR, \"..\" ,\"data\", \"training_results\", \"y_test_true_xgboost_ESM1b_ts_ECFP_2048.npy\"), test_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (f) ESM1b_ts and GNN (pretrained):"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (i) Creating numpy arrays with input vectors and output variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_input_and_output_data(df):\n",
    "    X = ();\n",
    "    y = ();\n",
    "    \n",
    "    for ind in df.index:\n",
    "        emb = df[\"ESM1b_ts\"][ind]\n",
    "        ecfp = df[\"GNN rep (pretrained)\"][ind]\n",
    "                \n",
    "        X = X +(np.concatenate([ecfp, emb]), );\n",
    "        y = y + (df[\"Binding\"][ind], );\n",
    "\n",
    "    return(X,y)\n",
    "\n",
    "train_X, train_y =  create_input_and_output_data(df = df_train)\n",
    "test_X, test_y =  create_input_and_output_data(df = df_test)\n",
    "\n",
    "\n",
    "feature_names =  [\"GNN rep_\" + str(i) for i in range(50)]\n",
    "feature_names = feature_names + [\"ESM1b_\" + str(i) for i in range(1280)]\n",
    "\n",
    "train_X = np.array(train_X)\n",
    "test_X  = np.array(test_X)\n",
    "\n",
    "train_y = np.array(train_y)\n",
    "test_y  = np.array(test_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (ii) Performing hyperparameter optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_validation_neg_acc_gradient_boosting(param):\n",
    "    num_round = param[\"num_rounds\"]\n",
    "    param[\"tree_method\"] = \"gpu_hist\"\n",
    "    param[\"sampling_method\"] = \"gradient_based\"\n",
    "    param['objective'] = 'binary:logistic'\n",
    "    weights = np.array([param[\"weight\"] if binding == 0 else 1.0 for binding in df_train[\"Binding\"]])\n",
    "    \n",
    "    del param[\"num_rounds\"]\n",
    "    del param[\"weight\"]\n",
    "    \n",
    "    loss = []\n",
    "    for i in range(5):\n",
    "        train_index, test_index  = train_indices[i], test_indices[i]\n",
    "        dtrain = xgb.DMatrix(np.array(train_X[train_index]), weight = weights[train_index],\n",
    "                         label = np.array(train_y[train_index]))\n",
    "        dvalid = xgb.DMatrix(np.array(train_X[test_index]))\n",
    "        bst = xgb.train(param,  dtrain, int(num_round), verbose_eval=1)\n",
    "        y_valid_pred = np.round(bst.predict(dvalid))\n",
    "        validation_y = train_y[test_index]\n",
    "    \n",
    "        false_positive = 100*(1-np.mean(np.array(validation_y)[y_valid_pred == 1]))\n",
    "        false_negative = 100*(np.mean(np.array(validation_y)[y_valid_pred == 0]))\n",
    "        logging.info(\"False positive rate: \" + str(false_positive)+ \"; False negative rate: \" + str(false_negative))\n",
    "        loss.append(2*(false_negative**2) + false_positive**1.3)\n",
    "    return(np.mean(loss))\n",
    "\n",
    "#Defining search space for hyperparameter optimization\n",
    "space_gradient_boosting = {\"learning_rate\": hp.uniform(\"learning_rate\", 0.01, 0.5),\n",
    "    \"max_depth\": hp.choice(\"max_depth\", [9,10,11,12,13]),\n",
    "    \"reg_lambda\": hp.uniform(\"reg_lambda\", 0, 5),\n",
    "    \"reg_alpha\": hp.uniform(\"reg_alpha\", 0, 5),\n",
    "    \"max_delta_step\": hp.uniform(\"max_delta_step\", 0, 5),\n",
    "    \"min_child_weight\": hp.uniform(\"min_child_weight\", 0.1, 15),\n",
    "    \"num_rounds\":  hp.uniform(\"num_rounds\", 200, 400),\n",
    "    \"weight\" : hp.uniform(\"weight\", 0.1,0.33)}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Performing a random grid search:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''trials = Trials()\n",
    "\n",
    "for i in range(1,2000):\n",
    "    best = fmin(fn = cross_validation_neg_acc_gradient_boosting, space = space_gradient_boosting,\n",
    "                algo = rand.suggest, max_evals = i, trials = trials)\n",
    "    logging.info(i)\n",
    "    logging.info(trials.best_trial[\"result\"][\"loss\"])\n",
    "    logging.info(trials.argmin)''';"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Best set of hyperparameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "param = {'learning_rate': 0.19789627044374644,\n",
    " 'max_delta_step': 3.815106738298364,\n",
    " 'max_depth': 12,\n",
    " 'min_child_weight': 0.9568708633806051,\n",
    " 'num_rounds': 358.42154962618235,\n",
    " 'reg_alpha': 0.3726209284173021,\n",
    " 'reg_lambda': 4.442065146895246,\n",
    " 'weight': 0.11281944917093198}\n",
    "\n",
    "num_round = param[\"num_rounds\"]\n",
    "param[\"tree_method\"] = \"gpu_hist\"\n",
    "param[\"sampling_method\"] = \"gradient_based\"\n",
    "param['objective'] = 'binary:logistic'\n",
    "weights = np.array([param[\"weight\"] if binding == 0 else 1.0 for binding in df_train[\"Binding\"]])\n",
    "\n",
    "del param[\"num_rounds\"]\n",
    "del param[\"weight\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (iii) Repeating 5-fold CV for best set of hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[06:07:17] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[06:09:33] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[06:11:49] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[06:14:02] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[06:16:19] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Loss values: [91.88073293137697, 99.67882761750269, 109.23993476370345, 120.01888413247693, 106.0349108806078]\n",
      "Accuracies: [0.917900403768506, 0.9150116299874754, 0.9098864916385062, 0.9069788465015368, 0.9120708546384222]\n",
      "ROC-AUC scores: [0.9604579328670103, 0.9560894222080177, 0.9530202250038822, 0.9515046007045915, 0.9566354023173045]\n"
     ]
    }
   ],
   "source": [
    "loss = []\n",
    "accuracy = []\n",
    "ROC_AUC = []\n",
    "\n",
    "for i in range(5):\n",
    "    train_index, test_index  = train_indices[i], test_indices[i]\n",
    "    dtrain = xgb.DMatrix(np.array(train_X[train_index]), weight = weights[train_index],\n",
    "                     label = np.array(train_y[train_index]))\n",
    "    dvalid = xgb.DMatrix(np.array(train_X[test_index]))\n",
    "    bst = xgb.train(param,  dtrain, int(num_round), verbose_eval=1)\n",
    "    y_valid_pred = np.round(bst.predict(dvalid))\n",
    "    validation_y = train_y[test_index]\n",
    "\n",
    "    #calculate loss:\n",
    "    false_positive = 100*(1-np.mean(np.array(validation_y)[y_valid_pred == 1]))\n",
    "    false_negative = 100*(np.mean(np.array(validation_y)[y_valid_pred == 0]))\n",
    "    logging.info(\"False positive rate: \" + str(false_positive)+ \"; False negative rate: \" + str(false_negative))\n",
    "    loss.append(2*(false_negative**2) + false_positive**1.3)\n",
    "    #calculate accuracy:\n",
    "    accuracy.append(np.mean(y_valid_pred == np.array(validation_y)))\n",
    "    #calculate ROC-AUC score:\n",
    "    ROC_AUC.append(roc_auc_score(np.array(validation_y), bst.predict(dvalid)))\n",
    "    \n",
    "print(\"Loss values: %s\" %loss) \n",
    "print(\"Accuracies: %s\" %accuracy)\n",
    "print(\"ROC-AUC scores: %s\" %ROC_AUC)\n",
    "\n",
    "np.save(join(CURRENT_DIR, \"..\" ,\"data\", \"training_results\", \"acc_CV_xgboost_ESM1b_ts_GNN_pretrained.npy\"), np.array(accuracy))\n",
    "np.save(join(CURRENT_DIR, \"..\" ,\"data\", \"training_results\", \"loss_CV_xgboost_ESM1b_ts_GNN_pretrained.npy\"), np.array(loss))\n",
    "np.save(join(CURRENT_DIR, \"..\" ,\"data\", \"training_results\", \"ROC_AUC_CV_xgboost_ESM1b_ts_GNN_pretrained.npy\"), np.array(ROC_AUC))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[06:18:40] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Accuracy on test set: 0.9181217029496991, ROC-AUC score for test set: 0.9562220354082519, MCC: 0.7889261156069193\n"
     ]
    }
   ],
   "source": [
    "dtrain = xgb.DMatrix(np.array(train_X), weight = weights, label = np.array(train_y),\n",
    "                feature_names= feature_names)\n",
    "dtest = xgb.DMatrix(np.array(test_X), label = np.array(test_y),\n",
    "                    feature_names= feature_names)\n",
    "\n",
    "bst = xgb.train(param,  dtrain, int(num_round), verbose_eval=1)\n",
    "y_test_pred = np.round(bst.predict(dtest))\n",
    "acc_test = np.mean(y_test_pred == np.array(test_y))\n",
    "roc_auc = roc_auc_score(np.array(test_y), bst.predict(dtest))\n",
    "mcc = matthews_corrcoef(np.array(test_y), y_test_pred)\n",
    "\n",
    "print(\"Accuracy on test set: %s, ROC-AUC score for test set: %s, MCC: %s\"  % (acc_test, roc_auc, mcc))\n",
    "\n",
    "np.save(join(CURRENT_DIR, \"..\" ,\"data\", \"training_results\", \"y_test_pred_xgboost_ESM1b_ts_GNN_pretrained.npy\"), bst.predict(dtest))\n",
    "np.save(join(CURRENT_DIR, \"..\" ,\"data\", \"training_results\", \"y_test_true_xgboost_ESM1b_ts_GNN_pretrained.npy\"), test_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (g) ESM1b_ts (mean representaion) and GNN (pretrained):"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (i) Creating numpy arrays with input vectors and output variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_input_and_output_data(df):\n",
    "    X = ();\n",
    "    y = ();\n",
    "    \n",
    "    for ind in df.index:\n",
    "        emb = df[\"ESM1b_ts_mean\"][ind]\n",
    "        ecfp = df[\"GNN rep (pretrained)\"][ind]\n",
    "                \n",
    "        X = X +(np.concatenate([ecfp, emb]), );\n",
    "        y = y + (df[\"Binding\"][ind], );\n",
    "\n",
    "    return(X,y)\n",
    "\n",
    "train_X, train_y =  create_input_and_output_data(df = df_train)\n",
    "test_X, test_y =  create_input_and_output_data(df = df_test)\n",
    "\n",
    "\n",
    "feature_names =  [\"GNN rep_\" + str(i) for i in range(50)]\n",
    "feature_names = feature_names + [\"ESM1b_\" + str(i) for i in range(1280)]\n",
    "\n",
    "train_X = np.array(train_X)\n",
    "test_X  = np.array(test_X)\n",
    "\n",
    "train_y = np.array(train_y)\n",
    "test_y  = np.array(test_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (ii) Performing hyperparameter optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_validation_neg_acc_gradient_boosting(param):\n",
    "    num_round = param[\"num_rounds\"]\n",
    "    param[\"tree_method\"] = \"gpu_hist\"\n",
    "    param[\"sampling_method\"] = \"gradient_based\"\n",
    "    param['objective'] = 'binary:logistic'\n",
    "    weights = np.array([param[\"weight\"] if binding == 0 else 1.0 for binding in df_train[\"Binding\"]])\n",
    "    \n",
    "    del param[\"num_rounds\"]\n",
    "    del param[\"weight\"]\n",
    "    \n",
    "    loss = []\n",
    "    for i in range(5):\n",
    "        train_index, test_index  = train_indices[i], test_indices[i]\n",
    "        dtrain = xgb.DMatrix(np.array(train_X[train_index]), weight = weights[train_index],\n",
    "                         label = np.array(train_y[train_index]))\n",
    "        dvalid = xgb.DMatrix(np.array(train_X[test_index]))\n",
    "        bst = xgb.train(param,  dtrain, int(num_round), verbose_eval=1)\n",
    "        y_valid_pred = np.round(bst.predict(dvalid))\n",
    "        validation_y = train_y[test_index]\n",
    "    \n",
    "        false_positive = 100*(1-np.mean(np.array(validation_y)[y_valid_pred == 1]))\n",
    "        false_negative = 100*(np.mean(np.array(validation_y)[y_valid_pred == 0]))\n",
    "        logging.info(\"False positive rate: \" + str(false_positive)+ \"; False negative rate: \" + str(false_negative))\n",
    "        loss.append(2*(false_negative**2) + false_positive**1.3)\n",
    "    return(np.mean(loss))\n",
    "\n",
    "#Defining search space for hyperparameter optimization\n",
    "space_gradient_boosting = {\"learning_rate\": hp.uniform(\"learning_rate\", 0.01, 0.5),\n",
    "    \"max_depth\": hp.choice(\"max_depth\", [9,10,11,12,13]),\n",
    "    \"reg_lambda\": hp.uniform(\"reg_lambda\", 0, 5),\n",
    "    \"reg_alpha\": hp.uniform(\"reg_alpha\", 0, 5),\n",
    "    \"max_delta_step\": hp.uniform(\"max_delta_step\", 0, 5),\n",
    "    \"min_child_weight\": hp.uniform(\"min_child_weight\", 0.1, 15),\n",
    "    \"num_rounds\":  hp.uniform(\"num_rounds\", 200, 400),\n",
    "    \"weight\" : hp.uniform(\"weight\", 0.1,0.33)}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Performing a random grid search:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''trials = Trials()\n",
    "\n",
    "for i in range(1,2000):\n",
    "    best = fmin(fn = cross_validation_neg_acc_gradient_boosting, space = space_gradient_boosting,\n",
    "                algo = rand.suggest, max_evals = i, trials = trials)\n",
    "    logging.info(i)\n",
    "    logging.info(trials.best_trial[\"result\"][\"loss\"])\n",
    "    logging.info(trials.argmin)''';"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Best set of hyperparameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "param = {'learning_rate': 0.1156069031228949,\n",
    "         'max_delta_step': 2.6918966267028415,\n",
    "         'max_depth': 12,\n",
    "         'min_child_weight': 1.9758135134127655,\n",
    "         'num_rounds': 127.079967978755,\n",
    "         'reg_alpha': 2.3233749696436714,\n",
    "         'reg_lambda': 2.163811098458429,\n",
    "         'weight': 0.28341863683389795}\n",
    "\n",
    "num_round = param[\"num_rounds\"]\n",
    "param[\"tree_method\"] = \"gpu_hist\"\n",
    "param[\"sampling_method\"] = \"gradient_based\"\n",
    "param['objective'] = 'binary:logistic'\n",
    "weights = np.array([param[\"weight\"] if binding == 0 else 1.0 for binding in df_train[\"Binding\"]])\n",
    "\n",
    "del param[\"num_rounds\"]\n",
    "del param[\"weight\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (iii) Repeating 5-fold CV for best set of hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[06:22:35] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[06:23:28] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[06:24:21] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[06:25:14] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[06:26:06] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Loss values: [84.09770237588249, 93.2762385821601, 105.77465665299039, 112.21969637517623, 101.68673959966944]\n",
      "Accuracies: [0.916733961417676, 0.9144748613347647, 0.9059873494497878, 0.9043572590851564, 0.910427319211103]\n",
      "ROC-AUC scores: [0.9636427269607835, 0.9587725902992912, 0.9556605491176462, 0.9545229260971622, 0.9585052255048616]\n"
     ]
    }
   ],
   "source": [
    "loss = []\n",
    "accuracy = []\n",
    "ROC_AUC = []\n",
    "\n",
    "for i in range(5):\n",
    "    train_index, test_index  = train_indices[i], test_indices[i]\n",
    "    dtrain = xgb.DMatrix(np.array(train_X[train_index]), weight = weights[train_index],\n",
    "                     label = np.array(train_y[train_index]))\n",
    "    dvalid = xgb.DMatrix(np.array(train_X[test_index]))\n",
    "    bst = xgb.train(param,  dtrain, int(num_round), verbose_eval=1)\n",
    "    y_valid_pred = np.round(bst.predict(dvalid))\n",
    "    validation_y = train_y[test_index]\n",
    "\n",
    "    #calculate loss:\n",
    "    false_positive = 100*(1-np.mean(np.array(validation_y)[y_valid_pred == 1]))\n",
    "    false_negative = 100*(np.mean(np.array(validation_y)[y_valid_pred == 0]))\n",
    "    logging.info(\"False positive rate: \" + str(false_positive)+ \"; False negative rate: \" + str(false_negative))\n",
    "    loss.append(2*(false_negative**2) + false_positive**1.3)\n",
    "    #calculate accuracy:\n",
    "    accuracy.append(np.mean(y_valid_pred == np.array(validation_y)))\n",
    "    #calculate ROC-AUC score:\n",
    "    ROC_AUC.append(roc_auc_score(np.array(validation_y), bst.predict(dvalid)))\n",
    "    \n",
    "print(\"Loss values: %s\" %loss) \n",
    "print(\"Accuracies: %s\" %accuracy)\n",
    "print(\"ROC-AUC scores: %s\" %ROC_AUC)\n",
    "\n",
    "np.save(join(CURRENT_DIR, \"..\" ,\"data\", \"training_results\", \"acc_CV_xgboost_ESM1b_ts_mean_GNN_pretrained.npy\"), np.array(accuracy))\n",
    "np.save(join(CURRENT_DIR, \"..\" ,\"data\", \"training_results\", \"loss_CV_xgboost_ESM1b_ts_mean_GNN_pretrained.npy\"), np.array(loss))\n",
    "np.save(join(CURRENT_DIR, \"..\" ,\"data\", \"training_results\", \"ROC_AUC_CV_xgboost_ESM1b_ts_mean_GNN_pretrained.npy\"), np.array(ROC_AUC))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[06:27:00] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Accuracy on test set: 0.9101716323649602, ROC-AUC score for test set: 0.956069174706691, MCC: 0.7725739053747791\n"
     ]
    }
   ],
   "source": [
    "dtrain = xgb.DMatrix(np.array(train_X), weight = weights, label = np.array(train_y),\n",
    "                feature_names= feature_names)\n",
    "dtest = xgb.DMatrix(np.array(test_X), label = np.array(test_y),\n",
    "                    feature_names= feature_names)\n",
    "\n",
    "bst = xgb.train(param,  dtrain, int(num_round), verbose_eval=1)\n",
    "y_test_pred = np.round(bst.predict(dtest))\n",
    "acc_test = np.mean(y_test_pred == np.array(test_y))\n",
    "roc_auc = roc_auc_score(np.array(test_y), bst.predict(dtest))\n",
    "mcc = matthews_corrcoef(np.array(test_y), y_test_pred)\n",
    "\n",
    "print(\"Accuracy on test set: %s, ROC-AUC score for test set: %s, MCC: %s\"  % (acc_test, roc_auc, mcc))\n",
    "\n",
    "np.save(join(CURRENT_DIR, \"..\" ,\"data\", \"training_results\", \"y_test_pred_xgboost_ESM1b_ts_mean_GNN_pretrained.npy\"), bst.predict(dtest))\n",
    "np.save(join(CURRENT_DIR, \"..\" ,\"data\", \"training_results\", \"y_test_true_xgboost_ESM1b_ts_mean_GNN_pretrained.npy\"), test_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (h) ESM1b_ts and GNN (not pre-trained):"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (i) Creating numpy arrays with input vectors and output variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_input_and_output_data(df):\n",
    "    X = ();\n",
    "    y = ();\n",
    "    \n",
    "    for ind in df.index:\n",
    "        emb = df[\"ESM1b_ts\"][ind]\n",
    "        ecfp = df[\"GNN rep\"][ind]\n",
    "                \n",
    "        X = X +(np.concatenate([ecfp, emb]), );\n",
    "        y = y + (df[\"Binding\"][ind], );\n",
    "\n",
    "    return(X,y)\n",
    "\n",
    "train_X, train_y =  create_input_and_output_data(df = df_train)\n",
    "test_X, test_y =  create_input_and_output_data(df = df_test)\n",
    "\n",
    "\n",
    "feature_names =  [\"GNN rep_\" + str(i) for i in range(50)]\n",
    "feature_names = feature_names + [\"ESM1b_\" + str(i) for i in range(1280)]\n",
    "\n",
    "train_X = np.array(train_X)\n",
    "test_X  = np.array(test_X)\n",
    "\n",
    "train_y = np.array(train_y)\n",
    "test_y  = np.array(test_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (ii) Performing hyperparameter optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_validation_neg_acc_gradient_boosting(param):\n",
    "    num_round = param[\"num_rounds\"]\n",
    "    param[\"tree_method\"] = \"gpu_hist\"\n",
    "    param[\"sampling_method\"] = \"gradient_based\"\n",
    "    param['objective'] = 'binary:logistic'\n",
    "    weights = np.array([param[\"weight\"] if binding == 0 else 1.0 for binding in df_train[\"Binding\"]])\n",
    "    \n",
    "    del param[\"num_rounds\"]\n",
    "    del param[\"weight\"]\n",
    "    \n",
    "    loss = []\n",
    "    for i in range(5):\n",
    "        train_index, test_index  = train_indices[i], test_indices[i]\n",
    "        dtrain = xgb.DMatrix(np.array(train_X[train_index]), weight = weights[train_index],\n",
    "                         label = np.array(train_y[train_index]))\n",
    "        dvalid = xgb.DMatrix(np.array(train_X[test_index]))\n",
    "        bst = xgb.train(param,  dtrain, int(num_round), verbose_eval=1)\n",
    "        y_valid_pred = np.round(bst.predict(dvalid))\n",
    "        validation_y = train_y[test_index]\n",
    "    \n",
    "        false_positive = 100*(1-np.mean(np.array(validation_y)[y_valid_pred == 1]))\n",
    "        false_negative = 100*(np.mean(np.array(validation_y)[y_valid_pred == 0]))\n",
    "        logging.info(\"False positive rate: \" + str(false_positive)+ \"; False negative rate: \" + str(false_negative))\n",
    "        loss.append(2*(false_negative**2) + false_positive**1.3)\n",
    "    return(np.mean(loss))\n",
    "\n",
    "#Defining search space for hyperparameter optimization\n",
    "space_gradient_boosting = {\"learning_rate\": hp.uniform(\"learning_rate\", 0.01, 0.5),\n",
    "    \"max_depth\": hp.choice(\"max_depth\", [9,10,11,12,13]),\n",
    "    \"reg_lambda\": hp.uniform(\"reg_lambda\", 0, 5),\n",
    "    \"reg_alpha\": hp.uniform(\"reg_alpha\", 0, 5),\n",
    "    \"max_delta_step\": hp.uniform(\"max_delta_step\", 0, 5),\n",
    "    \"min_child_weight\": hp.uniform(\"min_child_weight\", 0.1, 15),\n",
    "    \"num_rounds\":  hp.uniform(\"num_rounds\", 200, 400),\n",
    "    \"weight\" : hp.uniform(\"weight\", 0.1,0.33)}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Performing a random grid search:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''trials = Trials()\n",
    "\n",
    "for i in range(1,2000):\n",
    "    best = fmin(fn = cross_validation_neg_acc_gradient_boosting, space = space_gradient_boosting,\n",
    "                algo = rand.suggest, max_evals = i, trials = trials)\n",
    "    logging.info(i)\n",
    "    logging.info(trials.best_trial[\"result\"][\"loss\"])\n",
    "    logging.info(trials.argmin)''';"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Best set of hyperparameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "param = {'learning_rate': 0.18444025726334898,\n",
    "         'max_delta_step': 3.2748796106084117,\n",
    "         'max_depth': 13,\n",
    "         'min_child_weight': 3.1946753845027738,\n",
    "         'num_rounds': 314.1036429221291,\n",
    "         'reg_alpha': 0.48821021807600673,\n",
    "         'reg_lambda': 2.6236829011598073,\n",
    "         'weight': 0.1264521266931227}\n",
    "\n",
    "num_round = param[\"num_rounds\"]\n",
    "param[\"tree_method\"] = \"gpu_hist\"\n",
    "param[\"sampling_method\"] = \"gradient_based\"\n",
    "param['objective'] = 'binary:logistic'\n",
    "weights = np.array([param[\"weight\"] if binding == 0 else 1.0 for binding in df_train[\"Binding\"]])\n",
    "\n",
    "del param[\"num_rounds\"]\n",
    "del param[\"weight\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (iii) Repeating 5-fold CV for best set of hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[06:28:56] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[06:30:17] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[06:31:36] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[06:32:53] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[06:34:12] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Loss values: [95.85892125174448, 101.18538008374776, 107.3774676337244, 113.8545092756927, 103.56995296940914]\n",
      "Accuracies: [0.9084791386271871, 0.9079441760601181, 0.9039944545533316, 0.9011028747062014, 0.910336011687363]\n",
      "ROC-AUC scores: [0.9591609388450508, 0.9585739135344192, 0.9547930983970586, 0.9530322066116591, 0.9565295911826541]\n"
     ]
    }
   ],
   "source": [
    "loss = []\n",
    "accuracy = []\n",
    "ROC_AUC = []\n",
    "\n",
    "for i in range(5):\n",
    "    train_index, test_index  = train_indices[i], test_indices[i]\n",
    "    dtrain = xgb.DMatrix(np.array(train_X[train_index]), weight = weights[train_index],\n",
    "                     label = np.array(train_y[train_index]))\n",
    "    dvalid = xgb.DMatrix(np.array(train_X[test_index]))\n",
    "    bst = xgb.train(param,  dtrain, int(num_round), verbose_eval=1)\n",
    "    y_valid_pred = np.round(bst.predict(dvalid))\n",
    "    validation_y = train_y[test_index]\n",
    "\n",
    "    #calculate loss:\n",
    "    false_positive = 100*(1-np.mean(np.array(validation_y)[y_valid_pred == 1]))\n",
    "    false_negative = 100*(np.mean(np.array(validation_y)[y_valid_pred == 0]))\n",
    "    logging.info(\"False positive rate: \" + str(false_positive)+ \"; False negative rate: \" + str(false_negative))\n",
    "    loss.append(2*(false_negative**2) + false_positive**1.3)\n",
    "    #calculate accuracy:\n",
    "    accuracy.append(np.mean(y_valid_pred == np.array(validation_y)))\n",
    "    #calculate ROC-AUC score:\n",
    "    ROC_AUC.append(roc_auc_score(np.array(validation_y), bst.predict(dvalid)))\n",
    "    \n",
    "print(\"Loss values: %s\" %loss) \n",
    "print(\"Accuracies: %s\" %accuracy)\n",
    "print(\"ROC-AUC scores: %s\" %ROC_AUC)\n",
    "\n",
    "np.save(join(CURRENT_DIR, \"..\" ,\"data\", \"training_results\", \"acc_CV_xgboost_ESM1b_ts_GNN.npy\"), np.array(accuracy))\n",
    "np.save(join(CURRENT_DIR, \"..\" ,\"data\", \"training_results\", \"loss_CV_xgboost_ESM1b_ts_GNN.npy\"), np.array(loss))\n",
    "np.save(join(CURRENT_DIR, \"..\" ,\"data\", \"training_results\", \"ROC_AUC_CV_xgboost_ESM1b_ts_GNN.npy\"), np.array(ROC_AUC))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (iv) 3. Training and validating the final model\n",
    "Training the model and validating it on the test set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[06:35:32] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Accuracy on test set: 0.9063823463853183, ROC-AUC score for test set: 0.9546895380125349, MCC: 0.763088327957358\n"
     ]
    }
   ],
   "source": [
    "dtrain = xgb.DMatrix(np.array(train_X), weight = weights, label = np.array(train_y),\n",
    "                feature_names= feature_names)\n",
    "dtest = xgb.DMatrix(np.array(test_X), label = np.array(test_y),\n",
    "                    feature_names= feature_names)\n",
    "\n",
    "bst = xgb.train(param,  dtrain, int(num_round), verbose_eval=1)\n",
    "y_test_pred = np.round(bst.predict(dtest))\n",
    "acc_test = np.mean(y_test_pred == np.array(test_y))\n",
    "roc_auc = roc_auc_score(np.array(test_y), bst.predict(dtest))\n",
    "mcc = matthews_corrcoef(np.array(test_y), y_test_pred)\n",
    "\n",
    "print(\"Accuracy on test set: %s, ROC-AUC score for test set: %s, MCC: %s\"  % (acc_test, roc_auc, mcc))\n",
    "\n",
    "np.save(join(CURRENT_DIR, \"..\" ,\"data\", \"training_results\", \"y_test_pred_xgboost_ESM1b_ts_GNN.npy\"), bst.predict(dtest))\n",
    "np.save(join(CURRENT_DIR, \"..\" ,\"data\", \"training_results\", \"y_test_true_xgboost_ESM1b_ts_GNN.npy\"), test_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.Training the best model with training and test set (production mode):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_input_and_output_data(df):\n",
    "    X = ();\n",
    "    y = ();\n",
    "    \n",
    "    for ind in df.index:\n",
    "        emb = df[\"ESM1b_ts\"][ind]\n",
    "        ecfp = np.array(list(df[\"ECFP\"][ind])).astype(int)\n",
    "                \n",
    "        X = X +(np.concatenate([ecfp, emb]), );\n",
    "        y = y + (df[\"Binding\"][ind], );\n",
    "\n",
    "    return(X,y)\n",
    "\n",
    "train_X, train_y =  create_input_and_output_data(df = df_train)\n",
    "test_X, test_y =  create_input_and_output_data(df = df_test)\n",
    "\n",
    "\n",
    "feature_names =  [\"ECFP_\" + str(i) for i in range(1024)]\n",
    "feature_names = feature_names + [\"ESM1b_ts_\" + str(i) for i in range(1280)]\n",
    "\n",
    "train_X = np.array(train_X)\n",
    "test_X  = np.array(test_X)\n",
    "\n",
    "train_y = np.array(train_y)\n",
    "test_y  = np.array(test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X = np.concatenate([train_X, test_X])\n",
    "train_y = np.concatenate([train_y, test_y])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "param = {'learning_rate': 0.31553117247348733,\n",
    "         'max_delta_step': 1.7726044219753656,\n",
    "         'max_depth': 10,\n",
    "         'min_child_weight': 1.3845040588450772,\n",
    "         'num_rounds': 342.68325188584106,\n",
    "         'reg_alpha': 0.531395259755843,\n",
    "         'reg_lambda': 3.744980563764689,\n",
    "         'weight': 0.26187490421514203}\n",
    "\n",
    "num_round = param[\"num_rounds\"]\n",
    "param[\"tree_method\"] = \"gpu_hist\"\n",
    "param[\"sampling_method\"] = \"gradient_based\"\n",
    "param['objective'] = 'binary:logistic'\n",
    "weights = np.array([param[\"weight\"] if binding == 0 else 1.0 for binding in train_y])\n",
    "\n",
    "del param[\"num_rounds\"]\n",
    "del param[\"weight\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[06:38:13] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Accuracy on test set: 0.995690615944721, ROC-AUC score for test set: 0.999973562453436, MCC: 0.9890341165154867\n"
     ]
    }
   ],
   "source": [
    "dtrain = xgb.DMatrix(np.array(train_X), weight = weights, label = np.array(train_y),\n",
    "                feature_names= feature_names)\n",
    "dtest = xgb.DMatrix(np.array(test_X), label = np.array(test_y),\n",
    "                    feature_names= feature_names)\n",
    "\n",
    "bst = xgb.train(param,  dtrain, int(num_round), verbose_eval=1)\n",
    "y_test_pred = np.round(bst.predict(dtest))\n",
    "acc_test = np.mean(y_test_pred == np.array(test_y))\n",
    "roc_auc = roc_auc_score(np.array(test_y), bst.predict(dtest))\n",
    "mcc = matthews_corrcoef(np.array(test_y), y_test_pred)\n",
    "\n",
    "print(\"Accuracy on test set: %s, ROC-AUC score for test set: %s, MCC: %s\"  % (acc_test, roc_auc, mcc))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on train set: 0.9952117916840937, ROC-AUC score for train set: 0.9999666505894647, MCC: 0.9878260302574451\n"
     ]
    }
   ],
   "source": [
    "y_train_pred = np.round(bst.predict(dtrain))\n",
    "acc_train = np.mean(y_train_pred == np.array(train_y))\n",
    "roc_auc = roc_auc_score(np.array(train_y), bst.predict(dtrain))\n",
    "mcc = matthews_corrcoef(np.array(train_y), y_train_pred)\n",
    "\n",
    "print(\"Accuracy on train set: %s, ROC-AUC score for train set: %s, MCC: %s\"  % (acc_train, roc_auc, mcc))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(bst, open(join(CURRENT_DIR, \"..\" ,\"data\", \"model_weights\",\n",
    "                           \"xgboost_model_production_mode.dat\"), \"wb\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
