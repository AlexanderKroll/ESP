{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "from os.path import join\n",
    "import numpy as np\n",
    "import pickle\n",
    "import random\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import Dataset\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n",
    "\n",
    "sys.path.append('.\\\\additional_code')\n",
    "from xgboost_training_KM import *\n",
    "\n",
    "CURRENT_DIR = os.getcwd()\n",
    "print(CURRENT_DIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Loading and preprocessing data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_pickle(join(CURRENT_DIR, \"..\" ,\"data\",\"KM\", \"training_data_KM_new_with_unchecked_data.pkl\"))\n",
    "df_test = pd.read_pickle(join(CURRENT_DIR, \"..\" ,\"data\",\"KM\", \"test_data_KM_new_with_unchecked_data.pkl\"))\n",
    "\n",
    "df_train.rename(columns = {\"KEGG ID\" : \"molecule ID\"}, inplace = True)\n",
    "df_test.rename(columns = {\"KEGG ID\" : \"molecule ID\"}, inplace = True)\n",
    "\n",
    "df_train[\"Uniprot ID\"] = [\"Enzyme:train:\" + str(ind) for ind in df_train.index]\n",
    "df_test[\"Uniprot ID\"] = [\"Enzyme:test:\" + str(ind) for ind in df_test.index]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (a) Create dictionary with all target values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "mol_files = list(set(df_train[\"molecule ID\"])) + list(set(df_test[\"molecule ID\"]))\n",
    "mol_files = list(set(mol_files))\n",
    "\n",
    "target_variable_dict_KM = {}\n",
    "target_variable_dict_KM = create_target_dict_KM(df = df_train, target_variable_dict = target_variable_dict_KM)\n",
    "target_variable_dict_KM = create_target_dict_KM(df = df_test, target_variable_dict = target_variable_dict_KM)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (c) Get list with input combinations of Uniprot ID and metabolite ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7580 812\n"
     ]
    }
   ],
   "source": [
    "train_IDs = get_uid_cid_IDs(df_train)\n",
    "test_IDs = get_uid_cid_IDs(df_test)\n",
    "\n",
    "print(len(train_IDs), len(test_IDs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Calculating input matrices for metabolites"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (a) Creating input matrices:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "calculate_atom_and_bond_feature_vectors(mol_files = mol_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "More than 70 (75) atoms in molcuele C21471\n",
      "Could not create input for substrate ID C21471\n",
      "More than 70 (90) atoms in molcuele C06509\n",
      "Could not create input for substrate ID C06509\n",
      "More than 70 (113) atoms in molcuele C06510\n",
      "Could not create input for substrate ID C06510\n",
      "More than 70 (77) atoms in molcuele C04702\n",
      "Could not create input for substrate ID C04702\n",
      "More than 70 (96) atoms in molcuele C02015\n",
      "Could not create input for substrate ID C02015\n",
      "More than 70 (130) atoms in molcuele C05893\n",
      "Could not create input for substrate ID C05893\n",
      "More than 70 (91) atoms in molcuele C00853\n",
      "Could not create input for substrate ID C00853\n",
      "More than 70 (91) atoms in molcuele C00541\n",
      "Could not create input for substrate ID C00541\n"
     ]
    }
   ],
   "source": [
    "for mol_ID in mol_files:\n",
    "    calculate_and_save_input_matrixes(molecule_ID = mol_ID)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  (b) Removing all datapoints without molecule input file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>molecule ID</th>\n",
       "      <th>ESM1b</th>\n",
       "      <th>ECFP</th>\n",
       "      <th>RDKit FP</th>\n",
       "      <th>MACCS FP</th>\n",
       "      <th>PMID</th>\n",
       "      <th>MW</th>\n",
       "      <th>LogP</th>\n",
       "      <th>log10_KM</th>\n",
       "      <th>checked</th>\n",
       "      <th>GNN FP</th>\n",
       "      <th>Uniprot ID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>C00387</td>\n",
       "      <td>[0.100948475, 0.23829113, 0.0027401948, 0.0371...</td>\n",
       "      <td>0000000000000000000000000000000000000000010000...</td>\n",
       "      <td>1010111010101011101111011100011011000100100110...</td>\n",
       "      <td>0000000000000000000000000100000000000010000100...</td>\n",
       "      <td>17918964.0</td>\n",
       "      <td>283.091669</td>\n",
       "      <td>-2.6867</td>\n",
       "      <td>-0.728158</td>\n",
       "      <td>True</td>\n",
       "      <td>[13.362184, 70.41528, 2.7784162, 60.74657, 0.0...</td>\n",
       "      <td>Enzyme:train:0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>C00143</td>\n",
       "      <td>[-0.09477718, 0.16472308, 0.09403025, 0.007433...</td>\n",
       "      <td>0100000000000000000000000000000000000000000000...</td>\n",
       "      <td>1111111000110111101101111011100011001011011110...</td>\n",
       "      <td>0000000000000000000000000100100000000010000100...</td>\n",
       "      <td>21858212.0</td>\n",
       "      <td>457.170981</td>\n",
       "      <td>-0.5219</td>\n",
       "      <td>-0.744727</td>\n",
       "      <td>True</td>\n",
       "      <td>[18.767265, 151.67131, 25.194078, 66.9493, 0.6...</td>\n",
       "      <td>Enzyme:train:1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>C00756</td>\n",
       "      <td>[0.12043195, 0.17901447, -0.003300894, 0.07185...</td>\n",
       "      <td>0000000000000000000000000000000001000000000000...</td>\n",
       "      <td>0000000000000000000000000000000000000000000000...</td>\n",
       "      <td>0000000000000000000000000000000000000000000000...</td>\n",
       "      <td>19383697.0</td>\n",
       "      <td>130.135765</td>\n",
       "      <td>2.3392</td>\n",
       "      <td>0.588832</td>\n",
       "      <td>True</td>\n",
       "      <td>[0.053105697, 23.302288, 3.7088723, 5.9439626,...</td>\n",
       "      <td>Enzyme:train:2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>C00002</td>\n",
       "      <td>[0.068544716, 0.23684321, 0.080181114, -0.0251...</td>\n",
       "      <td>0000000001000000000000000000000000000000000000...</td>\n",
       "      <td>1010111010101011101011111000111010011100100111...</td>\n",
       "      <td>0000000000000000000000000000010000000010000100...</td>\n",
       "      <td>19509290.0</td>\n",
       "      <td>506.995745</td>\n",
       "      <td>-1.6290</td>\n",
       "      <td>-0.709965</td>\n",
       "      <td>True</td>\n",
       "      <td>[15.331518, 103.84776, 6.569991, 63.609444, 0....</td>\n",
       "      <td>Enzyme:train:3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>C00083</td>\n",
       "      <td>[-0.062576994, 0.30821875, 0.101220384, -0.011...</td>\n",
       "      <td>0100000001000100000000000000000001000000010000...</td>\n",
       "      <td>1010111010101011101011111011111010011100111111...</td>\n",
       "      <td>0000000000000000000000000000010000000010000100...</td>\n",
       "      <td>17292360.0</td>\n",
       "      <td>853.115603</td>\n",
       "      <td>-1.8606</td>\n",
       "      <td>-2.246545</td>\n",
       "      <td>True</td>\n",
       "      <td>[19.037132, 187.85568, 16.434797, 90.37692, 1....</td>\n",
       "      <td>Enzyme:train:4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7575</th>\n",
       "      <td>C20925</td>\n",
       "      <td>[-0.12106511, 0.16286044, -0.05657043, 0.00162...</td>\n",
       "      <td>0100000000000010000000000000000001000000010000...</td>\n",
       "      <td>0000000000000011100011000011000011000000001000...</td>\n",
       "      <td>0000000000000000000000000000000000000000000000...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>390.175064</td>\n",
       "      <td>-2.1652</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>False</td>\n",
       "      <td>[14.411318, 104.04242, 21.408749, 26.555807, 2...</td>\n",
       "      <td>Enzyme:train:7575</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7576</th>\n",
       "      <td>C21181</td>\n",
       "      <td>[-0.009757707, 0.1251226, 0.011750575, -0.0227...</td>\n",
       "      <td>0100000000000000000000000000000000000000000000...</td>\n",
       "      <td>0000000010000000000000000000000000000000000000...</td>\n",
       "      <td>0000000000000000000000000000000000000001100000...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>153.993594</td>\n",
       "      <td>-1.5660</td>\n",
       "      <td>-0.853872</td>\n",
       "      <td>False</td>\n",
       "      <td></td>\n",
       "      <td>Enzyme:train:7576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7577</th>\n",
       "      <td>C21310</td>\n",
       "      <td>[-0.0037425177, 0.06174834, -0.05052497, 0.063...</td>\n",
       "      <td>0000000000000100000000000000000000001000000000...</td>\n",
       "      <td>1011111011011111101111111101101011111111111111...</td>\n",
       "      <td>0000000000000000000000000100010000000010000100...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>522.990660</td>\n",
       "      <td>-2.9161</td>\n",
       "      <td>-3.102373</td>\n",
       "      <td>False</td>\n",
       "      <td>[12.673787, 120.78082, 6.8376884, 88.71222, 0....</td>\n",
       "      <td>Enzyme:train:7577</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7578</th>\n",
       "      <td>C21563</td>\n",
       "      <td>[0.028141364, 0.16967583, -0.118034706, 0.1133...</td>\n",
       "      <td>0100010000000000000000000000000000000000010000...</td>\n",
       "      <td>0100000100001010100001000011001110000001001101...</td>\n",
       "      <td>0000000000000000000000000000000000000000000000...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>415.104936</td>\n",
       "      <td>-0.9324</td>\n",
       "      <td>-0.366532</td>\n",
       "      <td>False</td>\n",
       "      <td>[10.382019, 105.68732, 18.721575, 34.91598, 2....</td>\n",
       "      <td>Enzyme:train:7578</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7579</th>\n",
       "      <td>C21737</td>\n",
       "      <td>[-0.017929962, 0.2529225, -0.14529729, -0.0213...</td>\n",
       "      <td>1000000000000000000000000000000000000000000000...</td>\n",
       "      <td>0000000000010000000000000000000000000000000000...</td>\n",
       "      <td>0000000000000010000000000000000000000000000000...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>238.033351</td>\n",
       "      <td>2.0974</td>\n",
       "      <td>-0.221849</td>\n",
       "      <td>False</td>\n",
       "      <td></td>\n",
       "      <td>Enzyme:train:7579</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7569 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     molecule ID                                              ESM1b  \\\n",
       "0         C00387  [0.100948475, 0.23829113, 0.0027401948, 0.0371...   \n",
       "1         C00143  [-0.09477718, 0.16472308, 0.09403025, 0.007433...   \n",
       "2         C00756  [0.12043195, 0.17901447, -0.003300894, 0.07185...   \n",
       "3         C00002  [0.068544716, 0.23684321, 0.080181114, -0.0251...   \n",
       "4         C00083  [-0.062576994, 0.30821875, 0.101220384, -0.011...   \n",
       "...          ...                                                ...   \n",
       "7575      C20925  [-0.12106511, 0.16286044, -0.05657043, 0.00162...   \n",
       "7576      C21181  [-0.009757707, 0.1251226, 0.011750575, -0.0227...   \n",
       "7577      C21310  [-0.0037425177, 0.06174834, -0.05052497, 0.063...   \n",
       "7578      C21563  [0.028141364, 0.16967583, -0.118034706, 0.1133...   \n",
       "7579      C21737  [-0.017929962, 0.2529225, -0.14529729, -0.0213...   \n",
       "\n",
       "                                                   ECFP  \\\n",
       "0     0000000000000000000000000000000000000000010000...   \n",
       "1     0100000000000000000000000000000000000000000000...   \n",
       "2     0000000000000000000000000000000001000000000000...   \n",
       "3     0000000001000000000000000000000000000000000000...   \n",
       "4     0100000001000100000000000000000001000000010000...   \n",
       "...                                                 ...   \n",
       "7575  0100000000000010000000000000000001000000010000...   \n",
       "7576  0100000000000000000000000000000000000000000000...   \n",
       "7577  0000000000000100000000000000000000001000000000...   \n",
       "7578  0100010000000000000000000000000000000000010000...   \n",
       "7579  1000000000000000000000000000000000000000000000...   \n",
       "\n",
       "                                               RDKit FP  \\\n",
       "0     1010111010101011101111011100011011000100100110...   \n",
       "1     1111111000110111101101111011100011001011011110...   \n",
       "2     0000000000000000000000000000000000000000000000...   \n",
       "3     1010111010101011101011111000111010011100100111...   \n",
       "4     1010111010101011101011111011111010011100111111...   \n",
       "...                                                 ...   \n",
       "7575  0000000000000011100011000011000011000000001000...   \n",
       "7576  0000000010000000000000000000000000000000000000...   \n",
       "7577  1011111011011111101111111101101011111111111111...   \n",
       "7578  0100000100001010100001000011001110000001001101...   \n",
       "7579  0000000000010000000000000000000000000000000000...   \n",
       "\n",
       "                                               MACCS FP        PMID  \\\n",
       "0     0000000000000000000000000100000000000010000100...  17918964.0   \n",
       "1     0000000000000000000000000100100000000010000100...  21858212.0   \n",
       "2     0000000000000000000000000000000000000000000000...  19383697.0   \n",
       "3     0000000000000000000000000000010000000010000100...  19509290.0   \n",
       "4     0000000000000000000000000000010000000010000100...  17292360.0   \n",
       "...                                                 ...         ...   \n",
       "7575  0000000000000000000000000000000000000000000000...         NaN   \n",
       "7576  0000000000000000000000000000000000000001100000...         NaN   \n",
       "7577  0000000000000000000000000100010000000010000100...         NaN   \n",
       "7578  0000000000000000000000000000000000000000000000...         NaN   \n",
       "7579  0000000000000010000000000000000000000000000000...         NaN   \n",
       "\n",
       "              MW    LogP  log10_KM  checked  \\\n",
       "0     283.091669 -2.6867 -0.728158     True   \n",
       "1     457.170981 -0.5219 -0.744727     True   \n",
       "2     130.135765  2.3392  0.588832     True   \n",
       "3     506.995745 -1.6290 -0.709965     True   \n",
       "4     853.115603 -1.8606 -2.246545     True   \n",
       "...          ...     ...       ...      ...   \n",
       "7575  390.175064 -2.1652 -1.000000    False   \n",
       "7576  153.993594 -1.5660 -0.853872    False   \n",
       "7577  522.990660 -2.9161 -3.102373    False   \n",
       "7578  415.104936 -0.9324 -0.366532    False   \n",
       "7579  238.033351  2.0974 -0.221849    False   \n",
       "\n",
       "                                                 GNN FP         Uniprot ID  \n",
       "0     [13.362184, 70.41528, 2.7784162, 60.74657, 0.0...     Enzyme:train:0  \n",
       "1     [18.767265, 151.67131, 25.194078, 66.9493, 0.6...     Enzyme:train:1  \n",
       "2     [0.053105697, 23.302288, 3.7088723, 5.9439626,...     Enzyme:train:2  \n",
       "3     [15.331518, 103.84776, 6.569991, 63.609444, 0....     Enzyme:train:3  \n",
       "4     [19.037132, 187.85568, 16.434797, 90.37692, 1....     Enzyme:train:4  \n",
       "...                                                 ...                ...  \n",
       "7575  [14.411318, 104.04242, 21.408749, 26.555807, 2...  Enzyme:train:7575  \n",
       "7576                                                     Enzyme:train:7576  \n",
       "7577  [12.673787, 120.78082, 6.8376884, 88.71222, 0....  Enzyme:train:7577  \n",
       "7578  [10.382019, 105.68732, 18.721575, 34.91598, 2....  Enzyme:train:7578  \n",
       "7579                                                     Enzyme:train:7579  \n",
       "\n",
       "[7569 rows x 12 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid_mols = os.listdir(join(CURRENT_DIR, \"..\" ,\"data\", \"substrate_data_KM\", \"GNN_input_matrices\"))\n",
    "valid_mols = [mol.split(\"_A\")[0] for mol in valid_mols]\n",
    "\n",
    "df_train = df_train.loc[df_train[\"molecule ID\"].isin(valid_mols)]\n",
    "df_test = df_test.loc[df_test[\"molecule ID\"].isin(valid_mols)]\n",
    "\n",
    "train_IDs = get_uid_cid_IDs(df_train)\n",
    "test_IDs = get_uid_cid_IDs(df_test)\n",
    "df_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (c) Creating representations for the enzymes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "uids_list = list(set(df_train[\"Uniprot ID\"])) + list(set(df_test[\"Uniprot ID\"]))\n",
    "uids_list = list(set(uids_list))\n",
    "uid_to_emb = {}\n",
    "embeddings = np.zeros((0,1280))\n",
    "for uid in uids_list:\n",
    "    try:\n",
    "        emb = np.reshape(np.array(list(df_train[\"ESM1b\"].loc[df_train[\"Uniprot ID\"] == uid])[0]), (1,1280))\n",
    "    except IndexError:\n",
    "        try:\n",
    "            emb = np.reshape(np.array(list(df_test[\"ESM1b\"].loc[df_test[\"Uniprot ID\"] == uid])[0]), (1,1280))\n",
    "        except IndexError:\n",
    "            emb = np.reshape(np.array(list(df_validation[\"ESM1b\"].loc[df_validation[\"Uniprot ID\"] == uid])[0]), (1,1280))\n",
    "    embeddings = np.concatenate([embeddings, emb])\n",
    "    uid_to_emb[uid] = emb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We perform a PCA an the enzyme representations to get 50-dimensional representations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "dim = 50\n",
    "\n",
    "pca = PCA(n_components = dim)\n",
    "pca.fit(embeddings)\n",
    "emb_pca = pca.transform(embeddings)\n",
    "\n",
    "#Calculate mean and std to normalize the PCA-transformed vectors\n",
    "mean = np.mean(emb_pca, axis = 0)\n",
    "std = np.std(emb_pca, axis = 0)\n",
    "\n",
    "uid_to_pca_emb = {}\n",
    "\n",
    "for i, uid in enumerate(uids_list):\n",
    "    uid_to_pca_emb[uid] = (emb_pca[i] - mean) / std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "uid_to_emb = uid_to_pca_emb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Training GNN:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  (a) Defining a DataGenerator:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataSet(Dataset):\n",
    "    def __init__(self, split_IDs, folder):\n",
    "        self.all_IDs = split_IDs\n",
    "        self.folder = folder\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.all_IDs)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        ID = self.all_IDs[idx]\n",
    "        try:\n",
    "            [uid,cid1, cid2] = ID.split(\"_\") \n",
    "            cid = cid1 +\"_\"+cid2\n",
    "        except ValueError:\n",
    "            [uid,cid] = ID.split(\"_\")\n",
    "            \n",
    "        XE = torch.tensor(np.load(join(self.folder, cid + '_XE.npy')), dtype = torch.float32)\n",
    "        X = torch.tensor(np.load(join(self.folder, cid + '_X.npy')), dtype = torch.float32)\n",
    "        A = torch.tensor(np.load(join(self.folder, cid + '_A.npy')), dtype = torch.float32)\n",
    "        ESM1b = torch.tensor(uid_to_emb[uid], dtype = torch.float32)\n",
    "        label = torch.tensor(target_variable_dict_KM[ID], dtype= torch.float32)\n",
    "        return XE,X,A,ESM1b, label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (b) Splitting the training set in a validation and a training set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = len(train_IDs) \n",
    "random.seed(1)\n",
    "random.shuffle(train_IDs)\n",
    "test_IDs = train_IDs[int(0.8*n):]\n",
    "train_IDs = train_IDs[:int(0.8*n)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "\n",
    "train_dataset = CustomDataSet(folder  = join(CURRENT_DIR, \"..\" ,\"data\", \"substrate_data_KM\",\n",
    "                                             \"GNN_input_matrices\"), split_IDs = train_IDs)\n",
    "train_loader = DataLoader(train_dataset , batch_size=batch_size, shuffle=True, drop_last=True)\n",
    "\n",
    "test_dataset = CustomDataSet(folder  = join(CURRENT_DIR, \"..\" ,\"data\", \"substrate_data_KM\",\n",
    "                                            \"GNN_input_matrices\"), split_IDs = test_IDs)\n",
    "test_loader = DataLoader(test_dataset , batch_size=batch_size, shuffle=False, drop_last=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_train_batches = int(len(train_dataset)/batch_size)\n",
    "n_test_batches = int(len(test_dataset)/batch_size)\n",
    "train_batches = list(range(n_train_batches))\n",
    "test_batches = list(range(n_test_batches))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (c) Training GNN:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,    20] loss: 1.585\n",
      "[1,    40] loss: 1.272\n",
      "[1,    60] loss: 1.098\n",
      "Epoch: 0, Val. loss: 1.05, Val. mse: 1.05, Val R2: 0.0\n",
      "[2,    20] loss: 1.021\n",
      "[2,    40] loss: 0.965\n",
      "[2,    60] loss: 0.989\n",
      "Epoch: 1, Val. loss: 1.0, Val. mse: 1.0, Val R2: 0.0\n",
      "[3,    20] loss: 0.930\n",
      "[3,    40] loss: 0.974\n",
      "[3,    60] loss: 0.894\n",
      "Epoch: 2, Val. loss: 0.93, Val. mse: 0.93, Val R2: 0.0\n",
      "[4,    20] loss: 0.857\n",
      "[4,    40] loss: 0.882\n",
      "[4,    60] loss: 0.933\n",
      "Epoch: 3, Val. loss: 0.92, Val. mse: 0.92, Val R2: 0.0\n",
      "[5,    20] loss: 0.826\n",
      "[5,    40] loss: 0.885\n",
      "[5,    60] loss: 0.835\n",
      "Epoch: 4, Val. loss: 0.9, Val. mse: 0.9, Val R2: 0.0\n",
      "[6,    20] loss: 0.862\n",
      "[6,    40] loss: 0.820\n",
      "[6,    60] loss: 0.782\n",
      "Epoch: 5, Val. loss: 0.89, Val. mse: 0.89, Val R2: 0.0\n",
      "[7,    20] loss: 0.815\n",
      "[7,    40] loss: 0.849\n",
      "[7,    60] loss: 0.808\n",
      "Epoch: 6, Val. loss: 0.92, Val. mse: 0.92, Val R2: 0.0\n",
      "[8,    20] loss: 0.770\n",
      "[8,    40] loss: 0.735\n",
      "[8,    60] loss: 0.828\n",
      "Epoch: 7, Val. loss: 0.87, Val. mse: 0.87, Val R2: 0.0\n",
      "[9,    20] loss: 0.766\n",
      "[9,    40] loss: 0.812\n",
      "[9,    60] loss: 0.752\n",
      "Epoch: 8, Val. loss: 0.88, Val. mse: 0.88, Val R2: 0.0\n",
      "[10,    20] loss: 0.714\n",
      "[10,    40] loss: 0.753\n",
      "[10,    60] loss: 0.766\n",
      "Epoch: 9, Val. loss: 0.9, Val. mse: 0.9, Val R2: 0.0\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "model = GNN(D= 100, N = 70, F1 = 32 , F2 = 10, F = F1+F2).to(device)\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001, weight_decay= 0.00001)\n",
    "\n",
    "for epoch in range(10):  # loop over the dataset multiple times\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    for i, [XE, X, A,ESM1b, labels] in enumerate(train_loader):\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "        XE, X, A, ESM1b, labels = XE.to(device), X.to(device), A.to(device),ESM1b.to(device), labels.to(device)\n",
    "        # forward + backward + optimize\n",
    "        outputs = model(XE, X, A, ESM1b)\n",
    "        loss = criterion(outputs, labels.view((batch_size,-1)))\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # print statistics\n",
    "        running_loss += loss.item()\n",
    "        if i % 20 == 19:    # print every 2000 mini-batches\n",
    "            print('[%d, %5d] loss: %.3f' %\n",
    "                  (epoch + 1, i + 1, running_loss / 20))\n",
    "            running_loss = 0.0\n",
    "            \n",
    "    #After each epoch, calculate the validation loss:\n",
    "    running_mse = 0.0\n",
    "    running_r2 = 0.0\n",
    "    running_loss = 0.0\n",
    "    model.eval()\n",
    "    for i, [XE, X, A,ESM1b, labels] in enumerate(test_loader):\n",
    "        XE, X, A, ESM1b, labels = XE.to(device), X.to(device), A.to(device),ESM1b.to(device), labels.to(device)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            outputs = model(XE, X, A, ESM1b)\n",
    "        loss = criterion(outputs, labels.view((batch_size,-1)))\n",
    "        running_loss += loss.item()\n",
    "\n",
    "        outputs2 = outputs.view(-1).cpu().detach().numpy()\n",
    "        labels2 = labels.cpu().detach().numpy()\n",
    "        mse = np.mean((np.array(outputs2) - np.array(labels2))**2)\n",
    "        R2 = r2_score(np.array(labels2), np.array(outputs2))\n",
    "        running_mse += mse\n",
    "        running_r2 += R2\n",
    "\n",
    "    print(\"Epoch: %s, Val. loss: %s, Val. mse: %s, Val R2: %s\" % (epoch, np.round(running_loss/(i+1),2),\n",
    "                                                                  np.round(running_mse/(i+1), 2), \n",
    "                                                                 np.round(running_r2/(i+1))))\n",
    "\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(),join(CURRENT_DIR, \"..\" ,\"data\", \"substrate_data_KM\", \"GNN\", \"Pytorch_GNN_KM\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
