{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n",
      "C:\\Users\\alexk\\projects\\ESP\\notebooks_and_code\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "from os.path import join\n",
    "import numpy as np\n",
    "import pickle\n",
    "import random\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import Dataset\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n",
    "\n",
    "sys.path.append('.\\\\additional_code')\n",
    "from xgboost_training import *\n",
    "\n",
    "CURRENT_DIR = os.getcwd()\n",
    "print(CURRENT_DIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Loading and preprocessing data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_pickle(join(CURRENT_DIR, \"..\" ,\"data\",\"splits\", \"df_train_with_ESM1b_ts.pkl\"))\n",
    "df_test = pd.read_pickle(join(CURRENT_DIR, \"..\" ,\"data\", \"splits\", \"df_test_with_ESM1b_ts.pkl\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (a) Balancing datasets such that we have same amount of negative as positive data samples:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_UIDs = df_train[\"Uniprot ID\"].loc[df_train[\"Binding\"] == 1]\n",
    "for UID in pos_UIDs:\n",
    "    n_pos = len(df_train.loc[df_train[\"Binding\"] == 1].loc[df_train[\"Uniprot ID\"] == UID])\n",
    "    help_df = df_train.loc[df_train[\"Binding\"] == 0].loc[df_train[\"Uniprot ID\"] == UID]\n",
    "    df_train.drop(list(help_df.index)[n_pos:], inplace= True)\n",
    "    df_train.reset_index(inplace = True, drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_UIDs = df_test[\"Uniprot ID\"].loc[df_test[\"Binding\"] == 1]\n",
    "for UID in pos_UIDs:\n",
    "    n_pos = len(df_test.loc[df_test[\"Binding\"] == 1].loc[df_test[\"Uniprot ID\"] == UID])\n",
    "    help_df = df_test.loc[df_test[\"Binding\"] == 0].loc[df_test[\"Uniprot ID\"] == UID]\n",
    "    df_test.drop(list(help_df.index)[n_pos:], inplace= True)\n",
    "    df_test.reset_index(inplace = True, drop = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (b) Create dictionary with all target values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "mol_files = list(set(df_train[\"molecule ID\"])) + list(set(df_test[\"molecule ID\"]))\n",
    "mol_files = list(set(mol_files))\n",
    "\n",
    "target_variable_dict = {}\n",
    "target_variable_dict = create_target_dict(df = df_train, target_variable_dict = target_variable_dict)\n",
    "target_variable_dict = create_target_dict(df = df_test, target_variable_dict = target_variable_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (c) Get list with input combinations of Uniprot ID and metabolite ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5 0.5\n",
      "29480 7068\n"
     ]
    }
   ],
   "source": [
    "train_IDs = get_uid_cid_IDs(df_train)\n",
    "test_IDs = get_uid_cid_IDs(df_test)\n",
    "\n",
    "print(np.mean(df_train[\"Binding\"]), np.mean(df_test[\"Binding\"]))\n",
    "print(len(train_IDs), len(test_IDs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Calculating input matrices for metabolites"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (a) Creating input matrices:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_and_save_input_matrixes(molecule_ID, save_folder = join(CURRENT_DIR, \"..\" ,\"data\", \"substrate_data\",\n",
    "                                                                      \"GNN_input_matrices\")):\n",
    "    molecule_ID = molecule_ID.replace(\":\", \"_\")\n",
    "    molecule_ID = molecule_ID.replace(\"/\", \"Q\")\n",
    "    [XE, X, A] = create_input_data_for_GNN_for_substrates(substrate_ID = molecule_ID, print_error=True)\n",
    "    if not A is None:\n",
    "        np.save(join(save_folder, molecule_ID + '_X.npy'), X) #feature matrix of atoms/nodes\n",
    "        np.save(join(save_folder, molecule_ID + '_XE.npy'), XE) #feature matrix of atoms/nodes and bonds/edges\n",
    "        np.save(join(save_folder, molecule_ID + '_A.npy'), A) #adjacency matrix\n",
    "        \n",
    "        \n",
    "def calculate_atom_and_bond_feature_vectors(mol_files):\n",
    "    #check if feature vectors have already been calculated:\n",
    "    try:\n",
    "        os.mkdir(join(CURRENT_DIR, \"..\" ,\"data\", \"substrate_data\", \"mol_feature_vectors\"))\n",
    "    except FileExistsError:\n",
    "        None\n",
    "    \n",
    "    #existing feature vector files:\n",
    "    feature_files = os.listdir(join(CURRENT_DIR, \"..\" ,\"data\", \"substrate_data\", \"mol_feature_vectors\"))\n",
    "    for mol_file in mol_files:\n",
    "        #check if feature vectors were already calculated:\n",
    "        try:\n",
    "            if not mol_file + \"-atoms.txt\" in  feature_files:\n",
    "                #load mol_file\n",
    "                is_CHEBI_ID = (mol_file[0:5] == \"CHEBI\")\n",
    "                is_inchi = (mol_file[0:5] == \"InChI\")\n",
    "                if is_CHEBI_ID:\n",
    "                    ID = int(mol_file.split(\" \")[0].split(\":\")[-1])\n",
    "                    Inchi = list(df_chebi_to_inchi[\"Inchi\"].loc[df_chebi_to_inchi[\"ChEBI\"] == float(ID)])[0]\n",
    "\n",
    "                    if not pd.isnull(Inchi):\n",
    "                        mol = Chem.inchi.MolFromInchi(Inchi)\n",
    "                    else:\n",
    "                        print(ID, Inchi)\n",
    "                elif is_inchi:\n",
    "                    mol = Chem.inchi.MolFromInchi(mol_file)\n",
    "                    mol_file = mol_file.replace(\"/\", \"Q\")\n",
    "                else:\n",
    "                    mol = Chem.MolFromMolFile(mol_folder +  \"/mol-files/\" + mol_file + '.mol')\n",
    "       \n",
    "            if not mol is None:\n",
    "                calculate_atom_feature_vector_for_mol_file(mol, mol_file)\n",
    "                calculate_bond_feature_vector_for_mol_file(mol, mol_file)\n",
    "        except OSError: pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "calculate_atom_and_bond_feature_vectors(mol_files = mol_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "More than 70 (91) atoms in molcuele CHEBI_58466\n",
      "Could not create input for substrate ID CHEBI_58466\n",
      "More than 70 (70) atoms in molcuele CHEBI_83905\n",
      "Could not create input for substrate ID CHEBI_83905\n",
      "More than 70 (90) atoms in molcuele CHEBI_58502\n",
      "Could not create input for substrate ID CHEBI_58502\n",
      "More than 70 (76) atoms in molcuele CHEBI_57373\n",
      "Could not create input for substrate ID CHEBI_57373\n",
      "More than 70 (116) atoms in molcuele CHEBI_60032\n",
      "Could not create input for substrate ID CHEBI_60032\n",
      "More than 70 (79) atoms in molcuele CHEBI_58677\n",
      "Could not create input for substrate ID CHEBI_58677\n",
      "More than 70 (166) atoms in molcuele CHEBI_61502\n",
      "Could not create input for substrate ID CHEBI_61502\n",
      "More than 70 (194) atoms in molcuele CHEBI_61998\n",
      "Could not create input for substrate ID CHEBI_61998\n",
      "More than 70 (194) atoms in molcuele C00770\n",
      "Could not create input for substrate ID C00770\n",
      "More than 70 (70) atoms in molcuele CHEBI_18259\n",
      "Could not create input for substrate ID CHEBI_18259\n",
      "More than 70 (130) atoms in molcuele CHEBI_78435\n",
      "Could not create input for substrate ID CHEBI_78435\n",
      "More than 70 (91) atoms in molcuele CHEBI_16304\n",
      "Could not create input for substrate ID CHEBI_16304\n",
      "More than 70 (77) atoms in molcuele CHEBI_70758\n",
      "Could not create input for substrate ID CHEBI_70758\n",
      "More than 70 (125) atoms in molcuele CHEBI_60365\n",
      "Could not create input for substrate ID CHEBI_60365\n"
     ]
    }
   ],
   "source": [
    "for mol_ID in mol_files:\n",
    "    calculate_and_save_input_matrixes(molecule_ID = mol_ID)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  (b) Removing all datapoints without molecule input file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train[\"molecule ID\"] = [ID.replace(\":\", \"_\") for ID in df_train[\"substrate ID\"]]\n",
    "df_test[\"molecule ID\"] = [ID.replace(\":\", \"_\") for ID in df_test[\"substrate ID\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Uniprot ID</th>\n",
       "      <th>molecule ID</th>\n",
       "      <th>evidence</th>\n",
       "      <th>Binding</th>\n",
       "      <th>type</th>\n",
       "      <th>substrate ID</th>\n",
       "      <th>ECFP</th>\n",
       "      <th>ESM1b</th>\n",
       "      <th>ESM1b_ts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>G8BBN0</td>\n",
       "      <td>CHEBI_35681</td>\n",
       "      <td>exp</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>CHEBI:35681</td>\n",
       "      <td>0100000000000000000000000000000001000000000000...</td>\n",
       "      <td>[-0.033332635, 0.35044205, -0.07861315, 0.0046...</td>\n",
       "      <td>[0.5721893, 0.56740093, 0.09789569, 0.8466092,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>P78937</td>\n",
       "      <td>CHEBI_30616</td>\n",
       "      <td>exp</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>CHEBI:30616</td>\n",
       "      <td>0000000001000000000000000000000000000000000100...</td>\n",
       "      <td>[0.049317513, 0.11258735, -0.08035447, 0.04825...</td>\n",
       "      <td>[-0.56589794, -0.5028634, 0.2953197, -0.357490...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>F4K688</td>\n",
       "      <td>CHEBI_30616</td>\n",
       "      <td>exp</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>CHEBI:30616</td>\n",
       "      <td>0000000001000000000000000000000000000000000100...</td>\n",
       "      <td>[-0.005019231, 0.06971764, -0.022618646, -0.03...</td>\n",
       "      <td>[0.3031646, 0.69172686, -1.0995013, 0.13241063...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Q9Z0J5</td>\n",
       "      <td>CHEBI_58349</td>\n",
       "      <td>exp</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>CHEBI:58349</td>\n",
       "      <td>0000000001000000100000100000000000000000000000...</td>\n",
       "      <td>[-0.15290919, 0.31520224, 0.025415594, 0.02750...</td>\n",
       "      <td>[0.118711345, 0.8216332, -0.9046953, 1.179861,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>P49189</td>\n",
       "      <td>CHEBI_58264</td>\n",
       "      <td>exp</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>CHEBI:58264</td>\n",
       "      <td>0000000000000000010000000000000000000000000000...</td>\n",
       "      <td>[-0.044796597, 0.24305029, 0.10043996, -0.0269...</td>\n",
       "      <td>[0.8842707, -0.06434063, 0.5387947, 1.6151128,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29475</th>\n",
       "      <td>C9Y9E7</td>\n",
       "      <td>CHEBI_16810</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>engqvist</td>\n",
       "      <td>CHEBI:16810</td>\n",
       "      <td>0000000000000000000000000000000010000000000000...</td>\n",
       "      <td>[0.1486952, 0.23952422, -0.18132365, 0.0853893...</td>\n",
       "      <td>[-0.5624707, 0.49068797, -0.78957033, 1.021208...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29476</th>\n",
       "      <td>C9Y9E7</td>\n",
       "      <td>CHEBI_17544</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>engqvist</td>\n",
       "      <td>CHEBI:17544</td>\n",
       "      <td>0000000000000000000000000000000000000000000000...</td>\n",
       "      <td>[0.1486952, 0.23952422, -0.18132365, 0.0853893...</td>\n",
       "      <td>[-0.5624707, 0.49068797, -0.78957033, 1.021208...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29477</th>\n",
       "      <td>C9Y9E7</td>\n",
       "      <td>C00007</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>engqvist</td>\n",
       "      <td>C00007</td>\n",
       "      <td>0000000000000000100000000000000000000000000000...</td>\n",
       "      <td>[0.1486952, 0.23952422, -0.18132365, 0.0853893...</td>\n",
       "      <td>[-0.5624707, 0.49068797, -0.78957033, 1.021208...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29478</th>\n",
       "      <td>D4MUV9</td>\n",
       "      <td>CHEBI_16810</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>engqvist</td>\n",
       "      <td>CHEBI:16810</td>\n",
       "      <td>0000000000000000000000000000000010000000000000...</td>\n",
       "      <td>[0.08790772, 0.17450011, -0.014648443, 0.06931...</td>\n",
       "      <td>[1.0554699, 0.441238, 0.19652943, 1.1101232, -...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29479</th>\n",
       "      <td>D4MUV9</td>\n",
       "      <td>CHEBI_17478</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>engqvist</td>\n",
       "      <td>CHEBI:17478</td>\n",
       "      <td>0000000000000000000000000000000000000000000000...</td>\n",
       "      <td>[0.08790772, 0.17450011, -0.014648443, 0.06931...</td>\n",
       "      <td>[1.0554699, 0.441238, 0.19652943, 1.1101232, -...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>29128 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Uniprot ID  molecule ID evidence  Binding      type substrate ID  \\\n",
       "0         G8BBN0  CHEBI_35681      exp      1.0       NaN  CHEBI:35681   \n",
       "1         P78937  CHEBI_30616      exp      1.0       NaN  CHEBI:30616   \n",
       "2         F4K688  CHEBI_30616      exp      1.0       NaN  CHEBI:30616   \n",
       "3         Q9Z0J5  CHEBI_58349      exp      1.0       NaN  CHEBI:58349   \n",
       "4         P49189  CHEBI_58264      exp      1.0       NaN  CHEBI:58264   \n",
       "...          ...          ...      ...      ...       ...          ...   \n",
       "29475     C9Y9E7  CHEBI_16810      NaN      0.0  engqvist  CHEBI:16810   \n",
       "29476     C9Y9E7  CHEBI_17544      NaN      0.0  engqvist  CHEBI:17544   \n",
       "29477     C9Y9E7       C00007      NaN      0.0  engqvist       C00007   \n",
       "29478     D4MUV9  CHEBI_16810      NaN      0.0  engqvist  CHEBI:16810   \n",
       "29479     D4MUV9  CHEBI_17478      NaN      0.0  engqvist  CHEBI:17478   \n",
       "\n",
       "                                                    ECFP  \\\n",
       "0      0100000000000000000000000000000001000000000000...   \n",
       "1      0000000001000000000000000000000000000000000100...   \n",
       "2      0000000001000000000000000000000000000000000100...   \n",
       "3      0000000001000000100000100000000000000000000000...   \n",
       "4      0000000000000000010000000000000000000000000000...   \n",
       "...                                                  ...   \n",
       "29475  0000000000000000000000000000000010000000000000...   \n",
       "29476  0000000000000000000000000000000000000000000000...   \n",
       "29477  0000000000000000100000000000000000000000000000...   \n",
       "29478  0000000000000000000000000000000010000000000000...   \n",
       "29479  0000000000000000000000000000000000000000000000...   \n",
       "\n",
       "                                                   ESM1b  \\\n",
       "0      [-0.033332635, 0.35044205, -0.07861315, 0.0046...   \n",
       "1      [0.049317513, 0.11258735, -0.08035447, 0.04825...   \n",
       "2      [-0.005019231, 0.06971764, -0.022618646, -0.03...   \n",
       "3      [-0.15290919, 0.31520224, 0.025415594, 0.02750...   \n",
       "4      [-0.044796597, 0.24305029, 0.10043996, -0.0269...   \n",
       "...                                                  ...   \n",
       "29475  [0.1486952, 0.23952422, -0.18132365, 0.0853893...   \n",
       "29476  [0.1486952, 0.23952422, -0.18132365, 0.0853893...   \n",
       "29477  [0.1486952, 0.23952422, -0.18132365, 0.0853893...   \n",
       "29478  [0.08790772, 0.17450011, -0.014648443, 0.06931...   \n",
       "29479  [0.08790772, 0.17450011, -0.014648443, 0.06931...   \n",
       "\n",
       "                                                ESM1b_ts  \n",
       "0      [0.5721893, 0.56740093, 0.09789569, 0.8466092,...  \n",
       "1      [-0.56589794, -0.5028634, 0.2953197, -0.357490...  \n",
       "2      [0.3031646, 0.69172686, -1.0995013, 0.13241063...  \n",
       "3      [0.118711345, 0.8216332, -0.9046953, 1.179861,...  \n",
       "4      [0.8842707, -0.06434063, 0.5387947, 1.6151128,...  \n",
       "...                                                  ...  \n",
       "29475  [-0.5624707, 0.49068797, -0.78957033, 1.021208...  \n",
       "29476  [-0.5624707, 0.49068797, -0.78957033, 1.021208...  \n",
       "29477  [-0.5624707, 0.49068797, -0.78957033, 1.021208...  \n",
       "29478  [1.0554699, 0.441238, 0.19652943, 1.1101232, -...  \n",
       "29479  [1.0554699, 0.441238, 0.19652943, 1.1101232, -...  \n",
       "\n",
       "[29128 rows x 9 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid_mols = os.listdir(join(CURRENT_DIR, \"..\" ,\"data\", \"substrate_data\", \"GNN_input_matrices\"))\n",
    "valid_mols = [mol.split(\"_A\")[0] for mol in valid_mols]\n",
    "\n",
    "df_train = df_train.loc[df_train[\"molecule ID\"].isin(valid_mols)]\n",
    "df_test = df_test.loc[df_test[\"molecule ID\"].isin(valid_mols)]\n",
    "\n",
    "train_IDs = get_uid_cid_IDs(df_train)\n",
    "test_IDs = get_uid_cid_IDs(df_test)\n",
    "df_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (c) Creating representations for the enzymes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "uids_list = list(set(df_train[\"Uniprot ID\"])) + list(set(df_test[\"Uniprot ID\"]))\n",
    "uids_list = list(set(uids_list))\n",
    "uid_to_emb = {}\n",
    "embeddings = np.zeros((0,1280))\n",
    "for uid in uids_list:\n",
    "    try:\n",
    "        emb = np.reshape(np.array(list(df_train[\"ESM1b\"].loc[df_train[\"Uniprot ID\"] == uid])[0]), (1,1280))\n",
    "    except IndexError:\n",
    "        try:\n",
    "            emb = np.reshape(np.array(list(df_test[\"ESM1b\"].loc[df_test[\"Uniprot ID\"] == uid])[0]), (1,1280))\n",
    "        except IndexError:\n",
    "            emb = np.reshape(np.array(list(df_validation[\"ESM1b\"].loc[df_validation[\"Uniprot ID\"] == uid])[0]), (1,1280))\n",
    "    embeddings = np.concatenate([embeddings, emb])\n",
    "    uid_to_emb[uid] = emb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We perform a PCA an the enzyme representations to get 50-dimensional representations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "dim = 50\n",
    "\n",
    "pca = PCA(n_components = dim)\n",
    "pca.fit(embeddings)\n",
    "emb_pca = pca.transform(embeddings)\n",
    "\n",
    "#Calculate mean and std to normalize the PCA-transformed vectors\n",
    "mean = np.mean(emb_pca, axis = 0)\n",
    "std = np.std(emb_pca, axis = 0)\n",
    "\n",
    "uid_to_pca_emb = {}\n",
    "\n",
    "for i, uid in enumerate(uids_list):\n",
    "    uid_to_pca_emb[uid] = (emb_pca[i] - mean) / std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "uid_to_emb = uid_to_pca_emb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Training GNN:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  (a) Defining a DataGenerator:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataSet(Dataset):\n",
    "    def __init__(self, split_IDs, folder):\n",
    "        self.all_IDs = split_IDs\n",
    "        self.folder = folder\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.all_IDs)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        ID = self.all_IDs[idx]\n",
    "        try:\n",
    "            [uid,cid1, cid2] = ID.split(\"_\") \n",
    "            cid = cid1 +\"_\"+cid2\n",
    "        except ValueError:\n",
    "            [uid,cid] = ID.split(\"_\")\n",
    "            \n",
    "        XE = torch.tensor(np.load(join(self.folder, cid + '_XE.npy')), dtype = torch.float32)\n",
    "        X = torch.tensor(np.load(join(self.folder, cid + '_X.npy')), dtype = torch.float32)\n",
    "        A = torch.tensor(np.load(join(self.folder, cid + '_A.npy')), dtype = torch.float32)\n",
    "        ESM1b = torch.tensor(uid_to_emb[uid], dtype = torch.float32)\n",
    "        label = torch.tensor(target_variable_dict[ID], dtype= torch.float32)\n",
    "        return XE,X,A,ESM1b, label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (b) Splitting the training set in a validation and a training set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = len(train_IDs) \n",
    "random.seed(1)\n",
    "random.shuffle(train_IDs)\n",
    "test_IDs = train_IDs[int(0.8*n):]\n",
    "train_IDs = train_IDs[:int(0.8*n)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "\n",
    "train_dataset = CustomDataSet(folder  = join(CURRENT_DIR, \"..\" ,\"data\", \"substrate_data\",\n",
    "                                             \"GNN_input_matrices\"), split_IDs = train_IDs)\n",
    "train_loader = DataLoader(train_dataset , batch_size=batch_size, shuffle=True, drop_last=True)\n",
    "\n",
    "test_dataset = CustomDataSet(folder  = join(CURRENT_DIR, \"..\" ,\"data\", \"substrate_data\",\n",
    "                                            \"GNN_input_matrices\"), split_IDs = test_IDs)\n",
    "test_loader = DataLoader(test_dataset , batch_size=batch_size, shuffle=False, drop_last=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_train_batches = int(len(train_dataset)/batch_size)\n",
    "n_test_batches = int(len(test_dataset)/batch_size)\n",
    "train_batches = list(range(n_train_batches))\n",
    "test_batches = list(range(n_test_batches))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (c) Training GNN:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "pre_training = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\alexk\\anaconda3\\envs\\Predicting_Km\\lib\\site-packages\\torch\\autograd\\__init__.py:127: UserWarning: Mixed memory format inputs detected while calling the operator. The operator will output contiguous tensor even if some of the inputs are in channels_last format. (Triggered internally at  ..\\aten\\src\\ATen\\native\\TensorIterator.cpp:918.)\n",
      "  allow_unreachable=True)  # allow_unreachable flag\n",
      "C:\\Users\\alexk\\anaconda3\\envs\\Predicting_Km\\lib\\site-packages\\torch\\autograd\\__init__.py:127: UserWarning: Mixed memory format inputs detected while calling the operator. The operator will output channels_last tensor even if some of the inputs are not in channels_last format. (Triggered internally at  ..\\aten\\src\\ATen\\native\\TensorIterator.cpp:924.)\n",
      "  allow_unreachable=True)  # allow_unreachable flag\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,    20] loss: 0.743\n",
      "[1,    40] loss: 0.693\n",
      "[1,    60] loss: 0.707\n",
      "[1,    80] loss: 0.690\n",
      "[1,   100] loss: 0.694\n",
      "[1,   120] loss: 0.682\n",
      "[1,   140] loss: 0.690\n",
      "[1,   160] loss: 0.688\n",
      "[1,   180] loss: 0.682\n",
      "[1,   200] loss: 0.676\n",
      "[1,   220] loss: 0.686\n",
      "[1,   240] loss: 0.675\n",
      "[1,   260] loss: 0.681\n",
      "[1,   280] loss: 0.674\n",
      "[1,   300] loss: 0.679\n",
      "[1,   320] loss: 0.676\n",
      "[1,   340] loss: 0.673\n",
      "[1,   360] loss: 0.682\n",
      "Epoch: 0, Val. loss: 0.67, Val. acc: 0.58\n",
      "[2,    20] loss: 0.666\n",
      "[2,    40] loss: 0.662\n",
      "[2,    60] loss: 0.674\n",
      "[2,    80] loss: 0.662\n",
      "[2,   100] loss: 0.671\n",
      "[2,   120] loss: 0.660\n",
      "[2,   140] loss: 0.661\n",
      "[2,   160] loss: 0.659\n",
      "[2,   180] loss: 0.649\n",
      "[2,   200] loss: 0.668\n",
      "[2,   220] loss: 0.655\n",
      "[2,   240] loss: 0.659\n",
      "[2,   260] loss: 0.650\n",
      "[2,   280] loss: 0.646\n",
      "[2,   300] loss: 0.650\n",
      "[2,   320] loss: 0.635\n",
      "[2,   340] loss: 0.646\n",
      "[2,   360] loss: 0.643\n",
      "Epoch: 1, Val. loss: 0.64, Val. acc: 0.61\n",
      "[3,    20] loss: 0.626\n",
      "[3,    40] loss: 0.635\n",
      "[3,    60] loss: 0.632\n",
      "[3,    80] loss: 0.639\n",
      "[3,   100] loss: 0.624\n",
      "[3,   120] loss: 0.624\n",
      "[3,   140] loss: 0.628\n",
      "[3,   160] loss: 0.617\n",
      "[3,   180] loss: 0.623\n",
      "[3,   200] loss: 0.630\n",
      "[3,   220] loss: 0.639\n",
      "[3,   240] loss: 0.635\n",
      "[3,   260] loss: 0.632\n",
      "[3,   280] loss: 0.618\n",
      "[3,   300] loss: 0.622\n",
      "[3,   320] loss: 0.607\n",
      "[3,   340] loss: 0.622\n",
      "[3,   360] loss: 0.612\n",
      "Epoch: 2, Val. loss: 0.61, Val. acc: 0.63\n",
      "[4,    20] loss: 0.608\n",
      "[4,    40] loss: 0.612\n",
      "[4,    60] loss: 0.609\n",
      "[4,    80] loss: 0.609\n",
      "[4,   100] loss: 0.607\n",
      "[4,   120] loss: 0.604\n",
      "[4,   140] loss: 0.611\n",
      "[4,   160] loss: 0.602\n",
      "[4,   180] loss: 0.600\n",
      "[4,   200] loss: 0.587\n",
      "[4,   220] loss: 0.616\n",
      "[4,   240] loss: 0.588\n",
      "[4,   260] loss: 0.589\n",
      "[4,   280] loss: 0.602\n",
      "[4,   300] loss: 0.597\n",
      "[4,   320] loss: 0.588\n",
      "[4,   340] loss: 0.588\n",
      "[4,   360] loss: 0.594\n",
      "Epoch: 3, Val. loss: 0.58, Val. acc: 0.67\n",
      "[5,    20] loss: 0.580\n",
      "[5,    40] loss: 0.590\n",
      "[5,    60] loss: 0.588\n",
      "[5,    80] loss: 0.598\n",
      "[5,   100] loss: 0.571\n",
      "[5,   120] loss: 0.562\n",
      "[5,   140] loss: 0.585\n",
      "[5,   160] loss: 0.567\n",
      "[5,   180] loss: 0.581\n",
      "[5,   200] loss: 0.560\n",
      "[5,   220] loss: 0.566\n",
      "[5,   240] loss: 0.577\n",
      "[5,   260] loss: 0.596\n",
      "[5,   280] loss: 0.584\n",
      "[5,   300] loss: 0.587\n",
      "[5,   320] loss: 0.580\n",
      "[5,   340] loss: 0.566\n",
      "[5,   360] loss: 0.579\n",
      "Epoch: 4, Val. loss: 0.58, Val. acc: 0.68\n",
      "[6,    20] loss: 0.582\n",
      "[6,    40] loss: 0.571\n",
      "[6,    60] loss: 0.572\n",
      "[6,    80] loss: 0.561\n",
      "[6,   100] loss: 0.578\n",
      "[6,   120] loss: 0.576\n",
      "[6,   140] loss: 0.583\n",
      "[6,   160] loss: 0.568\n",
      "[6,   180] loss: 0.574\n",
      "[6,   200] loss: 0.571\n",
      "[6,   220] loss: 0.557\n",
      "[6,   240] loss: 0.570\n",
      "[6,   260] loss: 0.564\n",
      "[6,   280] loss: 0.577\n",
      "[6,   300] loss: 0.568\n",
      "[6,   320] loss: 0.585\n",
      "[6,   340] loss: 0.567\n",
      "[6,   360] loss: 0.575\n",
      "Epoch: 5, Val. loss: 0.57, Val. acc: 0.69\n",
      "[7,    20] loss: 0.542\n",
      "[7,    40] loss: 0.564\n",
      "[7,    60] loss: 0.538\n",
      "[7,    80] loss: 0.548\n",
      "[7,   100] loss: 0.552\n",
      "[7,   120] loss: 0.557\n",
      "[7,   140] loss: 0.547\n",
      "[7,   160] loss: 0.580\n",
      "[7,   180] loss: 0.565\n",
      "[7,   200] loss: 0.580\n",
      "[7,   220] loss: 0.558\n",
      "[7,   240] loss: 0.537\n",
      "[7,   260] loss: 0.564\n",
      "[7,   280] loss: 0.569\n",
      "[7,   300] loss: 0.547\n",
      "[7,   320] loss: 0.559\n",
      "[7,   340] loss: 0.560\n",
      "[7,   360] loss: 0.578\n",
      "Epoch: 6, Val. loss: 0.56, Val. acc: 0.69\n",
      "[8,    20] loss: 0.542\n",
      "[8,    40] loss: 0.553\n",
      "[8,    60] loss: 0.540\n",
      "[8,    80] loss: 0.551\n",
      "[8,   100] loss: 0.544\n",
      "[8,   120] loss: 0.537\n",
      "[8,   140] loss: 0.559\n",
      "[8,   160] loss: 0.542\n",
      "[8,   180] loss: 0.552\n",
      "[8,   200] loss: 0.536\n",
      "[8,   220] loss: 0.551\n",
      "[8,   240] loss: 0.556\n",
      "[8,   260] loss: 0.540\n",
      "[8,   280] loss: 0.573\n",
      "[8,   300] loss: 0.543\n",
      "[8,   320] loss: 0.555\n",
      "[8,   340] loss: 0.550\n",
      "[8,   360] loss: 0.539\n",
      "Epoch: 7, Val. loss: 0.55, Val. acc: 0.7\n",
      "[9,    20] loss: 0.551\n",
      "[9,    40] loss: 0.562\n",
      "[9,    60] loss: 0.548\n",
      "[9,    80] loss: 0.557\n",
      "[9,   100] loss: 0.554\n",
      "[9,   120] loss: 0.555\n",
      "[9,   140] loss: 0.550\n",
      "[9,   160] loss: 0.543\n",
      "[9,   180] loss: 0.539\n",
      "[9,   200] loss: 0.545\n",
      "[9,   220] loss: 0.544\n",
      "[9,   240] loss: 0.538\n",
      "[9,   260] loss: 0.546\n",
      "[9,   280] loss: 0.548\n",
      "[9,   300] loss: 0.536\n",
      "[9,   320] loss: 0.538\n",
      "[9,   340] loss: 0.542\n",
      "[9,   360] loss: 0.545\n",
      "Epoch: 8, Val. loss: 0.54, Val. acc: 0.71\n",
      "[10,    20] loss: 0.519\n",
      "[10,    40] loss: 0.523\n",
      "[10,    60] loss: 0.521\n",
      "[10,    80] loss: 0.537\n",
      "[10,   100] loss: 0.525\n",
      "[10,   120] loss: 0.525\n",
      "[10,   140] loss: 0.532\n",
      "[10,   160] loss: 0.536\n",
      "[10,   180] loss: 0.543\n",
      "[10,   200] loss: 0.544\n",
      "[10,   220] loss: 0.556\n",
      "[10,   240] loss: 0.544\n",
      "[10,   260] loss: 0.558\n",
      "[10,   280] loss: 0.505\n",
      "[10,   300] loss: 0.548\n",
      "[10,   320] loss: 0.539\n",
      "[10,   340] loss: 0.534\n",
      "[10,   360] loss: 0.528\n",
      "Epoch: 9, Val. loss: 0.54, Val. acc: 0.71\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "model = GNN(D= 100, N = 70, F1 = 32 , F2 = 10, F = F1+F2).to(device)\n",
    "if pre_training:\n",
    "    model.load_state_dict(torch.load(join(CURRENT_DIR, \"..\" ,\"data\", \"substrate_data_KM\", \"GNN\", \"Pytorch_GNN_KM\")))\n",
    "\n",
    "criterion = nn.BCELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001, weight_decay= 0.00001)\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "for epoch in range(10):  # loop over the dataset multiple times\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    for i, [XE, X, A,ESM1b, labels] in enumerate(train_loader):\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "        XE, X, A, ESM1b, labels = XE.to(device), X.to(device), A.to(device),ESM1b.to(device), labels.to(device)\n",
    "        # forward + backward + optimize\n",
    "        outputs = model(XE, X, A, ESM1b)\n",
    "        loss = criterion(outputs, labels.view((batch_size,-1)))\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # print statistics\n",
    "        running_loss += loss.item()\n",
    "        if i % 20 == 19:    # print every 2000 mini-batches\n",
    "            print('[%d, %5d] loss: %.3f' %\n",
    "                  (epoch + 1, i + 1, running_loss / 20))\n",
    "            running_loss = 0.0\n",
    "            \n",
    "    #After each epoch, calculate the validation loss:\n",
    "    running_acc = 0.0\n",
    "    running_loss = 0.0\n",
    "    model.eval()\n",
    "    for i, [XE, X, A,ESM1b, labels] in enumerate(test_loader):\n",
    "        XE, X, A, ESM1b, labels = XE.to(device), X.to(device), A.to(device),ESM1b.to(device), labels.to(device)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            outputs = model(XE, X, A, ESM1b)\n",
    "        loss = criterion(outputs, labels.view((batch_size,-1)))\n",
    "        running_loss += loss.item()\n",
    "\n",
    "        outputs2 = np.round(outputs.view(-1).cpu().detach().numpy()) \n",
    "        labels2 = labels.cpu().detach().numpy()\n",
    "        acc = np.mean([outputs2[i] == labels2[i] for i in range(len(labels))])\n",
    "        running_acc += acc\n",
    "\n",
    "    print(\"Epoch: %s, Val. loss: %s, Val. acc: %s\" % (epoch, np.round(running_loss/(i+1),2),\n",
    "                                                                  np.round(running_acc/(i+1), 2)))\n",
    "\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(),join(CURRENT_DIR, \"..\" ,\"data\", \"substrate_data\", \"GNN\", \"Pytorch_GNN_with_pretraining\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Creating GNN representations for traing and test set:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load trained model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GNN(\n",
       "  (BN1): BatchNorm2d(100, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (BN2): BatchNorm2d(100, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (BN3): BatchNorm1d(150, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (linear1): Linear(in_features=150, out_features=32, bias=True)\n",
       "  (linear2): Linear(in_features=32, out_features=1, bias=True)\n",
       "  (drop_layer): Dropout(p=0.2, inplace=False)\n",
       ")"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = GNN(D= 100, N = 70, F1 = 32 , F2 = 10, F = F1+F2).to(device)\n",
    "model.load_state_dict(torch.load(join(CURRENT_DIR, \"..\" ,\"data\", \"substrate_data\", \"GNN\", \"Pytorch_GNN_with_pretraining\")))\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_pickle(join(CURRENT_DIR, \"..\" ,\"data\",\"splits\", \"df_train_with_ESM1b_ts.pkl\"))\n",
    "df_test = pd.read_pickle(join(CURRENT_DIR, \"..\" ,\"data\", \"splits\", \"df_test_with_ESM1b_ts.pkl\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating a DataFrame with all metabolites in our dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>molecule ID</th>\n",
       "      <th>uid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>C00001</td>\n",
       "      <td>P9WIQ3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>C00002</td>\n",
       "      <td>P9WIQ3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>C00003</td>\n",
       "      <td>P9WIQ3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>C00004</td>\n",
       "      <td>P9WIQ3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>C00005</td>\n",
       "      <td>P9WIQ3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1355</th>\n",
       "      <td>CHEBI_88052</td>\n",
       "      <td>P9WIQ3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1356</th>\n",
       "      <td>InChI=1SQC18H36O3Qc1-2-3-4-5-6-7-8-9-10-11-12-...</td>\n",
       "      <td>P9WIQ3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1357</th>\n",
       "      <td>InChI=1SQC3H6O3Qc1-2(4)3(5)6Qh2,4H,1H3,(H,5,6)...</td>\n",
       "      <td>P9WIQ3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1358</th>\n",
       "      <td>InChI=1SQC8H16O3Qc1-2-3-4-5-6-7(9)8(10)11Qh7,9...</td>\n",
       "      <td>P9WIQ3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1359</th>\n",
       "      <td>InChI=1SQC8H8O3Qc9-7(8(10)11)6-4-2-1-3-5-6Qh1-...</td>\n",
       "      <td>P9WIQ3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1360 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            molecule ID     uid\n",
       "0                                                C00001  P9WIQ3\n",
       "1                                                C00002  P9WIQ3\n",
       "2                                                C00003  P9WIQ3\n",
       "3                                                C00004  P9WIQ3\n",
       "4                                                C00005  P9WIQ3\n",
       "...                                                 ...     ...\n",
       "1355                                        CHEBI_88052  P9WIQ3\n",
       "1356  InChI=1SQC18H36O3Qc1-2-3-4-5-6-7-8-9-10-11-12-...  P9WIQ3\n",
       "1357  InChI=1SQC3H6O3Qc1-2(4)3(5)6Qh2,4H,1H3,(H,5,6)...  P9WIQ3\n",
       "1358  InChI=1SQC8H16O3Qc1-2-3-4-5-6-7(9)8(10)11Qh7,9...  P9WIQ3\n",
       "1359  InChI=1SQC8H8O3Qc9-7(8(10)11)6-4-2-1-3-5-6Qh1-...  P9WIQ3\n",
       "\n",
       "[1360 rows x 2 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid_mols = os.listdir(join(CURRENT_DIR, \"..\" ,\"data\", \"substrate_data\", \"GNN_input_matrices\"))\n",
    "valid_mols = [mol.split(\"_A.npy\")[0] for mol in valid_mols]\n",
    "valid_mols = [mol for mol in valid_mols if not \".\" in mol]\n",
    "df_mols = pd.DataFrame(data = {\"molecule ID\" : valid_mols})\n",
    "\n",
    "#To create the substrate rep, the UID does not matter. Therfore, setting it random:\n",
    "df_mols[\"uid\"] = \"P9WIQ3\"\n",
    "df_mols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_data_folder = join(CURRENT_DIR, \"..\" ,\"data\", \"substrate_data\", \"GNN_input_matrices\")\n",
    "\n",
    "def get_representation_input(cid_list):\n",
    "    XE = ();\n",
    "    X = ();\n",
    "    A = ();\n",
    "    UniRep = ();\n",
    "    extras = ();\n",
    "    # Generate data\n",
    "    for i in range(len(cid_list)):\n",
    "        cid  = cid_list[i]\n",
    "\n",
    "        X = X + (np.load(join(input_data_folder, cid + '_X.npy')), );\n",
    "        XE = XE + (np.load(join(input_data_folder, cid + '_XE.npy')), );\n",
    "        A = A + (np.load(join(input_data_folder, cid + '_A.npy')), );\n",
    "    return(XE, X, A)\n",
    "\n",
    "\n",
    "def get_substrate_representations(df):\n",
    "    df[\"substrate_rep\"] = \"\"\n",
    "    \n",
    "    i = 0\n",
    "    n = len(df)\n",
    "\n",
    "    while i*64 <= n:\n",
    "        cid_all = list(df[\"molecule ID\"])\n",
    "\n",
    "        if (i+1)*64  <= n:\n",
    "            XE, X, A= get_representation_input(cid_all[i*64:(i+1)*64])\n",
    "            \n",
    "            XE = torch.tensor(np.array(XE), dtype = torch.float32).to(device)\n",
    "            X = torch.tensor(np.array(X), dtype = torch.float32).to(device)\n",
    "            A = torch.tensor(np.array(A), dtype = torch.float32).to(device)\n",
    "            representations = model.get_GNN_rep(XE, X,A).cpu().detach().numpy()\n",
    "            df[\"substrate_rep\"][i*64:(i+1)*64] = list(representations[:, :D])\n",
    "        else:\n",
    "            print(i)\n",
    "            XE, X, A= get_representation_input(cid_all[i*64:(i+1)*64])\n",
    "            XE = torch.tensor(np.array(XE), dtype = torch.float32).to(device)\n",
    "            X = torch.tensor(np.array(X), dtype = torch.float32).to(device)\n",
    "            A = torch.tensor(np.array(A), dtype = torch.float32).to(device)\n",
    "            representations = model.get_GNN_rep(XE, X,A).cpu().detach().numpy()\n",
    "            df[\"substrate_rep\"][-len(representations):] = list(representations[:, :D])\n",
    "        i += 1\n",
    "    return(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>molecule ID</th>\n",
       "      <th>uid</th>\n",
       "      <th>substrate_rep</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>C00001</td>\n",
       "      <td>P9WIQ3</td>\n",
       "      <td>[0.0, 0.6329006, 0.0, 44.773804, 41.644196, 21...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>C00002</td>\n",
       "      <td>P9WIQ3</td>\n",
       "      <td>[0.0, 46.134777, 0.0, 0.0, 1177.1073, 187.5388...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>C00003</td>\n",
       "      <td>P9WIQ3</td>\n",
       "      <td>[0.0, 8.150052, 0.0, 8.550125, 40.956882, 66.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>C00004</td>\n",
       "      <td>P9WIQ3</td>\n",
       "      <td>[0.0, 1.8680593, 0.0, 0.0, 44.121048, 557.9273...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>C00005</td>\n",
       "      <td>P9WIQ3</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 183.79741, 173.6141, 0.0,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1355</th>\n",
       "      <td>CHEBI_88052</td>\n",
       "      <td>P9WIQ3</td>\n",
       "      <td>[0.0, 46.631508, 0.0, 0.0, 2.3734078, 1.361197...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1356</th>\n",
       "      <td>InChI=1SQC18H36O3Qc1-2-3-4-5-6-7-8-9-10-11-12-...</td>\n",
       "      <td>P9WIQ3</td>\n",
       "      <td>[0.0, 0.2668656, 0.0, 0.0, 0.784772, 10.25194,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1357</th>\n",
       "      <td>InChI=1SQC3H6O3Qc1-2(4)3(5)6Qh2,4H,1H3,(H,5,6)...</td>\n",
       "      <td>P9WIQ3</td>\n",
       "      <td>[0.0, 0.9508717, 0.0, 90.905556, 0.79774696, 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1358</th>\n",
       "      <td>InChI=1SQC8H16O3Qc1-2-3-4-5-6-7(9)8(10)11Qh7,9...</td>\n",
       "      <td>P9WIQ3</td>\n",
       "      <td>[0.0, 0.2668656, 0.0, 0.0, 0.784772, 10.25194,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1359</th>\n",
       "      <td>InChI=1SQC8H8O3Qc9-7(8(10)11)6-4-2-1-3-5-6Qh1-...</td>\n",
       "      <td>P9WIQ3</td>\n",
       "      <td>[0.0, 0.0, 0.0, 32.41623, 66.58023, 126.79576,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1360 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            molecule ID     uid  \\\n",
       "0                                                C00001  P9WIQ3   \n",
       "1                                                C00002  P9WIQ3   \n",
       "2                                                C00003  P9WIQ3   \n",
       "3                                                C00004  P9WIQ3   \n",
       "4                                                C00005  P9WIQ3   \n",
       "...                                                 ...     ...   \n",
       "1355                                        CHEBI_88052  P9WIQ3   \n",
       "1356  InChI=1SQC18H36O3Qc1-2-3-4-5-6-7-8-9-10-11-12-...  P9WIQ3   \n",
       "1357  InChI=1SQC3H6O3Qc1-2(4)3(5)6Qh2,4H,1H3,(H,5,6)...  P9WIQ3   \n",
       "1358  InChI=1SQC8H16O3Qc1-2-3-4-5-6-7(9)8(10)11Qh7,9...  P9WIQ3   \n",
       "1359  InChI=1SQC8H8O3Qc9-7(8(10)11)6-4-2-1-3-5-6Qh1-...  P9WIQ3   \n",
       "\n",
       "                                          substrate_rep  \n",
       "0     [0.0, 0.6329006, 0.0, 44.773804, 41.644196, 21...  \n",
       "1     [0.0, 46.134777, 0.0, 0.0, 1177.1073, 187.5388...  \n",
       "2     [0.0, 8.150052, 0.0, 8.550125, 40.956882, 66.0...  \n",
       "3     [0.0, 1.8680593, 0.0, 0.0, 44.121048, 557.9273...  \n",
       "4     [0.0, 0.0, 0.0, 0.0, 183.79741, 173.6141, 0.0,...  \n",
       "...                                                 ...  \n",
       "1355  [0.0, 46.631508, 0.0, 0.0, 2.3734078, 1.361197...  \n",
       "1356  [0.0, 0.2668656, 0.0, 0.0, 0.784772, 10.25194,...  \n",
       "1357  [0.0, 0.9508717, 0.0, 90.905556, 0.79774696, 0...  \n",
       "1358  [0.0, 0.2668656, 0.0, 0.0, 0.784772, 10.25194,...  \n",
       "1359  [0.0, 0.0, 0.0, 32.41623, 66.58023, 126.79576,...  \n",
       "\n",
       "[1360 rows x 3 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_mols = get_substrate_representations(df = df_mols)\n",
    "df_mols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_pickle(join(CURRENT_DIR, \"..\" ,\"data\", \"splits\", \"df_train_with_ESM1b_ts_GNN.pkl\"))\n",
    "df_test = pd.read_pickle(join(CURRENT_DIR, \"..\" ,\"data\", \"splits\", \"df_test_with_ESM1b_ts_GNN.pkl\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\alexk\\anaconda3\\envs\\Predicting_Km\\lib\\site-packages\\ipykernel_launcher.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  after removing the cwd from sys.path.\n"
     ]
    }
   ],
   "source": [
    "df_train[\"GNN rep (pretrained)\"] = \"\"\n",
    "for ind in df_train.index:\n",
    "    try:\n",
    "        df_train[\"GNN rep (pretrained)\"][ind] = list(df_mols[\"substrate_rep\"].loc[df_mols[\"molecule ID\"] == df_train[\"molecule ID\"][ind].replace(\":\", \"_\").replace(\"Q\", \"/\")])[0]\n",
    "    except IndexError:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\alexk\\anaconda3\\envs\\Predicting_Km\\lib\\site-packages\\ipykernel_launcher.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  after removing the cwd from sys.path.\n"
     ]
    }
   ],
   "source": [
    "df_test[\"GNN rep (pretrained)\"] = \"\"\n",
    "for ind in df_test.index:\n",
    "    try:\n",
    "        df_test[\"GNN rep (pretrained)\"][ind] = list(df_mols[\"substrate_rep\"].loc[df_mols[\"molecule ID\"] == df_test[\"molecule ID\"][ind].replace(\":\", \"_\").replace(\"Q\", \"/\")])[0]\n",
    "    except IndexError:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.to_pickle(join(CURRENT_DIR, \"..\" ,\"data\", \"splits\", \"df_train_with_ESM1b_ts_GNN.pkl\"), protocol = 4)\n",
    "df_test.to_pickle(join(CURRENT_DIR, \"..\" ,\"data\", \"splits\", \"df_test_with_ESM1b_ts_GNN.pkl\"), protocol = 4)\n",
    "\n",
    "#df_engqvist.to_pickle(join(CURRENT_DIR, \"alex_data\", \"new_test_data_Engqvist_group_with_GNN_train_test_split_with_GNN_similar.pkl\"), protocol = 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
